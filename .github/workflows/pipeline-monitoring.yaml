name: Pipeline Health Monitoring
on:
  schedule:
    # ë§¤ 5ë¶„ë§ˆë‹¤ ì‹¤í–‰
    - cron: '*/5 * * * *'
  workflow_dispatch:
    inputs:
      force_check:
        description: 'ê°•ì œ ì „ì²´ í—¬ìŠ¤ì²´í¬ ì‹¤í–‰'
        required: false
        default: 'false'
        type: boolean
      send_notifications:
        description: 'ì•Œë¦¼ ë°œì†¡ í™œì„±í™”'
        required: false
        default: 'true'
        type: boolean

env:
  NAMESPACE: blacklist
  APP_NAME: blacklist
  ARGOCD_SERVER: argo.jclee.me
  ALERT_THRESHOLD_MINUTES: 10
  MAX_CONSECUTIVE_FAILURES: 3

jobs:
  pipeline-health-check:
    runs-on: self-hosted
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set monitoring context
        id: context
        run: |
          echo "timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_OUTPUT
          echo "check_id=$(date +%s)" >> $GITHUB_OUTPUT
          echo "force_check=${{ github.event.inputs.force_check || 'false' }}" >> $GITHUB_OUTPUT
          echo "send_notifications=${{ github.event.inputs.send_notifications || 'true' }}" >> $GITHUB_OUTPUT
      
      - name: Pipeline health check
        id: health_check
        continue-on-error: true
        run: |
          echo "ğŸ” íŒŒì´í”„ë¼ì¸ í—¬ìŠ¤ì²´í¬ ì‹œì‘..."
          
          # í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
          bash scripts/pipeline-health-monitor.sh > health-check-output.log 2>&1
          HEALTH_EXIT_CODE=$?
          
          # ê²°ê³¼ ë¶„ì„
          case $HEALTH_EXIT_CODE in
            0)
              echo "status=healthy" >> $GITHUB_OUTPUT
              echo "severity=info" >> $GITHUB_OUTPUT
              echo "message=ëª¨ë“  íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œê°€ ì •ìƒ ì‘ë™ ì¤‘" >> $GITHUB_OUTPUT
              ;;
            1)
              echo "status=degraded" >> $GITHUB_OUTPUT
              echo "severity=warning" >> $GITHUB_OUTPUT
              echo "message=ì¼ë¶€ êµ¬ì„± ìš”ì†Œì— ê²½ë¯¸í•œ ë¬¸ì œ ë°œê²¬" >> $GITHUB_OUTPUT
              ;;
            2)
              echo "status=critical" >> $GITHUB_OUTPUT
              echo "severity=critical" >> $GITHUB_OUTPUT
              echo "message=ì‹¬ê°í•œ íŒŒì´í”„ë¼ì¸ ë¬¸ì œ ë°œê²¬" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "status=unknown" >> $GITHUB_OUTPUT
              echo "severity=warning" >> $GITHUB_OUTPUT
              echo "message=í—¬ìŠ¤ì²´í¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ" >> $GITHUB_OUTPUT
              ;;
          esac
          
          echo "exit_code=$HEALTH_EXIT_CODE" >> $GITHUB_OUTPUT
          
          # ë¡œê·¸ ìš”ì•½ ìƒì„±
          echo "=== í—¬ìŠ¤ì²´í¬ ê²°ê³¼ ìš”ì•½ ===" >> health-summary.txt
          echo "ì‹œê°„: $(date)" >> health-summary.txt
          echo "ìƒíƒœ: $([ $HEALTH_EXIT_CODE -eq 0 ] && echo "ì •ìƒ" || echo "ë¬¸ì œ ë°œê²¬")" >> health-summary.txt
          echo "ì¢…ë£Œ ì½”ë“œ: $HEALTH_EXIT_CODE" >> health-summary.txt
          echo "" >> health-summary.txt
          
          # ì£¼ìš” ì •ë³´ ì¶”ì¶œ
          if grep -q "íŒŒì´í”„ë¼ì¸ í—¬ìŠ¤ ìŠ¤ì½”ì–´" health-check-output.log; then
            grep "íŒŒì´í”„ë¼ì¸ í—¬ìŠ¤ ìŠ¤ì½”ì–´" health-check-output.log >> health-summary.txt
          fi
          
          if grep -q "íŒŒì´í”„ë¼ì¸ ìƒíƒœ:" health-check-output.log; then
            grep "íŒŒì´í”„ë¼ì¸ ìƒíƒœ:" health-check-output.log >> health-summary.txt
          fi
          
          echo "í—¬ìŠ¤ì²´í¬ ì™„ë£Œ. ìƒíƒœ: $(cat health-summary.txt | grep "ìƒíƒœ:" || echo "ì•Œ ìˆ˜ ì—†ìŒ")"
      
      - name: ArgoCD specific checks
        id: argocd_check
        continue-on-error: true
        run: |
          echo "ğŸš€ ArgoCD ìƒì„¸ ì²´í¬..."
          
          # ArgoCD ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ
          APP_STATUS=$(argocd app get ${{ env.APP_NAME }} --server ${{ env.ARGOCD_SERVER }} --grpc-web -o json 2>/dev/null || echo "{}")
          
          if [ "$APP_STATUS" != "{}" ]; then
            HEALTH_STATUS=$(echo "$APP_STATUS" | jq -r '.status.health.status // "Unknown"')
            SYNC_STATUS=$(echo "$APP_STATUS" | jq -r '.status.sync.status // "Unknown"')
            LAST_SYNC=$(echo "$APP_STATUS" | jq -r '.status.operationState.finishedAt // "Never"')
            
            echo "argocd_health=$HEALTH_STATUS" >> $GITHUB_OUTPUT
            echo "argocd_sync=$SYNC_STATUS" >> $GITHUB_OUTPUT
            echo "last_sync=$LAST_SYNC" >> $GITHUB_OUTPUT
            
            # ArgoCD ë¬¸ì œ ê°ì§€
            if [ "$HEALTH_STATUS" = "Degraded" ] || [ "$HEALTH_STATUS" = "Missing" ]; then
              echo "argocd_issue=true" >> $GITHUB_OUTPUT
              echo "argocd_issue_type=health_$HEALTH_STATUS" >> $GITHUB_OUTPUT
            elif [ "$SYNC_STATUS" = "OutOfSync" ]; then
              # ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹œê°„ í™•ì¸
              if [ "$LAST_SYNC" != "Never" ]; then
                LAST_SYNC_EPOCH=$(date -d "$LAST_SYNC" +%s 2>/dev/null || echo 0)
                CURRENT_EPOCH=$(date +%s)
                MINUTES_SINCE_SYNC=$(( (CURRENT_EPOCH - LAST_SYNC_EPOCH) / 60 ))
                
                if [ $MINUTES_SINCE_SYNC -gt ${{ env.ALERT_THRESHOLD_MINUTES }} ]; then
                  echo "argocd_issue=true" >> $GITHUB_OUTPUT
                  echo "argocd_issue_type=sync_outdated" >> $GITHUB_OUTPUT
                else
                  echo "argocd_issue=false" >> $GITHUB_OUTPUT
                fi
              else
                echo "argocd_issue=true" >> $GITHUB_OUTPUT
                echo "argocd_issue_type=never_synced" >> $GITHUB_OUTPUT
              fi
            else
              echo "argocd_issue=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "argocd_health=Unknown" >> $GITHUB_OUTPUT
            echo "argocd_sync=Unknown" >> $GITHUB_OUTPUT
            echo "argocd_issue=true" >> $GITHUB_OUTPUT
            echo "argocd_issue_type=connection_failed" >> $GITHUB_OUTPUT
          fi
      
      - name: Application endpoint checks
        id: endpoint_check
        continue-on-error: true
        run: |
          echo "ğŸŒ ì• í”Œë¦¬ì¼€ì´ì…˜ ì—”ë“œí¬ì¸íŠ¸ ì²´í¬..."
          
          NODE_PORT=$(kubectl get service ${{ env.APP_NAME }} -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.ports[0].nodePort}' 2>/dev/null || echo "")
          
          if [ -z "$NODE_PORT" ]; then
            echo "endpoint_status=service_not_found" >> $GITHUB_OUTPUT
            echo "endpoint_issue=true" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # í•µì‹¬ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
          ENDPOINTS=(
            "/health:Health Check"
            "/api/stats:Statistics API"
            "/api/collection/status:Collection Status"
            "/api/blacklist/active:Active Blacklist"
          )
          
          FAILED_ENDPOINTS=0
          TOTAL_ENDPOINTS=${#ENDPOINTS[@]}
          FAILED_LIST=""
          
          for endpoint_info in "${ENDPOINTS[@]}"; do
            endpoint=$(echo "$endpoint_info" | cut -d':' -f1)
            description=$(echo "$endpoint_info" | cut -d':' -f2)
            
            status=$(curl -s -o /dev/null -w "%{http_code}" --connect-timeout 5 --max-time 10 \
                    "http://localhost:$NODE_PORT$endpoint" 2>/dev/null || echo "000")
            
            if [ "$status" != "200" ]; then
              FAILED_ENDPOINTS=$((FAILED_ENDPOINTS + 1))
              FAILED_LIST="$FAILED_LIST $endpoint($status)"
              echo "âŒ $description ($endpoint): $status"
            else
              echo "âœ… $description ($endpoint): $status"
            fi
          done
          
          # ê²°ê³¼ ì €ì¥
          echo "failed_endpoints=$FAILED_ENDPOINTS" >> $GITHUB_OUTPUT
          echo "total_endpoints=$TOTAL_ENDPOINTS" >> $GITHUB_OUTPUT
          echo "failed_list=$FAILED_LIST" >> $GITHUB_OUTPUT
          
          if [ $FAILED_ENDPOINTS -gt 0 ]; then
            echo "endpoint_issue=true" >> $GITHUB_OUTPUT
            echo "endpoint_status=degraded" >> $GITHUB_OUTPUT
          else
            echo "endpoint_issue=false" >> $GITHUB_OUTPUT
            echo "endpoint_status=healthy" >> $GITHUB_OUTPUT
          fi
          
          # ì‘ë‹µ ì‹œê°„ ì¸¡ì •
          RESPONSE_TIME=$(curl -s -o /dev/null -w "%{time_total}" --connect-timeout 5 --max-time 10 \
                         "http://localhost:$NODE_PORT/health" 2>/dev/null || echo "999")
          echo "response_time=$RESPONSE_TIME" >> $GITHUB_OUTPUT
      
      - name: Store monitoring state
        id: state
        run: |
          # ì´ì „ ìƒíƒœ íŒŒì¼ ê²½ë¡œ
          STATE_FILE="/tmp/pipeline-monitoring-state.json"
          
          # í˜„ì¬ ìƒíƒœ ìƒì„±
          cat > current-state.json <<EOF
          {
            "timestamp": "${{ steps.context.outputs.timestamp }}",
            "check_id": "${{ steps.context.outputs.check_id }}",
            "overall_status": "${{ steps.health_check.outputs.status }}",
            "severity": "${{ steps.health_check.outputs.severity }}",
            "argocd": {
              "health": "${{ steps.argocd_check.outputs.argocd_health }}",
              "sync": "${{ steps.argocd_check.outputs.argocd_sync }}",
              "issue": "${{ steps.argocd_check.outputs.argocd_issue }}",
              "issue_type": "${{ steps.argocd_check.outputs.argocd_issue_type }}"
            },
            "endpoints": {
              "status": "${{ steps.endpoint_check.outputs.endpoint_status }}",
              "failed_count": "${{ steps.endpoint_check.outputs.failed_endpoints }}",
              "total_count": "${{ steps.endpoint_check.outputs.total_endpoints }}",
              "response_time": "${{ steps.endpoint_check.outputs.response_time }}",
              "issue": "${{ steps.endpoint_check.outputs.endpoint_issue }}"
            }
          }
          EOF
          
          # ì—°ì† ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ê³„ì‚°
          CONSECUTIVE_FAILURES=0
          if [ -f "$STATE_FILE" ]; then
            PREV_STATUS=$(jq -r '.overall_status // "unknown"' "$STATE_FILE")
            PREV_FAILURES=$(jq -r '.consecutive_failures // 0' "$STATE_FILE")
            
            if [ "${{ steps.health_check.outputs.status }}" != "healthy" ]; then
              if [ "$PREV_STATUS" != "healthy" ]; then
                CONSECUTIVE_FAILURES=$((PREV_FAILURES + 1))
              else
                CONSECUTIVE_FAILURES=1
              fi
            fi
          elif [ "${{ steps.health_check.outputs.status }}" != "healthy" ]; then
            CONSECUTIVE_FAILURES=1
          fi
          
          # ìƒíƒœ íŒŒì¼ ì—…ë°ì´íŠ¸
          jq --argjson failures "$CONSECUTIVE_FAILURES" '. + {"consecutive_failures": $failures}' current-state.json > "$STATE_FILE"
          
          echo "consecutive_failures=$CONSECUTIVE_FAILURES" >> $GITHUB_OUTPUT
          echo "trigger_alert=$([ $CONSECUTIVE_FAILURES -ge ${{ env.MAX_CONSECUTIVE_FAILURES }} ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
      
      - name: Auto-recovery attempt
        if: steps.health_check.outputs.status == 'critical' || steps.state.outputs.consecutive_failures >= 2
        id: auto_recovery
        run: |
          echo "ğŸ”§ ìë™ ë³µêµ¬ ì‹œë„..."
          
          # ArgoCD ê°•ì œ ë™ê¸°í™” ì‹œë„
          if [ "${{ steps.argocd_check.outputs.argocd_issue }}" = "true" ]; then
            echo "ArgoCD ê°•ì œ ë™ê¸°í™” ì‹¤í–‰..."
            argocd app sync ${{ env.APP_NAME }} --server ${{ env.ARGOCD_SERVER }} --grpc-web --force --prune || true
            sleep 30
          fi
          
          # Pod ì¬ì‹œì‘ ì‹œë„ (ì—”ë“œí¬ì¸íŠ¸ ë¬¸ì œ ì‹œ)
          if [ "${{ steps.endpoint_check.outputs.endpoint_issue }}" = "true" ]; then
            echo "ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘ ì‹¤í–‰..."
            kubectl rollout restart deployment/${{ env.APP_NAME }} -n ${{ env.NAMESPACE }} || true
            kubectl rollout status deployment/${{ env.APP_NAME }} -n ${{ env.NAMESPACE }} --timeout=300s || true
          fi
          
          echo "auto_recovery_attempted=true" >> $GITHUB_OUTPUT
      
      - name: Critical alert and rollback
        if: steps.state.outputs.trigger_alert == 'true'
        id: critical_alert
        run: |
          echo "ğŸš¨ ì„ê³„ì  ë„ë‹¬ - ìë™ ë¡¤ë°± ê³ ë ¤..."
          
          # ìë™ ë¡¤ë°± ì‹¤í–‰ (ì—°ì† 3íšŒ ì´ìƒ ì‹¤íŒ¨ ì‹œ)
          if [ ${{ steps.state.outputs.consecutive_failures }} -ge ${{ env.MAX_CONSECUTIVE_FAILURES }} ]; then
            echo "ì—°ì† ${{ steps.state.outputs.consecutive_failures }}íšŒ ì‹¤íŒ¨ - ìë™ ë¡¤ë°± ì‹¤í–‰"
            bash scripts/auto-rollback.sh --check-health || true
            echo "rollback_triggered=true" >> $GITHUB_OUTPUT
          else
            echo "rollback_triggered=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Send notifications
        if: steps.context.outputs.send_notifications == 'true' && (steps.health_check.outputs.status != 'healthy' || steps.context.outputs.force_check == 'true')
        run: |
          echo "ğŸ“¬ ì•Œë¦¼ ë°œì†¡ ì¤‘..."
          
          # ì•Œë¦¼ ë©”ì‹œì§€ êµ¬ì„±
          STATUS="${{ steps.health_check.outputs.status }}"
          SEVERITY="${{ steps.health_check.outputs.severity }}"
          CONSECUTIVE="${{ steps.state.outputs.consecutive_failures }}"
          
          case $STATUS in
            "healthy")
              EMOJI="âœ…"
              COLOR="good"
              ;;
            "degraded")
              EMOJI="âš ï¸"
              COLOR="warning"
              ;;
            "critical")
              EMOJI="ğŸš¨"
              COLOR="danger"
              ;;
            *)
              EMOJI="â“"
              COLOR="warning"
              ;;
          esac
          
          MESSAGE="$EMOJI Blacklist íŒŒì´í”„ë¼ì¸ ìƒíƒœ: $STATUS"
          if [ $CONSECUTIVE -gt 0 ]; then
            MESSAGE="$MESSAGE (ì—°ì† ${CONSECUTIVE}íšŒ ë¬¸ì œ)"
          fi
          
          # ArgoCD ìƒíƒœ ì¶”ê°€
          if [ "${{ steps.argocd_check.outputs.argocd_issue }}" = "true" ]; then
            MESSAGE="$MESSAGE\nâ€¢ ArgoCD: ${{ steps.argocd_check.outputs.argocd_issue_type }}"
          fi
          
          # ì—”ë“œí¬ì¸íŠ¸ ìƒíƒœ ì¶”ê°€
          if [ "${{ steps.endpoint_check.outputs.endpoint_issue }}" = "true" ]; then
            MESSAGE="$MESSAGE\nâ€¢ ì—”ë“œí¬ì¸íŠ¸: ${{ steps.endpoint_check.outputs.failed_endpoints }}/${{ steps.endpoint_check.outputs.total_endpoints }} ì‹¤íŒ¨"
          fi
          
          # ë³µêµ¬ ì‹œë„ ì—¬ë¶€
          if [ "${{ steps.auto_recovery.outputs.auto_recovery_attempted }}" = "true" ]; then
            MESSAGE="$MESSAGE\nâ€¢ ìë™ ë³µêµ¬ ì‹œë„ë¨"
          fi
          
          # ë¡¤ë°± ì—¬ë¶€
          if [ "${{ steps.critical_alert.outputs.rollback_triggered }}" = "true" ]; then
            MESSAGE="$MESSAGE\nâ€¢ ğŸ”„ ìë™ ë¡¤ë°± ì‹¤í–‰ë¨"
          fi
          
          # Webhook ì•Œë¦¼ ë°œì†¡ (ì„ íƒì )
          if [ ! -z "${{ secrets.MONITORING_WEBHOOK_URL }}" ]; then
            curl -X POST "${{ secrets.MONITORING_WEBHOOK_URL }}" \
              -H "Content-Type: application/json" \
              -d "{
                \"text\": \"$MESSAGE\",
                \"color\": \"$COLOR\",
                \"timestamp\": \"${{ steps.context.outputs.timestamp }}\",
                \"details\": {
                  \"status\": \"$STATUS\",
                  \"consecutive_failures\": $CONSECUTIVE,
                  \"argocd_health\": \"${{ steps.argocd_check.outputs.argocd_health }}\",
                  \"endpoint_status\": \"${{ steps.endpoint_check.outputs.endpoint_status }}\",
                  \"response_time\": \"${{ steps.endpoint_check.outputs.response_time }}\",
                  \"workflow_url\": \"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\"
                }
              }" || true
          fi
          
          echo "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ"
      
      - name: Update status badge
        if: always()
        run: |
          # ìƒíƒœ ë°°ì§€ìš© ì •ë³´ ìƒì„±
          STATUS="${{ steps.health_check.outputs.status }}"
          
          case $STATUS in
            "healthy")
              BADGE_COLOR="brightgreen"
              BADGE_MESSAGE="healthy"
              ;;
            "degraded")
              BADGE_COLOR="yellow"
              BADGE_MESSAGE="degraded"
              ;;
            "critical")
              BADGE_COLOR="red"
              BADGE_MESSAGE="critical"
              ;;
            *)
              BADGE_COLOR="lightgrey"
              BADGE_MESSAGE="unknown"
              ;;
          esac
          
          # GitHub Pagesë‚˜ ì™¸ë¶€ ë°°ì§€ ì„œë¹„ìŠ¤ìš© JSON ìƒì„±
          cat > pipeline-status.json <<EOF
          {
            "schemaVersion": 1,
            "label": "pipeline",
            "message": "$BADGE_MESSAGE",
            "color": "$BADGE_COLOR",
            "namedLogo": "kubernetes",
            "cacheSeconds": 300
          }
          EOF
          
          echo "ìƒíƒœ ë°°ì§€ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ"
      
      - name: Archive monitoring logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: monitoring-logs-${{ steps.context.outputs.check_id }}
          path: |
            health-check-output.log
            health-summary.txt
            current-state.json
            pipeline-status.json
          retention-days: 7
      
      - name: Monitoring summary
        if: always()
        run: |
          echo "ğŸ“Š ëª¨ë‹ˆí„°ë§ ê²°ê³¼ ìš”ì•½"
          echo "===================="
          echo "ì‹œê°„: ${{ steps.context.outputs.timestamp }}"
          echo "ì „ì²´ ìƒíƒœ: ${{ steps.health_check.outputs.status }}"
          echo "ì‹¬ê°ë„: ${{ steps.health_check.outputs.severity }}"
          echo "ì—°ì† ì‹¤íŒ¨: ${{ steps.state.outputs.consecutive_failures }}íšŒ"
          echo "ArgoCD ìƒíƒœ: ${{ steps.argocd_check.outputs.argocd_health }}/${{ steps.argocd_check.outputs.argocd_sync }}"
          echo "ì—”ë“œí¬ì¸íŠ¸ ìƒíƒœ: ${{ steps.endpoint_check.outputs.endpoint_status }}"
          echo "ì‘ë‹µ ì‹œê°„: ${{ steps.endpoint_check.outputs.response_time }}ì´ˆ"
          
          if [ "${{ steps.auto_recovery.outputs.auto_recovery_attempted }}" = "true" ]; then
            echo "ìë™ ë³µêµ¬: ì‹œë„ë¨"
          fi
          
          if [ "${{ steps.critical_alert.outputs.rollback_triggered }}" = "true" ]; then
            echo "ìë™ ë¡¤ë°±: ì‹¤í–‰ë¨"
          fi
          
          echo ""
          echo "ë‹¤ìŒ ê²€ì‚¬: 5ë¶„ í›„ ìë™ ì‹¤í–‰"