#!/usr/bin/env python3
"""
REGTECH Deep Search Collector
ê¹Šì€ íƒìƒ‰ì„ í†µí•œ ì¶”ê°€ ë°ì´í„° ë°œêµ´
- ìˆ¨ê²¨ì§„ API ì—”ë“œí¬ì¸íŠ¸ íƒìƒ‰
- JavaScript ë³€ìˆ˜ì—ì„œ ë°ì´í„° ì¶”ì¶œ  
- ë‹¤ì–‘í•œ menuCode ì‹œë„
- AJAX ìš”ì²­ ë¶„ì„
"""

import os
import re
import json
import requests
import sys
import time
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from dotenv import load_dotenv

sys.path.insert(0, '/home/jclee/app/blacklist')
load_dotenv()

def deep_search_regtech():
    """ê¹Šì€ íƒìƒ‰ìœ¼ë¡œ REGTECH ë°ì´í„° ë°œêµ´"""
    
    username = os.getenv('REGTECH_USERNAME', '')
    password = os.getenv('REGTECH_PASSWORD', '')
    
    if not username or not password:
        print("âŒ REGTECH ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        return []
    
    base_url = "https://regtech.fsec.or.kr"
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
    })
    
    collected_ips = set()  # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ set ì‚¬ìš©
    
    try:
        # 1. ë¡œê·¸ì¸
        print(f"ğŸ” REGTECH ë¡œê·¸ì¸: {username}")
        session.get(f'{base_url}/login/loginForm')
        
        verify_data = {'memberId': username, 'memberPw': password}
        session.headers.update({
            'X-Requested-With': 'XMLHttpRequest',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Content-Type': 'application/x-www-form-urlencoded'
        })
        
        verify_resp = session.post(f"{base_url}/member/findOneMember", data=verify_data)
        if verify_resp.status_code != 200:
            print(f"âŒ ì‚¬ìš©ì í™•ì¸ ì‹¤íŒ¨")
            return []
        
        login_form_data = {
            'username': username, 'password': password, 'login_error': '',
            'txId': '', 'token': '', 'memberId': '', 'smsTimeExcess': 'N'
        }
        
        login_resp = session.post(f"{base_url}/login/addLogin", data=login_form_data, allow_redirects=True)
        if login_resp.status_code != 200 or 'main' not in login_resp.url:
            print("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨")
            return []
        
        print("âœ… ë¡œê·¸ì¸ ì„±ê³µ")
        
        # 2. ê¹Šì€ íƒìƒ‰ ì‹œì‘
        print("\nğŸ” ê¹Šì€ íƒìƒ‰ ì‹œì‘...")
        
        # 2-1. ë‹¤ì–‘í•œ menuCode ì‹œë„
        menu_codes = [
            'HPHB0620101',  # ê¸°ë³¸
            'HPHB0620102', 'HPHB0620103', 'HPHB0620104', 'HPHB0620105',
            'HPHB0610101', 'HPHB0610102', 'HPHB0610103',
            'HPHB0630101', 'HPHB0630102', 'HPHB0630103',
            'THREAT001', 'THREAT002', 'THREAT003',
            'BLACKLIST01', 'BLACKLIST02', 'BLACKLIST03',
            'SECURITY01', 'SECURITY02', 'SECURITY03'
        ]
        
        print(f"ğŸ“‹ ë‹¤ì–‘í•œ menuCode ì‹œë„ ({len(menu_codes)}ê°œ)...")
        for menu_code in menu_codes:
            print(f"  menuCode: {menu_code}")
            
            # Board List ì‹œë„
            try:
                board_url = f"{base_url}/board/boardList"
                board_params = {'menuCode': menu_code, 'pageSize': '1000'}
                board_resp = session.get(board_url, params=board_params)
                
                if board_resp.status_code == 200:
                    soup = BeautifulSoup(board_resp.text, 'html.parser')
                    ips = extract_ips_from_soup(soup)
                    if ips:
                        collected_ips.update(ips)
                        print(f"    Board: {len(ips)}ê°œ ë°œê²¬")
            except Exception as e:
                pass
            
            # Excel Download ì‹œë„
            try:
                excel_url = f"{base_url}/board/excelDownload"
                excel_params = {
                    'menuCode': menu_code,
                    'pageSize': '1000',
                    'startDate': '20240101',
                    'endDate': '20251231'
                }
                excel_resp = session.post(excel_url, data=excel_params)
                
                if excel_resp.status_code == 200:
                    content_type = excel_resp.headers.get('Content-Type', '').lower()
                    if 'excel' in content_type or 'spreadsheet' in content_type:
                        excel_ips = process_excel_response(excel_resp, menu_code)
                        if excel_ips:
                            collected_ips.update(excel_ips)
                            print(f"    Excel: {len(excel_ips)}ê°œ ë°œê²¬")
            except Exception as e:
                pass
        
        # 2-2. API ì—”ë“œí¬ì¸íŠ¸ íƒìƒ‰
        api_endpoints = [
            '/api/blacklist/list',
            '/api/blacklist/search', 
            '/api/threat/list',
            '/api/threat/search',
            '/api/malware/list',
            '/api/security/advisory',
            '/api/fcti/blacklist',
            '/api/fcti/threat',
            '/board/selectIpPoolList',
            '/board/selectBlackList',
            '/board/selectThreatList',
            '/fcti/api/blacklist',
            '/fcti/api/threat',
            '/fcti/api/malware',
            '/threat/api/blacklist',
            '/security/api/blacklist'
        ]
        
        print(f"\nğŸ”Œ API ì—”ë“œí¬ì¸íŠ¸ íƒìƒ‰ ({len(api_endpoints)}ê°œ)...")
        for endpoint in api_endpoints:
            print(f"  API: {endpoint}")
            
            try:
                # GET ì‹œë„
                get_resp = session.get(f"{base_url}{endpoint}")
                if get_resp.status_code == 200:
                    try:
                        data = get_resp.json()
                        ips = extract_ips_from_json(data)
                        if ips:
                            collected_ips.update(ips)
                            print(f"    GET JSON: {len(ips)}ê°œ ë°œê²¬")
                    except:
                        # HTML ì‘ë‹µì¼ ìˆ˜ë„ ìˆìŒ
                        soup = BeautifulSoup(get_resp.text, 'html.parser')
                        ips = extract_ips_from_soup(soup)
                        if ips:
                            collected_ips.update(ips)
                            print(f"    GET HTML: {len(ips)}ê°œ ë°œê²¬")
                
                # POST ì‹œë„ (ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°)
                post_params_list = [
                    {},
                    {'size': '1000', 'page': '1'},
                    {'menuCode': 'HPHB0620101', 'size': '1000'},
                    {'type': 'blacklist', 'limit': '1000'},
                    {'category': 'threat', 'limit': '1000'},
                    {'search': 'ip', 'limit': '1000'}
                ]
                
                for post_params in post_params_list:
                    try:
                        post_resp = session.post(f"{base_url}{endpoint}", data=post_params)
                        if post_resp.status_code == 200:
                            try:
                                data = post_resp.json()
                                ips = extract_ips_from_json(data)
                                if ips:
                                    collected_ips.update(ips)
                                    print(f"    POST JSON: {len(ips)}ê°œ ë°œê²¬")
                            except:
                                soup = BeautifulSoup(post_resp.text, 'html.parser')
                                ips = extract_ips_from_soup(soup)
                                if ips:
                                    collected_ips.update(ips)
                                    print(f"    POST HTML: {len(ips)}ê°œ ë°œê²¬")
                    except:
                        pass
                        
            except Exception as e:
                pass
        
        # 2-3. JavaScript ë³€ìˆ˜ íƒìƒ‰
        print(f"\nğŸ”¬ JavaScript ë³€ìˆ˜ íƒìƒ‰...")
        
        js_pages = [
            '/main/main',
            '/fcti/securityAdvisory/advisoryList',
            '/board/boardList?menuCode=HPHB0620101',
            '/dashboard',
            '/statistics'
        ]
        
        for page_url in js_pages:
            try:
                resp = session.get(f"{base_url}{page_url}")
                if resp.status_code == 200:
                    # JavaScript ë³€ìˆ˜ì—ì„œ IP íŒ¨í„´ ì°¾ê¸°
                    js_ips = extract_ips_from_javascript(resp.text)
                    if js_ips:
                        collected_ips.update(js_ips)
                        print(f"  JS ({page_url}): {len(js_ips)}ê°œ ë°œê²¬")
            except:
                pass
        
        # 2-4. ìˆ¨ê²¨ì§„ í˜ì´ì§€ íƒìƒ‰
        print(f"\nğŸ•µï¸ ìˆ¨ê²¨ì§„ í˜ì´ì§€ íƒìƒ‰...")
        
        hidden_paths = [
            '/admin/blacklist',
            '/admin/threat', 
            '/admin/security',
            '/management/blacklist',
            '/management/threat',
            '/report/blacklist',
            '/report/threat',
            '/data/blacklist',
            '/data/threat',
            '/export/blacklist',
            '/export/threat',
            '/download/blacklist',
            '/download/threat'
        ]
        
        for path in hidden_paths:
            try:
                resp = session.get(f"{base_url}{path}")
                if resp.status_code == 200:
                    soup = BeautifulSoup(resp.text, 'html.parser')
                    ips = extract_ips_from_soup(soup)
                    if ips:
                        collected_ips.update(ips)
                        print(f"  Hidden ({path}): {len(ips)}ê°œ ë°œê²¬")
            except:
                pass
        
        print(f"\nğŸ“Š ê¹Šì€ íƒìƒ‰ ê²°ê³¼: {len(collected_ips)}ê°œ ê³ ìœ  IP")
        
        # IP ë°ì´í„° í˜•ì‹ ë³€í™˜
        ip_data_list = []
        for ip in collected_ips:
            ip_data_list.append({
                "ip": ip,
                "source": "REGTECH",
                "description": "Malicious IP from REGTECH (deep search)",
                "detection_date": datetime.now().strftime('%Y-%m-%d'),
                "confidence": "high"
            })
        
        return ip_data_list
    
    except Exception as e:
        print(f"âŒ ê¹Šì€ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return []
    
    finally:
        session.close()


def extract_ips_from_soup(soup):
    """BeautifulSoupì—ì„œ IP ì¶”ì¶œ"""
    ips = []
    ip_pattern = re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b')
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ì—ì„œ IP ì°¾ê¸°
    all_text = soup.get_text()
    found_ips = ip_pattern.findall(all_text)
    
    for ip in found_ips:
        if is_valid_ip(ip):
            ips.append(ip)
    
    return ips


def extract_ips_from_json(data):
    """JSON ë°ì´í„°ì—ì„œ IP ì¶”ì¶œ"""
    ips = []
    ip_pattern = re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b')
    
    def extract_from_obj(obj):
        if isinstance(obj, dict):
            for key, value in obj.items():
                if isinstance(value, (dict, list)):
                    extract_from_obj(value)
                elif isinstance(value, str):
                    found_ips = ip_pattern.findall(value)
                    for ip in found_ips:
                        if is_valid_ip(ip):
                            ips.append(ip)
        elif isinstance(obj, list):
            for item in obj:
                extract_from_obj(item)
        elif isinstance(obj, str):
            found_ips = ip_pattern.findall(obj)
            for ip in found_ips:
                if is_valid_ip(ip):
                    ips.append(ip)
    
    extract_from_obj(data)
    return ips


def extract_ips_from_javascript(html_text):
    """JavaScript ì½”ë“œì—ì„œ IP ì¶”ì¶œ"""
    ips = []
    ip_pattern = re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b')
    
    # script íƒœê·¸ ë‚´ìš© ì¶”ì¶œ
    script_pattern = re.compile(r'<script[^>]*>(.*?)</script>', re.DOTALL | re.IGNORECASE)
    scripts = script_pattern.findall(html_text)
    
    for script in scripts:
        # JavaScript ë³€ìˆ˜ì—ì„œ IP ì°¾ê¸°
        found_ips = ip_pattern.findall(script)
        for ip in found_ips:
            if is_valid_ip(ip):
                ips.append(ip)
    
    return ips


def is_valid_ip(ip):
    """IP ì£¼ì†Œ ìœ íš¨ì„± ê²€ì‚¬"""
    try:
        octets = ip.split('.')
        if len(octets) != 4:
            return False
        
        for octet in octets:
            num = int(octet)
            if not (0 <= num <= 255):
                return False
        
        # ë¡œì»¬/ì˜ˆì•½ IP ì œì™¸
        if ip.startswith(('127.', '192.168.', '10.', '172.', '0.', '255.')):
            return False
        
        # ë©€í‹°ìºìŠ¤íŠ¸/ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì œì™¸
        first_octet = int(octets[0])
        if first_octet >= 224:
            return False
        
        return True
    
    except:
        return False


def process_excel_response(excel_resp, menu_code):
    """Excel ì‘ë‹µ ì²˜ë¦¬"""
    try:
        import pandas as pd
        
        excel_path = f"/tmp/regtech_excel_{menu_code}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        with open(excel_path, 'wb') as f:
            for chunk in excel_resp.iter_content(chunk_size=8192):
                f.write(chunk)
        
        df = pd.read_excel(excel_path)
        
        ips = []
        ip_pattern = re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b')
        
        for col in df.columns:
            for val in df[col].dropna():
                val_str = str(val)
                found_ips = ip_pattern.findall(val_str)
                
                for ip in found_ips:
                    if is_valid_ip(ip):
                        ips.append(ip)
        
        try:
            os.unlink(excel_path)
        except:
            pass
        
        return ips
    
    except Exception as e:
        return []


def store_collected_data(ip_data_list):
    """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ PostgreSQLì— ì €ì¥"""
    if not ip_data_list:
        return {"success": False, "message": "No data to store"}
    
    try:
        from src.core.data_storage_fixed import FixedDataStorage
        storage = FixedDataStorage()
        result = storage.store_ips(ip_data_list, "REGTECH")
        return result
    except Exception as e:
        return {"success": False, "error": str(e)}


if __name__ == "__main__":
    print("ğŸš€ REGTECH Deep Search Collector")
    print("="*60)
    
    # ê¹Šì€ íƒìƒ‰ ì‹¤í–‰
    ips = deep_search_regtech()
    
    if ips:
        print(f"\nâœ… {len(ips)}ê°œ IP ê¹Šì€ íƒìƒ‰ ì„±ê³µ")
        
        # ì²˜ìŒ 20ê°œ í‘œì‹œ
        print("\nì²˜ìŒ 20ê°œ IP:")
        for i, ip_data in enumerate(ips[:20], 1):
            print(f"  {i:2d}. {ip_data['ip']}")
        
        if len(ips) > 20:
            print(f"  ... ì™¸ {len(ips) - 20}ê°œ")
        
        # PostgreSQLì— ì €ì¥
        result = store_collected_data(ips)
        
        if result.get("success"):
            print(f"\nâœ… PostgreSQL ì €ì¥ ì™„ë£Œ:")
            print(f"  - ì‹ ê·œ ì €ì¥: {result.get('imported_count', 0)}ê°œ")
            print(f"  - ì¤‘ë³µ ì œì™¸: {result.get('duplicate_count', 0)}ê°œ")
            print(f"  - ì „ì²´ DB: {result.get('total_count', 0)}ê°œ")
        else:
            print(f"\nâŒ ì €ì¥ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
    else:
        print("\nâŒ ê¹Šì€ íƒìƒ‰ì—ì„œ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŒ")
    
    print("\nğŸ” ê¹Šì€ íƒìƒ‰ ì™„ë£Œ!")