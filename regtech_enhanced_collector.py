#!/usr/bin/env python3
"""
REGTECH Enhanced Collector
ë” ë§ì€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ê°•í™”ëœ ìˆ˜ì§‘ê¸°
- í™•ì¥ëœ ë‚ ì§œ ë²”ìœ„
- ë‹¤ì¤‘ í˜ì´ì§€ ìˆ˜ì§‘
- ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¡°ê±´
- ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ ì‹œë„
"""

import os
import re
import json
import requests
import sys
import time
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from dotenv import load_dotenv

sys.path.insert(0, '/home/jclee/app/blacklist')
load_dotenv()

def collect_regtech_enhanced():
    """ê°•í™”ëœ REGTECH ë°ì´í„° ìˆ˜ì§‘"""
    
    username = os.getenv('REGTECH_USERNAME', '')
    password = os.getenv('REGTECH_PASSWORD', '')
    
    if not username or not password:
        print("âŒ REGTECH ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        return []
    
    base_url = "https://regtech.fsec.or.kr"
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
    })
    
    collected_ips = []
    
    try:
        # 1. ë¡œê·¸ì¸
        print(f"ğŸ” REGTECH ë¡œê·¸ì¸: {username}")
        session.get(f'{base_url}/login/loginForm')
        
        verify_data = {'memberId': username, 'memberPw': password}
        session.headers.update({
            'X-Requested-With': 'XMLHttpRequest',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Content-Type': 'application/x-www-form-urlencoded'
        })
        
        verify_resp = session.post(f"{base_url}/member/findOneMember", data=verify_data)
        if verify_resp.status_code != 200:
            print(f"âŒ ì‚¬ìš©ì í™•ì¸ ì‹¤íŒ¨: {verify_resp.status_code}")
            return []
        
        login_form_data = {
            'username': username, 'password': password, 'login_error': '',
            'txId': '', 'token': '', 'memberId': '', 'smsTimeExcess': 'N'
        }
        
        login_resp = session.post(f"{base_url}/login/addLogin", data=login_form_data, allow_redirects=True)
        if login_resp.status_code != 200 or 'main' not in login_resp.url:
            print("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨")
            return []
        
        print("âœ… ë¡œê·¸ì¸ ì„±ê³µ")
        
        # 2. ê°•í™”ëœ ë°ì´í„° ìˆ˜ì§‘
        print("\nğŸ” ê°•í™”ëœ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # 2-1. í™•ì¥ëœ ë‚ ì§œ ë²”ìœ„ (6ê°œì›”)
        date_ranges = [
            (180, "6ê°œì›”"),  # 6ê°œì›”
            (90, "3ê°œì›”"),   # 3ê°œì›”  
            (30, "1ê°œì›”"),   # 1ê°œì›”
            (7, "1ì£¼ì¼")     # 1ì£¼ì¼
        ]
        
        for days_back, period_name in date_ranges:
            print(f"\nğŸ“… {period_name} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days_back)
            
            # ë‹¤ì¤‘ í˜ì´ì§€ ìˆ˜ì§‘ (ìµœëŒ€ 10í˜ì´ì§€)
            for page in range(1, 11):
                print(f"  í˜ì´ì§€ {page}/10...")
                
                # ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¡°ê±´ë“¤
                search_conditions = [
                    {'tabSort': 'blacklist', 'findCondition': 'all', 'size': '100'},
                    {'tabSort': 'blacklist', 'findCondition': 'title', 'size': '100'},
                    {'tabSort': 'threat', 'findCondition': 'all', 'size': '100'},
                    {'tabSort': 'malware', 'findCondition': 'all', 'size': '100'},
                    {'tabSort': 'ip', 'findCondition': 'all', 'size': '100'},
                ]
                
                for condition in search_conditions:
                    page_ips = collect_single_page(
                        session, base_url, start_date, end_date, page, condition
                    )
                    
                    for ip in page_ips:
                        if ip not in collected_ips:
                            collected_ips.append(ip)
                    
                    # ìš”ì²­ ê°„ ì§€ì—°
                    time.sleep(0.5)
                
                # í˜ì´ì§€ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¤‘ë‹¨
                if not page_ips:
                    print(f"    í˜ì´ì§€ {page}ì—ì„œ ë°ì´í„° ì—†ìŒ, ë‹¤ìŒ ê¸°ê°„ìœ¼ë¡œ...")
                    break
        
        # 2-2. ë‹¤ë¥¸ URL ê²½ë¡œë“¤ ì‹œë„
        alternative_urls = [
            '/board/boardList?menuCode=HPHB0620101',
            '/fcti/securityAdvisory/blackListView', 
            '/threat/blacklist/list',
            '/security/advisory/list'
        ]
        
        print(f"\nğŸ” ëŒ€ì²´ URL ê²½ë¡œ ì‹œë„...")
        for url_path in alternative_urls:
            print(f"  ì‹œë„: {url_path}")
            try:
                full_url = f"{base_url}{url_path}"
                resp = session.get(full_url)
                
                if resp.status_code == 200:
                    soup = BeautifulSoup(resp.text, 'html.parser')
                    page_ips = extract_ips_from_soup(soup)
                    
                    for ip in page_ips:
                        if ip not in collected_ips:
                            collected_ips.append(ip)
                    
                    print(f"    ì¶”ê°€ ìˆ˜ì§‘: {len(page_ips)}ê°œ")
            except Exception as e:
                print(f"    ì˜¤ë¥˜: {e}")
        
        # 2-3. Excel ë‹¤ìš´ë¡œë“œ ì‹œë„ (ì—¬ëŸ¬ ë‚ ì§œ ë²”ìœ„)
        print(f"\nğŸ“¥ Excel ë‹¤ìš´ë¡œë“œ ì‹œë„...")
        for days_back, period_name in date_ranges[:3]:  # ìƒìœ„ 3ê°œ ê¸°ê°„ë§Œ
            try:
                end_date = datetime.now()
                start_date = end_date - timedelta(days=days_back)
                
                excel_url = f"{base_url}/board/excelDownload"
                excel_params = {
                    'menuCode': 'HPHB0620101',
                    'startDate': start_date.strftime('%Y%m%d'),
                    'endDate': end_date.strftime('%Y%m%d'),
                    'pageSize': '1000'  # ìµœëŒ€ í¬ê¸°
                }
                
                excel_resp = session.post(excel_url, data=excel_params, stream=True)
                
                if excel_resp.status_code == 200:
                    content_type = excel_resp.headers.get('Content-Type', '').lower()
                    if 'excel' in content_type or 'spreadsheet' in content_type:
                        excel_ips = process_excel_response(excel_resp, period_name)
                        
                        for ip in excel_ips:
                            if ip not in collected_ips:
                                collected_ips.append(ip)
                        
                        print(f"  {period_name} Excel: {len(excel_ips)}ê°œ ì¶”ê°€")
            except Exception as e:
                print(f"  Excel ì˜¤ë¥˜ ({period_name}): {e}")
        
        print(f"\nğŸ“Š ì´ ìˆ˜ì§‘ ê²°ê³¼: {len(collected_ips)}ê°œ IP")
        
        # IP ë°ì´í„° í˜•ì‹ ë³€í™˜
        ip_data_list = []
        for ip in collected_ips:
            ip_data_list.append({
                "ip": ip,
                "source": "REGTECH",
                "description": "Malicious IP from REGTECH (enhanced collection)",
                "detection_date": datetime.now().strftime('%Y-%m-%d'),
                "confidence": "high"
            })
        
        return ip_data_list
    
    except Exception as e:
        print(f"âŒ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return []
    
    finally:
        session.close()


def collect_single_page(session, base_url, start_date, end_date, page, condition):
    """ë‹¨ì¼ í˜ì´ì§€ì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
    try:
        advisory_url = f"{base_url}/fcti/securityAdvisory/advisoryList"
        
        post_data = {
            'page': str(page),
            'rows': condition.get('size', '100'),
            'size': condition.get('size', '100'),
            'startDate': start_date.strftime('%Y%m%d'),
            'endDate': end_date.strftime('%Y%m%d'),
            'tabSort': condition.get('tabSort', 'blacklist'),
            'findCondition': condition.get('findCondition', 'all'),
            'findKeyword': condition.get('findKeyword', '')
        }
        
        session.headers.update({
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Content-Type': 'application/x-www-form-urlencoded'
        })
        
        resp = session.post(advisory_url, data=post_data)
        
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, 'html.parser')
            return extract_ips_from_soup(soup)
        
        return []
    
    except Exception as e:
        print(f"    í˜ì´ì§€ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return []


def extract_ips_from_soup(soup):
    """BeautifulSoup ê°ì²´ì—ì„œ IP ì¶”ì¶œ"""
    ips = []
    ip_pattern = re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b')
    
    # í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
    for row in soup.select('tbody tr, table tr'):
        for cell in row.find_all(['td', 'th']):
            text = cell.get_text(strip=True)
            found_ips = ip_pattern.findall(text)
            
            for ip in found_ips:
                if is_valid_ip(ip):
                    ips.append(ip)
    
    # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œë„ ì°¾ê¸°
    all_text = soup.get_text()
    found_ips = ip_pattern.findall(all_text)
    
    for ip in found_ips:
        if is_valid_ip(ip) and ip not in ips:
            ips.append(ip)
    
    return ips


def is_valid_ip(ip):
    """IP ì£¼ì†Œ ìœ íš¨ì„± ê²€ì‚¬"""
    try:
        octets = ip.split('.')
        if len(octets) != 4:
            return False
        
        for octet in octets:
            num = int(octet)
            if not (0 <= num <= 255):
                return False
        
        # ë¡œì»¬/ì˜ˆì•½ IP ì œì™¸
        if ip.startswith(('127.', '192.168.', '10.', '172.', '0.', '255.')):
            return False
        
        # ë©€í‹°ìºìŠ¤íŠ¸/ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì œì™¸
        first_octet = int(octets[0])
        if first_octet >= 224:  # 224-255ëŠ” íŠ¹ìˆ˜ ìš©ë„
            return False
        
        return True
    
    except:
        return False


def process_excel_response(excel_resp, period_name):
    """Excel ì‘ë‹µ ì²˜ë¦¬"""
    try:
        import pandas as pd
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        excel_path = f"/tmp/regtech_excel_{period_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        with open(excel_path, 'wb') as f:
            for chunk in excel_resp.iter_content(chunk_size=8192):
                f.write(chunk)
        
        # Excel íŒŒì‹±
        df = pd.read_excel(excel_path)
        
        ips = []
        ip_pattern = re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b')
        
        # ëª¨ë“  ì»¬ëŸ¼ì—ì„œ IP ì°¾ê¸°
        for col in df.columns:
            for val in df[col].dropna():
                val_str = str(val)
                found_ips = ip_pattern.findall(val_str)
                
                for ip in found_ips:
                    if is_valid_ip(ip) and ip not in ips:
                        ips.append(ip)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try:
            os.unlink(excel_path)
        except:
            pass
        
        return ips
    
    except Exception as e:
        print(f"Excel ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return []


def store_collected_data(ip_data_list):
    """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ PostgreSQLì— ì €ì¥"""
    if not ip_data_list:
        return {"success": False, "message": "No data to store"}
    
    try:
        from src.core.data_storage_fixed import FixedDataStorage
        storage = FixedDataStorage()
        result = storage.store_ips(ip_data_list, "REGTECH")
        return result
    except Exception as e:
        return {"success": False, "error": str(e)}


if __name__ == "__main__":
    print("ğŸš€ REGTECH Enhanced Collector (ë” ë§ì€ ë°ì´í„°)")
    print("="*60)
    
    # ë°ì´í„° ìˆ˜ì§‘
    ips = collect_regtech_enhanced()
    
    if ips:
        print(f"\nâœ… {len(ips)}ê°œ IP ìˆ˜ì§‘ ì„±ê³µ")
        
        # ì²˜ìŒ 20ê°œ í‘œì‹œ
        print("\nì²˜ìŒ 20ê°œ IP:")
        for i, ip_data in enumerate(ips[:20], 1):
            print(f"  {i:2d}. {ip_data['ip']}")
        
        if len(ips) > 20:
            print(f"  ... ì™¸ {len(ips) - 20}ê°œ")
        
        # PostgreSQLì— ì €ì¥
        result = store_collected_data(ips)
        
        if result.get("success"):
            print(f"\nâœ… PostgreSQL ì €ì¥ ì™„ë£Œ:")
            print(f"  - ì‹ ê·œ ì €ì¥: {result.get('imported_count', 0)}ê°œ")
            print(f"  - ì¤‘ë³µ ì œì™¸: {result.get('duplicate_count', 0)}ê°œ")
            print(f"  - ì „ì²´ DB: {result.get('total_count', 0)}ê°œ")
        else:
            print(f"\nâŒ ì €ì¥ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
    else:
        print("\nâŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŒ")
    
    print("\nê°•í™”ëœ ìˆ˜ì§‘ ì™„ë£Œ!")