#!/usr/bin/env python3
"""
ì‹¤ì œ ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ì†ŒìŠ¤ì—ì„œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ IP ìˆ˜ì§‘
ê³µê°œëœ ìœ„í˜‘ í”¼ë“œì—ì„œ ì‹¤ì œ ì•…ì„± IP ë°ì´í„° ìˆ˜ì§‘
"""
import requests
import json
import logging
import re
import os
from datetime import datetime
import time
from urllib3.exceptions import InsecureRequestWarning

# SSL ê²½ê³  ë¬´ì‹œ
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class RealThreatIPCollector:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.all_ips = set()
        
        # ë°ì´í„° ì €ì¥ ê²½ë¡œ
        script_dir = os.path.dirname(__file__)
        self.data_dir = os.path.join(script_dir, '..', 'data', 'blacklist')
        os.makedirs(self.data_dir, exist_ok=True)
    
    def validate_ip(self, ip):
        """IP ì£¼ì†Œ ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            parts = ip.split('.')
            if len(parts) != 4:
                return False
            
            for part in parts:
                num = int(part)
                if not (0 <= num <= 255):
                    return False
            
            # ë‚´ë¶€ IP ë° íŠ¹ìˆ˜ IP ì œì™¸
            if (ip.startswith('10.') or 
                ip.startswith('192.168.') or
                ip.startswith('172.16.') or ip.startswith('172.17.') or ip.startswith('172.18.') or
                ip.startswith('172.19.') or ip.startswith('172.20.') or ip.startswith('172.21.') or
                ip.startswith('172.22.') or ip.startswith('172.23.') or ip.startswith('172.24.') or
                ip.startswith('172.25.') or ip.startswith('172.26.') or ip.startswith('172.27.') or
                ip.startswith('172.28.') or ip.startswith('172.29.') or ip.startswith('172.30.') or
                ip.startswith('172.31.') or
                ip.startswith('127.') or
                ip.startswith('0.') or
                ip.startswith('169.254.') or
                ip.startswith('224.') or ip.startswith('225.') or ip.startswith('226.') or
                ip.startswith('227.') or ip.startswith('228.') or ip.startswith('229.') or
                ip.startswith('230.') or ip.startswith('231.') or ip.startswith('232.') or
                ip.startswith('233.') or ip.startswith('234.') or ip.startswith('235.') or
                ip.startswith('236.') or ip.startswith('237.') or ip.startswith('238.') or
                ip.startswith('239.') or
                ip == '255.255.255.255'):
                return False
                
            return True
        except ValueError:
            return False
    
    def collect_from_abuse_ch(self):
        """Abuse.ch ìœ„í˜‘ í”¼ë“œì—ì„œ ìˆ˜ì§‘"""
        logger.info("Collecting from Abuse.ch...")
        
        sources = [
            'https://feodotracker.abuse.ch/downloads/ipblocklist.txt',
            'https://sslbl.abuse.ch/blacklist/sslipblacklist.txt',
            'https://urlhaus.abuse.ch/downloads/csv/',
            'https://bazaar.abuse.ch/export/txt/ips/'
        ]
        
        collected = 0
        
        for source in sources:
            try:
                logger.info(f"  Fetching: {source}")
                resp = self.session.get(source, timeout=30)
                
                if resp.status_code == 200:
                    content = resp.text
                    
                    # IP íŒ¨í„´ ì¶”ì¶œ
                    ip_pattern = re.compile(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b')
                    ips = ip_pattern.findall(content)
                    
                    valid_ips = 0
                    for ip in ips:
                        if self.validate_ip(ip):
                            self.all_ips.add(ip)
                            valid_ips += 1
                    
                    logger.info(f"    Added {valid_ips} valid IPs")
                    collected += valid_ips
                    
                    time.sleep(1)  # Rate limiting
                
            except Exception as e:
                logger.error(f"  Error fetching {source}: {e}")
        
        logger.info(f"Abuse.ch total: {collected} IPs")
        return collected
    
    def collect_from_blocklist_de(self):
        """Blocklist.deì—ì„œ ìˆ˜ì§‘"""
        logger.info("Collecting from Blocklist.de...")
        
        sources = [
            'https://lists.blocklist.de/lists/all.txt',
            'https://lists.blocklist.de/lists/ssh.txt',
            'https://lists.blocklist.de/lists/mail.txt',
            'https://lists.blocklist.de/lists/apache.txt',
            'https://lists.blocklist.de/lists/bots.txt'
        ]
        
        collected = 0
        
        for source in sources:
            try:
                logger.info(f"  Fetching: {source}")
                resp = self.session.get(source, timeout=30)
                
                if resp.status_code == 200:
                    lines = resp.text.strip().split('\n')
                    
                    valid_ips = 0
                    for line in lines:
                        line = line.strip()
                        if self.validate_ip(line):
                            self.all_ips.add(line)
                            valid_ips += 1
                    
                    logger.info(f"    Added {valid_ips} valid IPs")
                    collected += valid_ips
                    
                    time.sleep(1)  # Rate limiting
                
            except Exception as e:
                logger.error(f"  Error fetching {source}: {e}")
        
        logger.info(f"Blocklist.de total: {collected} IPs")
        return collected
    
    def collect_from_greensnow(self):
        """GreenSnowì—ì„œ ìˆ˜ì§‘"""
        logger.info("Collecting from GreenSnow...")
        
        try:
            url = 'https://blocklist.greensnow.co/greensnow.txt'
            logger.info(f"  Fetching: {url}")
            
            resp = self.session.get(url, timeout=30)
            
            if resp.status_code == 200:
                lines = resp.text.strip().split('\n')
                
                valid_ips = 0
                for line in lines:
                    line = line.strip()
                    if self.validate_ip(line):
                        self.all_ips.add(line)
                        valid_ips += 1
                
                logger.info(f"    Added {valid_ips} valid IPs")
                logger.info(f"GreenSnow total: {valid_ips} IPs")
                return valid_ips
                
        except Exception as e:
            logger.error(f"  Error fetching GreenSnow: {e}")
        
        return 0
    
    def collect_from_talos(self):
        """Cisco Talosì—ì„œ ìˆ˜ì§‘"""
        logger.info("Collecting from Cisco Talos...")
        
        try:
            url = 'https://www.talosintelligence.com/documents/ip-blacklist'
            logger.info(f"  Fetching: {url}")
            
            resp = self.session.get(url, timeout=30)
            
            if resp.status_code == 200:
                content = resp.text
                
                # IP íŒ¨í„´ ì¶”ì¶œ
                ip_pattern = re.compile(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b')
                ips = ip_pattern.findall(content)
                
                valid_ips = 0
                for ip in ips:
                    if self.validate_ip(ip):
                        self.all_ips.add(ip)
                        valid_ips += 1
                
                logger.info(f"    Added {valid_ips} valid IPs")
                logger.info(f"Talos total: {valid_ips} IPs")
                return valid_ips
                
        except Exception as e:
            logger.error(f"  Error fetching Talos: {e}")
        
        return 0
    
    def collect_from_spamhaus(self):
        """Spamhaus DROP ë¦¬ìŠ¤íŠ¸ì—ì„œ ìˆ˜ì§‘"""
        logger.info("Collecting from Spamhaus...")
        
        sources = [
            'https://www.spamhaus.org/drop/drop.txt',
            'https://www.spamhaus.org/drop/edrop.txt'
        ]
        
        collected = 0
        
        for source in sources:
            try:
                logger.info(f"  Fetching: {source}")
                resp = self.session.get(source, timeout=30)
                
                if resp.status_code == 200:
                    lines = resp.text.strip().split('\n')
                    
                    valid_ips = 0
                    for line in lines:
                        line = line.strip()
                        # ì£¼ì„ ë¼ì¸ ì œì™¸
                        if line.startswith(';') or not line:
                            continue
                            
                        # CIDR í‘œê¸°ì—ì„œ IP ì¶”ì¶œ
                        if '/' in line:
                            ip = line.split('/')[0].strip()
                        else:
                            ip = line.split()[0].strip() if line.split() else line
                        
                        if self.validate_ip(ip):
                            self.all_ips.add(ip)
                            valid_ips += 1
                    
                    logger.info(f"    Added {valid_ips} valid IPs")
                    collected += valid_ips
                    
                    time.sleep(1)  # Rate limiting
                
            except Exception as e:
                logger.error(f"  Error fetching {source}: {e}")
        
        logger.info(f"Spamhaus total: {collected} IPs")
        return collected
    
    def collect_from_emergingthreats(self):
        """Emerging Threatsì—ì„œ ìˆ˜ì§‘"""
        logger.info("Collecting from Emerging Threats...")
        
        sources = [
            'https://rules.emergingthreats.net/fwrules/emerging-Block-IPs.txt',
            'https://rules.emergingthreats.net/blockrules/compromised-ips.txt'
        ]
        
        collected = 0
        
        for source in sources:
            try:
                logger.info(f"  Fetching: {source}")
                resp = self.session.get(source, timeout=30)
                
                if resp.status_code == 200:
                    content = resp.text
                    
                    # IP íŒ¨í„´ ì¶”ì¶œ
                    ip_pattern = re.compile(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b')
                    ips = ip_pattern.findall(content)
                    
                    valid_ips = 0
                    for ip in ips:
                        if self.validate_ip(ip):
                            self.all_ips.add(ip)
                            valid_ips += 1
                    
                    logger.info(f"    Added {valid_ips} valid IPs")
                    collected += valid_ips
                    
                    time.sleep(1)  # Rate limiting
                
            except Exception as e:
                logger.error(f"  Error fetching {source}: {e}")
        
        logger.info(f"Emerging Threats total: {collected} IPs")
        return collected
    
    def collect_all_sources(self):
        """ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘"""
        logger.info("Starting collection from all threat intelligence sources...")
        
        start_time = time.time()
        
        # ê° ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘
        abuse_ch_count = self.collect_from_abuse_ch()
        blocklist_de_count = self.collect_from_blocklist_de()
        greensnow_count = self.collect_from_greensnow()
        talos_count = self.collect_from_talos()
        spamhaus_count = self.collect_from_spamhaus()
        emerging_threats_count = self.collect_from_emergingthreats()
        
        end_time = time.time()
        
        logger.info(f"\n{'='*60}")
        logger.info(f"THREAT INTELLIGENCE COLLECTION SUMMARY")
        logger.info(f"{'='*60}")
        logger.info(f"Abuse.ch:         {abuse_ch_count:,} IPs")
        logger.info(f"Blocklist.de:     {blocklist_de_count:,} IPs")
        logger.info(f"GreenSnow:        {greensnow_count:,} IPs")
        logger.info(f"Cisco Talos:      {talos_count:,} IPs")
        logger.info(f"Spamhaus:         {spamhaus_count:,} IPs")
        logger.info(f"Emerging Threats: {emerging_threats_count:,} IPs")
        logger.info(f"{'='*60}")
        logger.info(f"TOTAL UNIQUE IPs: {len(self.all_ips):,}")
        logger.info(f"Collection time:  {end_time - start_time:.1f} seconds")
        logger.info(f"{'='*60}")
        
        return len(self.all_ips)
    
    def save_blacklist_data(self):
        """ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë°ì´í„° ì €ì¥"""
        if not self.all_ips:
            logger.error("No IPs to save")
            return False
        
        # í˜„ì¬ ì›” ë””ë ‰í† ë¦¬ ìƒì„±
        current_month = datetime.now().strftime("%Y_%m")
        month_dir = os.path.join(self.data_dir, f"by_detection_month/{current_month}")
        os.makedirs(month_dir, exist_ok=True)
        
        # ì›”ë³„ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì €ì¥
        monthly_file = os.path.join(month_dir, "blacklist.txt")
        with open(monthly_file, 'w') as f:
            for ip in sorted(self.all_ips):
                f.write(f"{ip}\n")
        
        # ì „ì²´ í™œì„± ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì €ì¥
        all_active_file = os.path.join(self.data_dir, "all_ips.txt")
        with open(all_active_file, 'w') as f:
            for ip in sorted(self.all_ips):
                f.write(f"{ip}\n")
        
        # í†µê³„ íŒŒì¼ ì—…ë°ì´íŠ¸
        stats_file = os.path.join(os.path.dirname(self.data_dir), "stats.json")
        stats = {
            "last_update": datetime.now().isoformat(),
            "total_ips": len(self.all_ips),
            "current_month_ips": len(self.all_ips),
            "update_count": 1,
            "sources": [
                "Abuse.ch",
                "Blocklist.de", 
                "GreenSnow",
                "Cisco Talos",
                "Spamhaus",
                "Emerging Threats"
            ]
        }
        
        with open(stats_file, 'w') as f:
            json.dump(stats, f, indent=2)
        
        logger.info(f"\nReal threat intelligence data saved:")
        logger.info(f"  - Monthly file: {monthly_file}")
        logger.info(f"  - All active:   {all_active_file}")
        logger.info(f"  - Statistics:   {stats_file}")
        
        # ìƒ˜í”Œ IP ì¶œë ¥
        sample_ips = list(sorted(self.all_ips))[:20]
        logger.info(f"\nSample threat IPs:")
        for i, ip in enumerate(sample_ips, 1):
            logger.info(f"  {i:2d}. {ip}")
        
        if len(self.all_ips) > 20:
            logger.info(f"  ... and {len(self.all_ips) - 20:,} more")
        
        return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("="*60)
    logger.info("REAL THREAT INTELLIGENCE BLACKLIST COLLECTOR")
    logger.info("="*60)
    
    collector = RealThreatIPCollector()
    
    # ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
    total_ips = collector.collect_all_sources()
    
    if total_ips > 0:
        # ë°ì´í„° ì €ì¥
        if collector.save_blacklist_data():
            logger.info(f"\nâœ… SUCCESS: {total_ips:,} real threat IPs collected and saved!")
            return True
        else:
            logger.error("âŒ FAILED: Could not save collected data")
            return False
    else:
        logger.error("âŒ FAILED: No threat IPs collected")
        return False

if __name__ == "__main__":
    if main():
        print("\nğŸ¯ ì‹¤ì œ ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ!")
    else:
        print("\nğŸ’¥ ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")