#!/usr/bin/env python3
"""
REGTECH ë‚ ì§œ ë²”ìœ„ ê¸°ë°˜ ìˆ˜ì§‘ê¸° - START DATE ê¸°ì¤€ 3ê°œì›” ë‹¨ìœ„ ì¬ì¡°íšŒ
REGTECH ì‹œìŠ¤í…œì˜ 3ê°œì›” ì œì•½ì‚¬í•­ì— ë§ì¶° ìµœì í™”ëœ ìˆ˜ì§‘ê¸°

íŠ¹ì§•:
- START DATE ê¸°ì¤€ìœ¼ë¡œ 3ê°œì›” ë‹¨ìœ„ ìë™ ë¶„í• 
- ê° 3ê°œì›” êµ¬ê°„ì„ 1ê°œì›”ì”© ì„¸ë¶„í™”í•˜ì—¬ ìˆ˜ì§‘
- ê¸°ì¡´ ìˆ˜ì§‘ ë°ì´í„°ì™€ ì¤‘ë³µ ì œê±°
- ìë™ ì¬ì‹œë„ ë° ì˜¤ë¥˜ ë³µêµ¬

ì‚¬ìš©ë²•:
    python3 regtech_date_range_collector.py --start-date 2024-01-01 --end-date 2024-12-31
    python3 regtech_date_range_collector.py --start-date 2024-01-01 --months 6
"""

import os
import sys
import re
import time
import json
import argparse
import requests
from pathlib import Path
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from bs4 import BeautifulSoup
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from urllib.parse import urljoin
import uuid

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent.parent))

class REGTECHDateRangeCollector:
    """REGTECH ë‚ ì§œ ë²”ìœ„ ê¸°ë°˜ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, output_dir="data/sources/regtech"):
        self.base_url = "https://regtech.fsec.or.kr"
        self.advisorylist_url = f"{self.base_url}/fcti/securityAdvisory/advisoryList"
        self.blacklistview_url = f"{self.base_url}/fcti/securityAdvisory/blackListView"
        
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ìˆ˜ì§‘ í†µê³„
        self.collected_ips = []
        self.collection_stats = {
            'total_date_ranges': 0,
            'processed_ranges': 0,
            'total_ips': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'duplicates_removed': 0,
            'start_time': None,
            'end_time': None,
            'date_ranges': []
        }
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self.lock = threading.Lock()
        
        # ì„¸ì…˜ ì„¤ì •
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        
        # ê¸°ì¡´ ìˆ˜ì§‘ ë°ì´í„° ìºì‹œ (ì¤‘ë³µ ì œê±°ìš©)
        self.existing_ips = set()
        self.load_existing_data()
    
    def load_existing_data(self):
        """ê¸°ì¡´ ìˆ˜ì§‘ ë°ì´í„° ë¡œë“œí•˜ì—¬ ì¤‘ë³µ ì œê±°"""
        print("ğŸ“‚ ê¸°ì¡´ ìˆ˜ì§‘ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # data/sources/regtech/ í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ í™•ì¸
        for json_file in self.output_dir.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                if 'blacklist_data' in data:
                    for item in data['blacklist_data']:
                        if 'ip' in item:
                            self.existing_ips.add(item['ip'])
                elif isinstance(data, list):
                    for item in data:
                        if 'ip' in item:
                            self.existing_ips.add(item['ip'])
                elif 'ips' in data:
                    for item in data['ips']:
                        if 'ip' in item:
                            self.existing_ips.add(item['ip'])
                            
            except Exception as e:
                print(f"âš ï¸ {json_file} ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        print(f"âœ… ê¸°ì¡´ IP ë°ì´í„° {len(self.existing_ips):,}ê°œ ë¡œë“œ ì™„ë£Œ")
    
    def generate_date_ranges(self, start_date, end_date):
        """3ê°œì›” ë‹¨ìœ„ë¡œ ë‚ ì§œ ë²”ìœ„ ìƒì„±"""
        date_ranges = []
        current_start = start_date
        
        while current_start < end_date:
            # 3ê°œì›” í›„ ë‚ ì§œ ê³„ì‚°
            quarter_end = min(current_start + relativedelta(months=3), end_date)
            
            # 3ê°œì›” êµ¬ê°„ì„ 1ê°œì›”ì”© ì„¸ë¶„í™”
            monthly_ranges = []
            month_start = current_start
            
            while month_start < quarter_end:
                month_end = min(month_start + relativedelta(months=1), quarter_end)
                monthly_ranges.append({
                    'start': month_start,
                    'end': month_end,
                    'label': f"{month_start.strftime('%Y-%m')}_{month_end.strftime('%Y-%m')}"
                })
                month_start = month_end
            
            # 3ê°œì›” êµ¬ê°„ ì¶”ê°€
            date_ranges.append({
                'quarter_start': current_start,
                'quarter_end': quarter_end,
                'quarter_label': f"{current_start.strftime('%Y-%m')}_{quarter_end.strftime('%Y-%m')}",
                'monthly_ranges': monthly_ranges
            })
            
            current_start = quarter_end
        
        return date_ranges
    
    def collect_date_range(self, start_date, end_date, label=""):
        """íŠ¹ì • ë‚ ì§œ ë²”ìœ„ì˜ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            print(f"ğŸ“… ìˆ˜ì§‘ ì‹œì‘: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')} ({label})")
            
            start_date_str = start_date.strftime('%Y%m%d')
            end_date_str = end_date.strftime('%Y%m%d')
            
            # ì²« ë²ˆì§¸ í˜ì´ì§€ë¡œ ì´ ê°œìˆ˜ í™•ì¸
            initial_response = self.session.post(self.advisorylist_url, data={
                'page': '0',
                'size': '50',
                'tabSort': 'blacklist',
                'startDate': start_date_str,
                'endDate': end_date_str,
                'findCondition': 'all'
            }, timeout=30)
            
            if initial_response.status_code != 200:
                print(f"âŒ ì´ˆê¸° ìš”ì²­ ì‹¤íŒ¨: HTTP {initial_response.status_code}")
                return []
            
            soup = BeautifulSoup(initial_response.text, 'html.parser')
            
            # ì´ ê°œìˆ˜ í™•ì¸
            total_count = 0
            total_text = soup.find('span', class_='total_num')
            if total_text:
                total_match = re.search(r'ì´\s*(\d+)', total_text.get_text())
                if total_match:
                    total_count = int(total_match.group(1).replace(',', ''))
            
            if total_count == 0:
                print(f"ğŸ“Š {label}: ë°ì´í„° ì—†ìŒ")
                return []
            
            print(f"ğŸ“Š {label}: ì´ {total_count:,}ê°œ í•­ëª© ë°œê²¬")
            
            # í˜ì´ì§€ ìˆ˜ ê³„ì‚°
            page_size = 50
            total_pages = (total_count + page_size - 1) // page_size
            
            # ëª¨ë“  í˜ì´ì§€ ìˆ˜ì§‘
            range_ips = []
            for page_num in range(total_pages):
                page_ips = self.extract_ips_from_page(page_num, page_size, start_date_str, end_date_str)
                range_ips.extend(page_ips)
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress = ((page_num + 1) / total_pages) * 100
                print(f"ğŸ“ˆ {label} ì§„í–‰ë¥ : {progress:.1f}% ({page_num + 1}/{total_pages} í˜ì´ì§€)")
                
                # ìš”ì²­ ê°„ê²©
                time.sleep(0.2)
            
            # ì¤‘ë³µ ì œê±°
            unique_ips = []
            for ip_data in range_ips:
                if ip_data['ip'] not in self.existing_ips:
                    unique_ips.append(ip_data)
                    self.existing_ips.add(ip_data['ip'])
                else:
                    with self.lock:
                        self.collection_stats['duplicates_removed'] += 1
            
            print(f"âœ… {label}: {len(unique_ips):,}ê°œ ê³ ìœ  IP ìˆ˜ì§‘ (ì¤‘ë³µ {len(range_ips) - len(unique_ips):,}ê°œ ì œê±°)")
            
            return unique_ips
            
        except Exception as e:
            print(f"âŒ {label} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def extract_ips_from_page(self, page_num, page_size, start_date_str, end_date_str):
        """ë‹¨ì¼ í˜ì´ì§€ì—ì„œ IP ì •ë³´ ì¶”ì¶œ"""
        try:
            post_data = {
                'page': str(page_num),
                'size': str(page_size),
                'tabSort': 'blacklist',
                'startDate': start_date_str,
                'endDate': end_date_str,
                'findCondition': 'all'
            }
            
            response = self.session.post(self.advisorylist_url, data=post_data, timeout=30)
            
            if response.status_code != 200:
                with self.lock:
                    self.collection_stats['failed_requests'] += 1
                return []
            
            with self.lock:
                self.collection_stats['successful_requests'] += 1
            
            soup = BeautifulSoup(response.text, 'html.parser')
            page_ips = []
            
            # IP ì¶”ì¶œ ë¡œì§ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
            links = soup.find_all('a', href=lambda x: x and 'javascript:goView' in x)
            for link in links:
                href = link.get('href', '')
                uuid_match = re.search(r"goView\('([a-f0-9\-]{36})'\)", href)
                if uuid_match:
                    uuid_val = uuid_match.group(1)
                    
                    tr_element = link.find_parent('tr')
                    if tr_element:
                        tr_text = tr_element.get_text()
                        ip_matches = re.findall(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', tr_text)
                        
                        if ip_matches:
                            ip_address = ip_matches[0]
                            
                            # ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                            detail = self.get_ip_details(ip_address, uuid_val)
                            if detail:
                                detail['date_range'] = f"{start_date_str}_{end_date_str}"
                                detail['page'] = page_num
                                page_ips.append(detail)
                            
                            time.sleep(0.1)  # ìš”ì²­ ê°„ê²©
            
            return page_ips
            
        except Exception as e:
            with self.lock:
                self.collection_stats['failed_requests'] += 1
            return []
    
    def get_ip_details(self, ip_address, uuid_val):
        """ê°œë³„ IPì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)"""
        try:
            post_data = {
                'page': '0',
                'tabSort': 'blacklist',
                'ipId': uuid_val,
                'startDate': (datetime.now() - timedelta(days=365)).strftime('%Y%m%d'),
                'endDate': datetime.now().strftime('%Y%m%d'),
                'findCondition': 'all',
                'size': '10'
            }
            
            response = self.session.post(self.blacklistview_url, data=post_data, timeout=20)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                ip_detail = {
                    'ip': ip_address,
                    'uuid': uuid_val,
                    'country': '',
                    'reason': '',
                    'reg_date': '',
                    'exp_date': '',
                    'view_count': 0,
                    'collection_time': datetime.now().isoformat()
                }
                
                # ìƒì„¸ ì •ë³´ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
                detail_table = soup.find('table', class_='tbl')
                if detail_table:
                    rows = detail_table.find_all('tr')
                    for row in rows:
                        cells = row.find_all(['td', 'th'])
                        if len(cells) >= 2:
                            label = cells[0].get_text(strip=True)
                            value = cells[1].get_text(strip=True)
                            
                            if 'êµ­ê°€' in label or 'Country' in label:
                                ip_detail['country'] = value
                            elif 'ë“±ë¡ì‚¬ìœ ' in label or 'Reason' in label:
                                ip_detail['reason'] = value
                            elif 'ë“±ë¡ì¼' in label or 'Registration' in label:
                                date_match = re.search(r'(\d{4})\.(\d{2})\.(\d{2})', value)
                                if date_match:
                                    ip_detail['reg_date'] = f"{date_match.group(1)}-{date_match.group(2)}-{date_match.group(3)}"
                            elif 'í•´ì œì˜ˆì •ì¼' in label or 'Expiry' in label:
                                date_match = re.search(r'(\d{4})\.(\d{2})\.(\d{2})', value)
                                if date_match:
                                    ip_detail['exp_date'] = f"{date_match.group(1)}-{date_match.group(2)}-{date_match.group(3)}"
                            elif 'ì¡°íšŒìˆ˜' in label or 'View' in label:
                                view_match = re.search(r'(\d+)', value)
                                if view_match:
                                    ip_detail['view_count'] = int(view_match.group(1))
                
                # ê¸°ë³¸ê°’ ì„¤ì •
                if not ip_detail['reg_date']:
                    ip_detail['reg_date'] = datetime.now().strftime('%Y-%m-%d')
                if not ip_detail['exp_date']:
                    ip_detail['exp_date'] = (datetime.now() + timedelta(days=90)).strftime('%Y-%m-%d')
                if not ip_detail['country']:
                    ip_detail['country'] = 'UNKNOWN'
                if not ip_detail['reason']:
                    ip_detail['reason'] = 'ë³´ì•ˆ ìœ„í˜‘ íƒì§€'
                
                return ip_detail
            
        except Exception as e:
            print(f"âš ï¸ IP {ip_address} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ì •ë³´ë¼ë„ ë°˜í™˜
        return {
            'ip': ip_address,
            'uuid': uuid_val,
            'country': 'UNKNOWN',
            'reason': 'ë³´ì•ˆ ìœ„í˜‘ íƒì§€',
            'reg_date': datetime.now().strftime('%Y-%m-%d'),
            'exp_date': (datetime.now() + timedelta(days=90)).strftime('%Y-%m-%d'),
            'view_count': 0,
            'collection_time': datetime.now().isoformat()
        }
    
    def collect_by_date_range(self, start_date, end_date):
        """ë‚ ì§œ ë²”ìœ„ ê¸°ë°˜ ì „ì²´ ìˆ˜ì§‘"""
        self.collection_stats['start_time'] = datetime.now()
        
        print(f"ğŸš€ REGTECH ë‚ ì§œ ë²”ìœ„ ìˆ˜ì§‘ ì‹œì‘")
        print(f"ğŸ“… ì „ì²´ ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
        print(f"â° ì‹œì‘ ì‹œê°„: {self.collection_stats['start_time']}")
        print("=" * 70)
        
        # 3ê°œì›” ë‹¨ìœ„ ë‚ ì§œ ë²”ìœ„ ìƒì„±
        date_ranges = self.generate_date_ranges(start_date, end_date)
        self.collection_stats['total_date_ranges'] = len(date_ranges)
        
        print(f"ğŸ“Š ì´ {len(date_ranges)}ê°œ ë¶„ê¸°ë¡œ ë¶„í• :")
        for i, quarter in enumerate(date_ranges):
            print(f"  ë¶„ê¸° {i+1}: {quarter['quarter_label']} ({len(quarter['monthly_ranges'])}ê°œì›”)")
        print()
        
        # ê° 3ê°œì›” ë¶„ê¸°ë³„ ìˆ˜ì§‘
        for quarter_idx, quarter in enumerate(date_ranges):
            print(f"\nğŸƒâ€â™‚ï¸ ë¶„ê¸° {quarter_idx + 1}/{len(date_ranges)} ìˆ˜ì§‘ ì‹œì‘: {quarter['quarter_label']}")
            
            quarter_ips = []
            
            # ë¶„ê¸° ë‚´ ì›”ë³„ ìˆ˜ì§‘
            for month_range in quarter['monthly_ranges']:
                month_ips = self.collect_date_range(
                    month_range['start'], 
                    month_range['end'], 
                    month_range['label']
                )
                quarter_ips.extend(month_ips)
                
                # ì¤‘ê°„ ì €ì¥ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
                if len(quarter_ips) > 1000:
                    self.collected_ips.extend(quarter_ips)
                    quarter_ips = []
            
            self.collected_ips.extend(quarter_ips)
            
            with self.lock:
                self.collection_stats['processed_ranges'] += 1
                self.collection_stats['total_ips'] = len(self.collected_ips)
            
            print(f"âœ… ë¶„ê¸° {quarter_idx + 1} ì™„ë£Œ: ì´ {len(self.collected_ips):,}ê°œ IP ìˆ˜ì§‘")
            
            # ì¤‘ê°„ ì €ì¥
            if (quarter_idx + 1) % 2 == 0:  # 2ë¶„ê¸°ë§ˆë‹¤ ì €ì¥
                self.save_intermediate_results(f"quarter_{quarter_idx + 1}")
        
        self.collection_stats['end_time'] = datetime.now()
        duration = self.collection_stats['end_time'] - self.collection_stats['start_time']
        
        print(f"\nâœ… ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ IP: {len(self.collected_ips):,}ê°œ")
        print(f"ğŸ”„ ì¤‘ë³µ ì œê±°: {self.collection_stats['duplicates_removed']:,}ê°œ")
        print(f"â±ï¸ ì†Œìš” ì‹œê°„: {duration}")
        
        return self.collected_ips
    
    def save_intermediate_results(self, suffix=""):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        if not self.collected_ips:
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"regtech_date_range_{suffix}_{timestamp}.json"
        
        output_file = self.output_dir / filename
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'collection_info': {
                    'timestamp': timestamp,
                    'total_collected': len(self.collected_ips),
                    'collection_stats': self.collection_stats,
                    'data_source': 'regtech.fsec.or.kr',
                    'collection_type': 'date_range_based'
                },
                'blacklist_data': self.collected_ips
            }, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥: {output_file}")
    
    def save_final_results(self):
        """ìµœì¢… ê²°ê³¼ ì €ì¥"""
        if not self.collected_ips:
            print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŒ")
            return None
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON ì €ì¥
        json_file = self.output_dir / f"regtech_date_range_final_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({
                'collection_info': {
                    'timestamp': timestamp,
                    'total_collected': len(self.collected_ips),
                    'collection_stats': self.collection_stats,
                    'data_source': 'regtech.fsec.or.kr',
                    'collection_type': 'date_range_based'
                },
                'blacklist_data': self.collected_ips
            }, f, ensure_ascii=False, indent=2, default=str)
        
        # CSV ì €ì¥
        df = pd.DataFrame(self.collected_ips)
        csv_file = self.output_dir / f"regtech_date_range_final_{timestamp}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        # í†µê³„ ì €ì¥
        stats_file = self.output_dir / f"regtech_date_range_stats_{timestamp}.txt"
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write("REGTECH ë‚ ì§œ ë²”ìœ„ ìˆ˜ì§‘ ê²°ê³¼ ë³´ê³ ì„œ\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"ìˆ˜ì§‘ ì‹œê°„: {self.collection_stats['start_time']} ~ {self.collection_stats['end_time']}\n")
            f.write(f"ì´ ìˆ˜ì§‘ IP: {len(self.collected_ips):,}ê°œ\n")
            f.write(f"ì²˜ë¦¬ëœ ë²”ìœ„: {self.collection_stats['processed_ranges']}/{self.collection_stats['total_date_ranges']}\n")
            f.write(f"ì¤‘ë³µ ì œê±°: {self.collection_stats['duplicates_removed']:,}ê°œ\n")
            f.write(f"ì„±ê³µ ìš”ì²­: {self.collection_stats['successful_requests']}\n")
            f.write(f"ì‹¤íŒ¨ ìš”ì²­: {self.collection_stats['failed_requests']}\n")
        
        print(f"ğŸ’¾ ìµœì¢… ì €ì¥ ì™„ë£Œ:")
        print(f"  ğŸ“„ JSON: {json_file}")
        print(f"  ğŸ“Š CSV: {csv_file}")
        print(f"  ğŸ“‹ í†µê³„: {stats_file}")
        
        return json_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="REGTECH ë‚ ì§œ ë²”ìœ„ ê¸°ë°˜ ìˆ˜ì§‘ê¸° - START DATE ê¸°ì¤€ 3ê°œì›” ë‹¨ìœ„ ì¬ì¡°íšŒ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python3 regtech_date_range_collector.py --start-date 2024-01-01 --end-date 2024-12-31
  python3 regtech_date_range_collector.py --start-date 2024-01-01 --months 6
  python3 regtech_date_range_collector.py --start-date 2023-06-01 --months 12
        """
    )
    
    parser.add_argument('--start-date', type=str, required=True,
                       help='ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)')
    parser.add_argument('--end-date', type=str, default=None,
                       help='ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)')
    parser.add_argument('--months', type=int, default=None,
                       help='ì‹œì‘ ë‚ ì§œë¶€í„° ìˆ˜ì§‘í•  ê°œì›” ìˆ˜')
    parser.add_argument('--output-dir', type=str, default="data/sources/regtech",
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data/sources/regtech)')
    
    args = parser.parse_args()
    
    # ë‚ ì§œ íŒŒì‹±
    try:
        start_date = datetime.strptime(args.start_date, '%Y-%m-%d')
    except ValueError:
        print("âŒ ì‹œì‘ ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return
    
    # ì¢…ë£Œ ë‚ ì§œ ê³„ì‚°
    if args.end_date:
        try:
            end_date = datetime.strptime(args.end_date, '%Y-%m-%d')
        except ValueError:
            print("âŒ ì¢…ë£Œ ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return
    elif args.months:
        end_date = start_date + relativedelta(months=args.months)
    else:
        print("âŒ --end-date ë˜ëŠ” --months ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        return
    
    # ë‚ ì§œ ê²€ì¦
    if start_date >= end_date:
        print("âŒ ì‹œì‘ ë‚ ì§œê°€ ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤.")
        return
    
    if end_date > datetime.now():
        end_date = datetime.now()
        print(f"âš ï¸ ì¢…ë£Œ ë‚ ì§œë¥¼ í˜„ì¬ ë‚ ì§œë¡œ ì¡°ì •: {end_date.strftime('%Y-%m-%d')}")
    
    print("ğŸš€ REGTECH ë‚ ì§œ ë²”ìœ„ ìˆ˜ì§‘ê¸° ì‹œì‘")
    print("=" * 70)
    print(f"ì„¤ì •ê°’:")
    print(f"  - ì‹œì‘ ë‚ ì§œ: {start_date.strftime('%Y-%m-%d')}")
    print(f"  - ì¢…ë£Œ ë‚ ì§œ: {end_date.strftime('%Y-%m-%d')}")
    print(f"  - ì´ ê¸°ê°„: {(end_date - start_date).days}ì¼")
    print(f"  - ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output_dir}")
    print("=" * 70)
    
    # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    collector = REGTECHDateRangeCollector(output_dir=args.output_dir)
    
    try:
        # ë°ì´í„° ìˆ˜ì§‘
        collected_data = collector.collect_by_date_range(start_date, end_date)
        
        if collected_data:
            # ê²°ê³¼ ì €ì¥
            result_file = collector.save_final_results()
            
            print(f"\nğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ!")
            print(f"ğŸ“Š ì´ {len(collected_data):,}ê°œ IP ìˆ˜ì§‘")
            print(f"ğŸ’¾ ê²°ê³¼ íŒŒì¼: {result_file}")
        else:
            print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        if collector.collected_ips:
            print(f"ğŸ“Š í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ë°ì´í„°: {len(collector.collected_ips)}ê°œ")
            collector.save_intermediate_results("interrupted")
    except Exception as e:
        print(f"âŒ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if collector.collected_ips:
            print(f"ğŸ“Š í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ë°ì´í„°: {len(collector.collected_ips)}ê°œ")
            collector.save_intermediate_results("error")

if __name__ == "__main__":
    main()