#!/usr/bin/env python3
"""
HAR ë¶„ì„ ê¸°ë°˜ REGTECH ì§ì ‘ ìˆ˜ì§‘
ì¸ì¦ ì—†ì´ Excel ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸ í™œìš©
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

import requests
import pandas as pd
import json
import re
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any
import tempfile

class RegtechDirectCollector:
    """HAR ë¶„ì„ ê¸°ë°˜ ì§ì ‘ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.base_url = "https://regtech.fsec.or.kr"
        self.excel_endpoint = "/fcti/securityAdvisory/advisoryListDownloadXlsx"
        self.session = requests.Session()
        
        # HARì—ì„œ ì¶”ì¶œí•œ í—¤ë” ì„¤ì •
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'sec-ch-ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"'
        })
    
    def collect_blacklist_data(self, start_date: str = None, end_date: str = None, max_size: int = 5000) -> Dict[str, Any]:
        """
        HAR ê¸°ë°˜ ì§ì ‘ ë°ì´í„° ìˆ˜ì§‘
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD) 
            max_size: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜
        """
        print("ğŸš€ REGTECH ì§ì ‘ ìˆ˜ì§‘ ì‹œì‘ (HAR ê¸°ë°˜)")
        
        # ê¸°ë³¸ ë‚ ì§œ ì„¤ì • (ìµœê·¼ 3ê°œì›”)
        if not end_date:
            end_date = datetime.now().strftime('%Y%m%d')
        if not start_date:
            start_date = (datetime.now() - timedelta(days=90)).strftime('%Y%m%d')
        
        print(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")
        
        # ì„¸ì…˜ ì´ˆê¸°í™” ë° ë©”ì¸ í˜ì´ì§€ ì ‘ì†
        try:
            print("ğŸ”— ë©”ì¸ í˜ì´ì§€ ì ‘ì† ì¤‘...")
            main_response = self.session.get(f"{self.base_url}/")
            print(f"ğŸ“„ ë©”ì¸ í˜ì´ì§€ ì‘ë‹µ: {main_response.status_code}")
            
            # Advisory ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ì ‘ì† (ì„¸ì…˜ ìœ ì§€ìš©)
            print("ğŸ“‹ Advisory ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ì ‘ì†...")
            advisory_response = self.session.get(f"{self.base_url}/fcti/securityAdvisory/advisoryList")
            print(f"ğŸ“„ Advisory í˜ì´ì§€ ì‘ë‹µ: {advisory_response.status_code}")
            
        except Exception as e:
            print(f"âš ï¸ ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # HARì—ì„œ ì¶”ì¶œí•œ ì •í™•í•œ íŒŒë¼ë¯¸í„° (Document ë¶„ì„ ê²°ê³¼ ì ìš©)
        form_data = {
            'page': '0',
            'tabSort': 'blacklist',  # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë°ì´í„°ë§Œ
            'excelDownload': 'security,blacklist,weakpoint,',
            'cveId': '',
            'ipId': '',
            'estId': '',
            'startDate': start_date,
            'endDate': end_date,
            'findCondition': 'all',
            'findKeyword': '',
            'excelDown': 'blacklist',  # ë¸”ë™ë¦¬ìŠ¤íŠ¸ë§Œ ì„ íƒ
            'size': str(max_size)
        }
        
        # Document ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ì •í™•í•œ í—¤ë”
        headers = {
            'Content-Type': 'application/x-www-form-urlencoded',
            'Origin': self.base_url,
            'Referer': f"{self.base_url}/fcti/securityAdvisory/advisoryList",
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin',
            'Sec-Fetch-User': '?1',
            'Upgrade-Insecure-Requests': '1'
        }
        
        try:
            print("ğŸ“¡ Excel ë‹¤ìš´ë¡œë“œ ìš”ì²­ ì¤‘...")
            response = self.session.post(
                f"{self.base_url}{self.excel_endpoint}",
                data=form_data,
                headers=headers,
                timeout=60,
                stream=True
            )
            
            print(f"ğŸ“Š ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            print(f"ğŸ“ Content-Type: {response.headers.get('Content-Type', 'N/A')}")
            print(f"ğŸ“ Content-Disposition: {response.headers.get('Content-Disposition', 'N/A')}")
            print(f"ğŸ”— ìµœì¢… URL: {response.url}")
            
            if response.status_code == 200:
                return self._process_response(response, start_date, end_date)
            else:
                return {
                    'success': False,
                    'error': f'HTTP {response.status_code}',
                    'response_text': response.text[:500],
                    'final_url': response.url
                }
                
        except Exception as e:
            print(f"âŒ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _process_response(self, response: requests.Response, start_date: str, end_date: str) -> Dict[str, Any]:
        """ì‘ë‹µ ì²˜ë¦¬ ë° ë°ì´í„° ì¶”ì¶œ"""
        
        content_type = response.headers.get('Content-Type', '').lower()
        content_disp = response.headers.get('Content-Disposition', '')
        
        if 'excel' in content_type or 'spreadsheet' in content_type or 'filename=' in content_disp:
            print("ğŸ“‹ Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ!")
            return self._parse_excel_data(response.content, start_date, end_date)
        
        elif 'text/html' in content_type:
            print("ğŸ” HTML ì‘ë‹µ - IP ë°ì´í„° ì¶”ì¶œ ì‹œë„")
            return self._parse_html_data(response.text, start_date, end_date)
        
        elif 'application/json' in content_type:
            print("ğŸ“Š JSON ì‘ë‹µ ì²˜ë¦¬")
            return self._parse_json_data(response.text, start_date, end_date)
        
        else:
            print(f"â“ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ í˜•ì‹: {content_type}")
            return {
                'success': False,
                'error': 'Unknown response format',
                'content_type': content_type,
                'content_preview': response.text[:500]
            }
    
    def _parse_excel_data(self, excel_content: bytes, start_date: str, end_date: str) -> Dict[str, Any]:
        """Excel íŒŒì¼ì—ì„œ IP ë°ì´í„° ì¶”ì¶œ"""
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                tmp_file.write(excel_content)
                tmp_path = tmp_file.name
            
            print(f"ğŸ“ ì„ì‹œ íŒŒì¼ ì €ì¥: {tmp_path}")
            
            # Excel íŒŒì¼ ì½ê¸°
            df = pd.read_excel(tmp_path)
            print(f"ğŸ“Š Excel ë°ì´í„°: {len(df)} í–‰, {len(df.columns)} ì—´")
            print(f"ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}")
            
            # IP ë°ì´í„° ì¶”ì¶œ
            ip_data = self._extract_ips_from_dataframe(df)
            
            # íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_dir = Path(__file__).parent.parent.parent / 'data' / 'regtech'
            output_dir.mkdir(parents=True, exist_ok=True)
            
            excel_file = output_dir / f'regtech_excel_{timestamp}.xlsx'
            json_file = output_dir / f'regtech_data_{timestamp}.json'
            
            # ì›ë³¸ Excel ì €ì¥
            with open(excel_file, 'wb') as f:
                f.write(excel_content)
            
            # JSONìœ¼ë¡œ ì €ì¥
            result_data = {
                'collection_date': timestamp,
                'period': f"{start_date}_{end_date}",
                'source_method': 'direct_excel',
                'total_records': len(df),
                'ip_count': len(ip_data),
                'data': ip_data
            }
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_path)
            
            print(f"âœ… ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(ip_data)}ê°œ IP")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {json_file}")
            
            return {
                'success': True,
                'method': 'excel_download',
                'total_records': len(df),
                'ip_count': len(ip_data),
                'data': ip_data,
                'files': {
                    'excel': str(excel_file),
                    'json': str(json_file)
                }
            }
            
        except Exception as e:
            print(f"âŒ Excel íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': f'Excel parsing failed: {e}'
            }
    
    def _parse_html_data(self, html_content: str, start_date: str, end_date: str) -> Dict[str, Any]:
        """HTMLì—ì„œ IP ë°ì´í„° ì¶”ì¶œ"""
        
        # ë¡œê·¸ì¸ í˜ì´ì§€ í™•ì¸
        if 'ë¡œê·¸ì¸' in html_content or 'login' in html_content.lower():
            print("âŒ ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¨")
            return {
                'success': False,
                'error': 'Redirected to login page',
                'requires_auth': True
            }
        
        # IP íŒ¨í„´ ì°¾ê¸°
        ip_pattern = r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b'
        ips = re.findall(ip_pattern, html_content)
        
        # í…Œì´ë¸” ë°ì´í„° ì°¾ê¸°
        table_pattern = r'<table[^>]*>.*?</table>'
        tables = re.findall(table_pattern, html_content, re.DOTALL)
        
        print(f"ğŸ” ë°œê²¬ëœ IP: {len(set(ips))}ê°œ")
        print(f"ğŸ“Š ë°œê²¬ëœ í…Œì´ë¸”: {len(tables)}ê°œ")
        
        # ê³µì¸ IPë§Œ í•„í„°ë§
        public_ips = []
        for ip in set(ips):
            if self._is_public_ip(ip):
                public_ips.append({
                    'ip': ip,
                    'source': 'REGTECH',
                    'detection_date': datetime.now().strftime('%Y-%m-%d'),
                    'method': 'html_extraction'
                })
        
        return {
            'success': len(public_ips) > 0,
            'method': 'html_extraction',
            'ip_count': len(public_ips),
            'data': public_ips,
            'raw_ips_found': len(ips),
            'tables_found': len(tables)
        }
    
    def _parse_json_data(self, json_text: str, start_date: str, end_date: str) -> Dict[str, Any]:
        """JSON ì‘ë‹µì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        try:
            data = json.loads(json_text)
            print(f"ğŸ“Š JSON ë°ì´í„° êµ¬ì¡°: {list(data.keys()) if isinstance(data, dict) else type(data)}")
            
            # JSONì—ì„œ IP ì¶”ì¶œ ë¡œì§ êµ¬í˜„
            # (ì‹¤ì œ ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ ìˆ˜ì • í•„ìš”)
            
            return {
                'success': True,
                'method': 'json_api',
                'data': data
            }
            
        except json.JSONDecodeError as e:
            return {
                'success': False,
                'error': f'JSON parsing failed: {e}'
            }
    
    def _extract_ips_from_dataframe(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
        """DataFrameì—ì„œ IP ë°ì´í„° ì¶”ì¶œ"""
        ip_data = []
        
        # IP ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
        ip_columns = []
        for col in df.columns:
            col_lower = str(col).lower()
            if any(keyword in col_lower for keyword in ['ip', 'ì•„ì´í”¼', 'addr', 'address']):
                ip_columns.append(col)
        
        print(f"ğŸ” IP ê´€ë ¨ ì»¬ëŸ¼: {ip_columns}")
        
        if not ip_columns:
            # ëª¨ë“  ì»¬ëŸ¼ì—ì„œ IP íŒ¨í„´ ì°¾ê¸°
            ip_pattern = r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b'
            for idx, row in df.iterrows():
                for col in df.columns:
                    cell_value = str(row[col])
                    ips = re.findall(ip_pattern, cell_value)
                    for ip in ips:
                        if self._is_public_ip(ip):
                            ip_data.append({
                                'ip': ip,
                                'source': 'REGTECH',
                                'detection_date': datetime.now().strftime('%Y-%m-%d'),
                                'column': col,
                                'row_index': idx,
                                'method': 'excel_extraction'
                            })
        else:
            # IP ì»¬ëŸ¼ì—ì„œ ì§ì ‘ ì¶”ì¶œ
            for col in ip_columns:
                for idx, ip in enumerate(df[col]):
                    ip_str = str(ip).strip()
                    if self._is_valid_ip(ip_str) and self._is_public_ip(ip_str):
                        ip_data.append({
                            'ip': ip_str,
                            'source': 'REGTECH',
                            'detection_date': datetime.now().strftime('%Y-%m-%d'),
                            'column': col,
                            'row_index': idx,
                            'method': 'excel_extraction',
                            # ë‹¤ë¥¸ ì»¬ëŸ¼ ë°ì´í„°ë„ í¬í•¨
                            'additional_data': {c: str(df.iloc[idx][c]) for c in df.columns if c != col}
                        })
        
        return ip_data
    
    def _is_valid_ip(self, ip: str) -> bool:
        """IP ì£¼ì†Œ ìœ íš¨ì„± ê²€ì¦"""
        try:
            parts = ip.split('.')
            if len(parts) != 4:
                return False
            for part in parts:
                if not (0 <= int(part) <= 255):
                    return False
            return True
        except:
            return False
    
    def _is_public_ip(self, ip: str) -> bool:
        """ê³µì¸ IP ì—¬ë¶€ í™•ì¸"""
        if not self._is_valid_ip(ip):
            return False
        
        parts = ip.split('.')
        first = int(parts[0])
        second = int(parts[1])
        
        # ì‚¬ì„¤ IP ì œì™¸
        if first == 10:
            return False
        if first == 172 and 16 <= second <= 31:
            return False
        if first == 192 and second == 168:
            return False
        if first == 127:
            return False
        if first == 0 or first >= 224:
            return False
        
        return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    collector = RegtechDirectCollector()
    
    # ìµœê·¼ 30ì¼ ë°ì´í„° ìˆ˜ì§‘
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')
    
    result = collector.collect_blacklist_data(start_date, end_date, max_size=5000)
    
    print("\n" + "="*60)
    print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼")
    print("="*60)
    
    if result['success']:
        print(f"âœ… ì„±ê³µ: {result['method']}")
        print(f"ğŸ“Š ì´ ë ˆì½”ë“œ: {result.get('total_records', 'N/A')}")
        print(f"ğŸ¯ IP ê°œìˆ˜: {result.get('ip_count', 0)}")
        
        if 'files' in result:
            print(f"ğŸ“ ì €ì¥ íŒŒì¼:")
            for file_type, file_path in result['files'].items():
                print(f"  - {file_type}: {file_path}")
        
        if result.get('data'):
            print(f"\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„°:")
            for i, item in enumerate(result['data'][:3]):
                print(f"  {i+1}. {item.get('ip', 'N/A')} - {item.get('detection_date', 'N/A')}")
    else:
        print(f"âŒ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
        if 'response_text' in result:
            print(f"ğŸ“ ì‘ë‹µ: {result['response_text']}")

if __name__ == "__main__":
    main()