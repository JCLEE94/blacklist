#!/usr/bin/env python3
"""
REGTECH HAR íŒŒì¼ ì™„ì „ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ëª¨ë“  ìš”ì²­, ì¸ì¦, ì¿ í‚¤, í—¤ë” ì •ë³´ ì¶”ì¶œ
"""
import json
import re
from pathlib import Path
from typing import Dict, List, Any
from urllib.parse import unquote

class HARAnalyzer:
    """HAR íŒŒì¼ ì™„ì „ ë¶„ì„ê¸°"""
    
    def __init__(self, har_file_path: str):
        self.har_file_path = har_file_path
        self.har_data = None
        self.analysis_result = {}
    
    def load_har_file(self) -> bool:
        """HAR íŒŒì¼ ë¡œë“œ"""
        try:
            with open(self.har_file_path, 'r', encoding='utf-8') as f:
                self.har_data = json.load(f)
            print(f"âœ… HAR íŒŒì¼ ë¡œë“œ ì„±ê³µ: {self.har_file_path}")
            return True
        except Exception as e:
            print(f"âŒ HAR íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_complete_structure(self) -> Dict[str, Any]:
        """ì „ì²´ HAR êµ¬ì¡° ì™„ì „ ë¶„ì„"""
        if not self.har_data:
            return {"error": "HAR data not loaded"}
        
        log = self.har_data.get('log', {})
        entries = log.get('entries', [])
        pages = log.get('pages', [])
        
        analysis = {
            "summary": {
                "total_requests": len(entries),
                "total_pages": len(pages),
                "har_version": log.get('version', 'unknown'),
                "creator": log.get('creator', {}),
                "analysis_timestamp": "2025-06-21"
            },
            "pages": [],
            "requests": [],
            "authentication": {
                "cookies_found": [],
                "auth_headers": [],
                "session_tokens": [],
                "csrf_tokens": []
            },
            "regtech_specific": {
                "excel_download_requests": [],
                "login_attempts": [],
                "blacklist_requests": []
            },
            "security_analysis": {
                "cors_headers": [],
                "csrf_protection": [],
                "content_security_policy": []
            }
        }
        
        # í˜ì´ì§€ ë¶„ì„
        for page in pages:
            analysis["pages"].append({
                "id": page.get('id'),
                "title": page.get('title'),
                "started": page.get('startedDateTime'),
                "timing": page.get('pageTimings', {})
            })
        
        # ìš”ì²­ë³„ ìƒì„¸ ë¶„ì„
        for i, entry in enumerate(entries):
            request_analysis = self._analyze_request(entry, i)
            analysis["requests"].append(request_analysis)
            
            # ì¸ì¦ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
            self._extract_authentication_info(entry, analysis["authentication"])
            
            # REGTECH íŠ¹í™” ë¶„ì„
            self._analyze_regtech_specific(entry, analysis["regtech_specific"])
            
            # ë³´ì•ˆ í—¤ë” ë¶„ì„
            self._analyze_security_headers(entry, analysis["security_analysis"])
        
        self.analysis_result = analysis
        return analysis
    
    def _analyze_request(self, entry: Dict, index: int) -> Dict[str, Any]:
        """ê°œë³„ ìš”ì²­ ìƒì„¸ ë¶„ì„"""
        request = entry.get('request', {})
        response = entry.get('response', {})
        
        return {
            "index": index,
            "method": request.get('method'),
            "url": request.get('url'),
            "status": response.get('status'),
            "started_time": entry.get('startedDateTime'),
            "total_time": entry.get('time'),
            "timing_breakdown": entry.get('timings', {}),
            "request_headers": {h['name']: h['value'] for h in request.get('headers', [])},
            "response_headers": {h['name']: h['value'] for h in response.get('headers', [])},
            "request_cookies": request.get('cookies', []),
            "response_cookies": response.get('cookies', []),
            "post_data": request.get('postData', {}),
            "query_string": request.get('queryString', []),
            "server_ip": entry.get('serverIPAddress'),
            "error": response.get('_error'),
            "content_type": response.get('content', {}).get('mimeType'),
            "content_size": response.get('content', {}).get('size', 0)
        }
    
    def _extract_authentication_info(self, entry: Dict, auth_data: Dict):
        """ì¸ì¦ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ"""
        request = entry.get('request', {})
        response = entry.get('response', {})
        
        # ìš”ì²­ ì¿ í‚¤ ê²€ì‚¬
        for cookie in request.get('cookies', []):
            if any(keyword in cookie.get('name', '').lower() 
                   for keyword in ['session', 'jsessionid', 'auth', 'token']):
                auth_data['cookies_found'].append({
                    'name': cookie.get('name'),
                    'value': cookie.get('value'),
                    'domain': cookie.get('domain'),
                    'path': cookie.get('path'),
                    'request_url': request.get('url')
                })
        
        # ì‘ë‹µ ì¿ í‚¤ ê²€ì‚¬
        for cookie in response.get('cookies', []):
            if any(keyword in cookie.get('name', '').lower() 
                   for keyword in ['session', 'jsessionid', 'auth', 'token']):
                auth_data['cookies_found'].append({
                    'name': cookie.get('name'),
                    'value': cookie.get('value'),
                    'domain': cookie.get('domain'),
                    'path': cookie.get('path'),
                    'response_url': request.get('url'),
                    'expires': cookie.get('expires')
                })
        
        # ì¸ì¦ í—¤ë” ê²€ì‚¬
        for header in request.get('headers', []):
            header_name = header.get('name', '').lower()
            if any(keyword in header_name for keyword in ['authorization', 'authentication', 'token']):
                auth_data['auth_headers'].append({
                    'name': header.get('name'),
                    'value': header.get('value'),
                    'url': request.get('url')
                })
        
        # POST ë°ì´í„°ì—ì„œ í† í° ê²€ì‚¬
        post_data = request.get('postData', {})
        if post_data.get('text'):
            # CSRF í† í° ì°¾ê¸°
            csrf_patterns = [r'_token=([^&]+)', r'csrf_token=([^&]+)', r'authenticity_token=([^&]+)']
            for pattern in csrf_patterns:
                matches = re.findall(pattern, post_data.get('text', ''))
                for match in matches:
                    auth_data['csrf_tokens'].append({
                        'token': unquote(match),
                        'url': request.get('url'),
                        'pattern': pattern
                    })
    
    def _analyze_regtech_specific(self, entry: Dict, regtech_data: Dict):
        """REGTECH íŠ¹í™” ë¶„ì„"""
        request = entry.get('request', {})
        url = request.get('url', '')
        
        # Excel ë‹¤ìš´ë¡œë“œ ìš”ì²­
        if 'advisoryListDownloadXlsx' in url:
            post_data = request.get('postData', {})
            regtech_data['excel_download_requests'].append({
                'url': url,
                'method': request.get('method'),
                'post_data': post_data,
                'status': entry.get('response', {}).get('status'),
                'error': entry.get('response', {}).get('_error'),
                'content_disposition': next((h['value'] for h in entry.get('response', {}).get('headers', []) 
                                           if h['name'] == 'Content-Disposition'), None)
            })
        
        # ë¡œê·¸ì¸ ê´€ë ¨ ìš”ì²­
        if any(keyword in url.lower() for keyword in ['login', 'ë¡œê·¸ì¸', 'addLogin']):
            regtech_data['login_attempts'].append({
                'url': url,
                'method': request.get('method'),
                'post_data': request.get('postData', {}),
                'status': entry.get('response', {}).get('status')
            })
        
        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ê´€ë ¨ ìš”ì²­
        if any(keyword in url.lower() for keyword in ['blacklist', 'advisory', 'security']):
            regtech_data['blacklist_requests'].append({
                'url': url,
                'method': request.get('method'),
                'status': entry.get('response', {}).get('status')
            })
    
    def _analyze_security_headers(self, entry: Dict, security_data: Dict):
        """ë³´ì•ˆ í—¤ë” ë¶„ì„"""
        response_headers = entry.get('response', {}).get('headers', [])
        
        for header in response_headers:
            header_name = header.get('name', '').lower()
            header_value = header.get('value', '')
            
            # CORS í—¤ë”
            if 'access-control' in header_name:
                security_data['cors_headers'].append({
                    'name': header.get('name'),
                    'value': header_value,
                    'url': entry.get('request', {}).get('url')
                })
            
            # CSP í—¤ë”
            if 'content-security-policy' in header_name:
                security_data['content_security_policy'].append({
                    'name': header.get('name'),
                    'value': header_value,
                    'url': entry.get('request', {}).get('url')
                })
    
    def generate_comprehensive_report(self) -> str:
        """ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        if not self.analysis_result:
            self.analyze_complete_structure()
        
        report = []
        report.append("=" * 80)
        report.append("ğŸ” REGTECH HAR íŒŒì¼ ì™„ì „ ë¶„ì„ ë³´ê³ ì„œ")
        report.append("=" * 80)
        
        # 1. ìš”ì•½ ì •ë³´
        summary = self.analysis_result['summary']
        report.append(f"\nğŸ“Š ìš”ì•½ ì •ë³´:")
        report.append(f"  - ì´ ìš”ì²­ ìˆ˜: {summary['total_requests']}")
        report.append(f"  - ì´ í˜ì´ì§€ ìˆ˜: {summary['total_pages']}")
        report.append(f"  - HAR ë²„ì „: {summary['har_version']}")
        report.append(f"  - ìƒì„±ì: {summary.get('creator', {}).get('name', 'Unknown')}")
        
        # 2. REGTECH íŠ¹í™” ë¶„ì„
        regtech = self.analysis_result['regtech_specific']
        report.append(f"\nğŸ¯ REGTECH íŠ¹í™” ë¶„ì„:")
        report.append(f"  - Excel ë‹¤ìš´ë¡œë“œ ìš”ì²­: {len(regtech['excel_download_requests'])}ê°œ")
        report.append(f"  - ë¡œê·¸ì¸ ì‹œë„: {len(regtech['login_attempts'])}ê°œ")
        report.append(f"  - ë¸”ë™ë¦¬ìŠ¤íŠ¸ ê´€ë ¨ ìš”ì²­: {len(regtech['blacklist_requests'])}ê°œ")
        
        # 3. Excel ë‹¤ìš´ë¡œë“œ ìƒì„¸ ë¶„ì„
        if regtech['excel_download_requests']:
            report.append(f"\nğŸ“‹ Excel ë‹¤ìš´ë¡œë“œ ìš”ì²­ ìƒì„¸:")
            for i, req in enumerate(regtech['excel_download_requests']):
                report.append(f"  ìš”ì²­ {i+1}:")
                report.append(f"    - URL: {req['url']}")
                report.append(f"    - Method: {req['method']}")
                report.append(f"    - Status: {req['status']}")
                report.append(f"    - Error: {req.get('error', 'None')}")
                report.append(f"    - Content-Disposition: {req.get('content_disposition', 'None')}")
                
                if req.get('post_data'):
                    report.append(f"    - POST íŒŒë¼ë¯¸í„°:")
                    post_params = req['post_data'].get('params', [])
                    for param in post_params:
                        report.append(f"      â€¢ {param.get('name')}: {param.get('value')}")
        
        # 4. ì¸ì¦ ì •ë³´ ë¶„ì„
        auth = self.analysis_result['authentication']
        report.append(f"\nğŸ” ì¸ì¦ ì •ë³´ ë¶„ì„:")
        report.append(f"  - ë°œê²¬ëœ ì¿ í‚¤: {len(auth['cookies_found'])}ê°œ")
        report.append(f"  - ì¸ì¦ í—¤ë”: {len(auth['auth_headers'])}ê°œ")
        report.append(f"  - CSRF í† í°: {len(auth['csrf_tokens'])}ê°œ")
        
        if auth['cookies_found']:
            report.append(f"\nğŸª ë°œê²¬ëœ ì¿ í‚¤:")
            for cookie in auth['cookies_found']:
                report.append(f"    - {cookie['name']}: {cookie.get('value', 'N/A')[:50]}...")
        else:
            report.append(f"\nâŒ ì¸ì¦ ì¿ í‚¤ ì—†ìŒ - ë¹„ì¸ì¦ ì„¸ì…˜ìœ¼ë¡œ ìš”ì²­ë¨")
        
        # 5. ë³´ì•ˆ ë¶„ì„
        security = self.analysis_result['security_analysis']
        report.append(f"\nğŸ›¡ï¸ ë³´ì•ˆ ë¶„ì„:")
        report.append(f"  - CORS í—¤ë”: {len(security['cors_headers'])}ê°œ")
        report.append(f"  - CSP í—¤ë”: {len(security['content_security_policy'])}ê°œ")
        
        # 6. í•µì‹¬ ë°œê²¬ì‚¬í•­
        report.append(f"\nğŸ¯ í•µì‹¬ ë°œê²¬ì‚¬í•­:")
        
        # ì¸ì¦ ìƒíƒœ í™•ì¸
        has_auth_cookies = len(auth['cookies_found']) > 0
        has_csrf_tokens = len(auth['csrf_tokens']) > 0
        
        if not has_auth_cookies:
            report.append(f"  âŒ ì¸ì¦ ì¿ í‚¤ ì—†ìŒ - ë¡œê·¸ì•„ì›ƒ ìƒíƒœì—ì„œ ìš”ì²­")
            report.append(f"  ğŸ’¡ ì´ëŠ” ì¸ì¦ ì—†ì´ë„ Excel ë‹¤ìš´ë¡œë“œê°€ ê°€ëŠ¥í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬")
        
        if regtech['excel_download_requests']:
            excel_req = regtech['excel_download_requests'][0]
            if excel_req.get('error') == 'net::ERR_ABORTED':
                report.append(f"  âš ï¸ Excel ë‹¤ìš´ë¡œë“œ ìš”ì²­ì´ ì¤‘ë‹¨ë¨ (ERR_ABORTED)")
                report.append(f"  ğŸ’¡ ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì¤‘ë‹¨í–ˆê±°ë‚˜ íƒ€ì„ì•„ì›ƒ ë°œìƒ")
            
            if excel_req.get('content_disposition'):
                report.append(f"  âœ… ì„œë²„ì—ì„œ Excel íŒŒì¼ëª… ì‘ë‹µ: {excel_req['content_disposition']}")
                report.append(f"  ğŸ’¡ ì„œë²„ëŠ” íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ ì¤€ë¹„í–ˆìŒ")
        
        # 7. ê¶Œì¥ì‚¬í•­
        report.append(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        
        if not has_auth_cookies:
            report.append(f"  1. ì¸ì¦ ì—†ì´ Excel ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸ ì§ì ‘ í˜¸ì¶œ ì‹œë„")
            report.append(f"  2. POST íŒŒë¼ë¯¸í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ ìš”ì²­")
            report.append(f"  3. ë¸Œë¼ìš°ì € í—¤ë” ì •í™•íˆ ëª¨ë°©")
        
        report.append(f"  4. ìš”ì²­ íƒ€ì„ì•„ì›ƒì„ ì¶©ë¶„íˆ ê¸¸ê²Œ ì„¤ì • (60ì´ˆ ì´ìƒ)")
        report.append(f"  5. stream=Trueë¡œ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬")
        report.append(f"  6. Content-Disposition í—¤ë” í™•ì¸í•˜ì—¬ íŒŒì¼ëª… ì¶”ì¶œ")
        
        return "\n".join(report)
    
    def extract_working_request_code(self) -> str:
        """ì‹¤ì œ ë™ì‘í•˜ëŠ” ìš”ì²­ ì½”ë“œ ìƒì„±"""
        if not self.analysis_result:
            self.analyze_complete_structure()
        
        excel_requests = self.analysis_result['regtech_specific']['excel_download_requests']
        if not excel_requests:
            return "# Excel ë‹¤ìš´ë¡œë“œ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        excel_req = excel_requests[0]
        post_data = excel_req.get('post_data', {})
        params = post_data.get('params', [])
        
        code = []
        code.append("#!/usr/bin/env python3")
        code.append('"""')
        code.append("HAR ë¶„ì„ ê¸°ë°˜ ì‹¤ì œ ë™ì‘í•˜ëŠ” REGTECH ìˆ˜ì§‘ ì½”ë“œ")
        code.append('"""')
        code.append("import requests")
        code.append("from datetime import datetime, timedelta")
        code.append("")
        code.append("def collect_regtech_data():")
        code.append('    """HAR ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì •í™•í•œ ìš”ì²­"""')
        code.append("")
        code.append("    # ê¸°ë³¸ ì„¤ì •")
        code.append('    base_url = "https://regtech.fsec.or.kr"')
        code.append('    endpoint = "/fcti/securityAdvisory/advisoryListDownloadXlsx"')
        code.append("")
        code.append("    # HARì—ì„œ ì¶”ì¶œí•œ ì •í™•í•œ í—¤ë”")
        code.append("    headers = {")
        
        # ì£¼ìš” í—¤ë” ì¶”ì¶œ
        req_headers = self.analysis_result['requests'][0]['request_headers']
        essential_headers = [
            'User-Agent', 'Accept', 'Accept-Encoding', 'Accept-Language',
            'Content-Type', 'Origin', 'Referer', 'Sec-Fetch-Dest',
            'Sec-Fetch-Mode', 'Sec-Fetch-Site', 'Cache-Control', 'Pragma'
        ]
        
        for header_name in essential_headers:
            if header_name in req_headers:
                code.append(f'        "{header_name}": "{req_headers[header_name]}",')
        
        code.append("    }")
        code.append("")
        code.append("    # HARì—ì„œ ì¶”ì¶œí•œ ì •í™•í•œ POST íŒŒë¼ë¯¸í„°")
        code.append("    form_data = {")
        
        for param in params:
            name = param.get('name')
            value = param.get('value')
            if name in ['startDate', 'endDate']:
                if name == 'startDate':
                    code.append(f'        "{name}": (datetime.now() - timedelta(days=90)).strftime("%Y%m%d"),  # 3ê°œì›” ì „')
                else:
                    code.append(f'        "{name}": datetime.now().strftime("%Y%m%d"),  # ì˜¤ëŠ˜')
            else:
                code.append(f'        "{name}": "{value}",')
        
        code.append("    }")
        code.append("")
        code.append("    # ìš”ì²­ ì‹¤í–‰")
        code.append("    session = requests.Session()")
        code.append("    try:")
        code.append("        response = session.post(")
        code.append("            f'{base_url}{endpoint}',")
        code.append("            data=form_data,")
        code.append("            headers=headers,")
        code.append("            timeout=120,  # ì¶©ë¶„í•œ íƒ€ì„ì•„ì›ƒ")
        code.append("            stream=True   # ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬")
        code.append("        )")
        code.append("")
        code.append("        print(f'Status: {response.status_code}')")
        code.append("        print(f'Content-Type: {response.headers.get(\"Content-Type\")}')")
        code.append("        print(f'Content-Disposition: {response.headers.get(\"Content-Disposition\")}')")
        code.append("")
        code.append("        if response.status_code == 200:")
        code.append("            content_type = response.headers.get('Content-Type', '')")
        code.append("            if 'excel' in content_type or 'spreadsheet' in content_type:")
        code.append("                filename = f'regtech_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.xlsx'")
        code.append("                with open(filename, 'wb') as f:")
        code.append("                    f.write(response.content)")
        code.append("                print(f'âœ… Excel íŒŒì¼ ì €ì¥: {filename}')")
        code.append("                return True")
        code.append("            else:")
        code.append("                print(f'âŒ ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ: {response.text[:200]}')")
        code.append("        else:")
        code.append("            print(f'âŒ HTTP ì˜¤ë¥˜: {response.status_code}')")
        code.append("")
        code.append("    except Exception as e:")
        code.append("        print(f'âŒ ìš”ì²­ ì‹¤íŒ¨: {e}')")
        code.append("")
        code.append("    return False")
        code.append("")
        code.append('if __name__ == "__main__":')
        code.append("    collect_regtech_data()")
        
        return "\n".join(code)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    har_file = "/home/jclee/dev/blacklist/document/har_backup/regtech.fsec.or.kr.har"
    
    analyzer = HARAnalyzer(har_file)
    
    if not analyzer.load_har_file():
        return
    
    # ì™„ì „ ë¶„ì„ ì‹¤í–‰
    analysis = analyzer.analyze_complete_structure()
    
    # ë³´ê³ ì„œ ìƒì„±
    report = analyzer.generate_comprehensive_report()
    print(report)
    
    # ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ìƒì„±
    working_code = analyzer.extract_working_request_code()
    
    # ê²°ê³¼ íŒŒì¼ë¡œ ì €ì¥
    output_dir = Path(__file__).parent.parent / 'data' / 'har_analysis'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¶„ì„ ê²°ê³¼ JSON ì €ì¥
    with open(output_dir / 'har_complete_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    
    # ë³´ê³ ì„œ ì €ì¥
    with open(output_dir / 'har_analysis_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    # ì‹¤í–‰ ì½”ë“œ ì €ì¥
    with open(output_dir / 'regtech_har_based_collector.py', 'w', encoding='utf-8') as f:
        f.write(working_code)
    
    print(f"\nğŸ“ ë¶„ì„ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜:")
    print(f"  - ìƒì„¸ ë¶„ì„: {output_dir / 'har_complete_analysis.json'}")
    print(f"  - ë³´ê³ ì„œ: {output_dir / 'har_analysis_report.txt'}")
    print(f"  - ì‹¤í–‰ ì½”ë“œ: {output_dir / 'regtech_har_based_collector.py'}")

if __name__ == "__main__":
    main()