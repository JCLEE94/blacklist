#!/usr/bin/env python3
"""
REGTECH ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ - HAR ë¶„ì„ ê¸°ë°˜ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
"""
import requests
import json
from bs4 import BeautifulSoup
import re
from datetime import datetime, timedelta

def test_regtech_collection():
    """HAR ë¶„ì„ ê¸°ë°˜ ì‹¤ì œ REGTECH ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª REGTECH ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (HAR ë¶„ì„ ê¸°ë°˜)")
    
    # ì„¤ì •
    username = "nextrade"
    password = "Sprtmxm1@3"
    base_url = "https://regtech.fsec.or.kr"
    
    # ë‚ ì§œ ì„¤ì • (ìµœê·¼ 30ì¼)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)
    start_date_str = start_date.strftime('%Y%m%d')
    end_date_str = end_date.strftime('%Y%m%d')
    
    print(f"ë‚ ì§œ ë²”ìœ„: {start_date_str} ~ {end_date_str}")
    
    # ì„¸ì…˜ ìƒì„±
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
    })
    
    try:
        # 1. ë¡œê·¸ì¸ ìˆ˜í–‰
        print("1. ë¡œê·¸ì¸...")
        main_resp = session.get(f"{base_url}/main/main", timeout=30)
        form_resp = session.get(f"{base_url}/login/loginForm", timeout=30)
        
        login_data = {
            'memberId': username,
            'memberPw': password
        }
        
        login_resp = session.post(
            f"{base_url}/login/addLogin",
            data=login_data,
            headers={
                'Content-Type': 'application/x-www-form-urlencoded',
                'Accept': 'application/json, text/javascript, */*; q=0.01',
                'X-Requested-With': 'XMLHttpRequest',
                'Referer': f"{base_url}/login/loginForm"
            },
            timeout=30
        )
        
        if login_resp.status_code != 200:
            print(f"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {login_resp.status_code}")
            return False
        
        print("âœ… ë¡œê·¸ì¸ ì„±ê³µ")
        
        # 2. HAR ë¶„ì„ ê¸°ë°˜ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ìš”ì²­
        print("2. ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ (HAR ë¶„ì„ ê¸°ë°˜)...")
        
        # HARì—ì„œ ë°œê²¬ëœ ì •í™•í•œ POST íŒŒë¼ë¯¸í„° (ì‹¤ì œ ë™ì‘í–ˆë˜ ìš”ì²­ ë³µì‚¬)
        # ì¤‘ë³µ íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì‚¬ìš©
        collection_data = [
            ('page', '0'),
            ('tabSort', 'blacklist'),
            ('excelDownload', ''),
            ('cveId', ''),
            ('ipId', ''),
            ('estId', ''),
            ('startDate', '20250601'),
            ('endDate', '20250630'),
            ('findCondition', 'all'),
            ('findKeyword', ''),
            ('excelDown', 'security'),
            ('excelDown', 'blacklist'),      # ì¤‘ë³µ íŒŒë¼ë¯¸í„°
            ('excelDown', 'weakpoint'),      # ì¤‘ë³µ íŒŒë¼ë¯¸í„°
            ('size', '10')
        ]
        
        # POST ìš”ì²­ (HARì—ì„œ í™•ì¸ëœ ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸)
        collection_resp = session.post(
            f"{base_url}/fcti/securityAdvisory/advisoryList",
            data=collection_data,
            headers={
                'Content-Type': 'application/x-www-form-urlencoded',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Referer': f"{base_url}/fcti/securityAdvisory/advisoryList"
            },
            timeout=30
        )
        
        print(f"ë°ì´í„° ìˆ˜ì§‘ ì‘ë‹µ: {collection_resp.status_code}")
        
        if collection_resp.status_code == 200:
            # 3. BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
            print("3. BeautifulSoup4ë¡œ HTML íŒŒì‹±...")
            soup = BeautifulSoup(collection_resp.text, 'html.parser')
            
            # ì´ ê±´ìˆ˜ ì°¾ê¸°
            total_count_elem = soup.find('em', {'class': 'num'})
            if total_count_elem:
                total_count = total_count_elem.get_text(strip=True)
                print(f"ğŸ“Š ì´ ê±´ìˆ˜: {total_count}")
            
            # í…Œì´ë¸”ì—ì„œ IP ë°ì´í„° ì¶”ì¶œ
            ip_list = []
            
            # ë‹¤ì–‘í•œ í…Œì´ë¸” êµ¬ì¡° í™•ì¸
            tables = soup.find_all('table')
            print(f"ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(tables)}")
            
            for i, table in enumerate(tables):
                rows = table.find_all('tr')
                print(f"í…Œì´ë¸” {i+1}: {len(rows)}ê°œ í–‰")
                
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) > 1:  # í—¤ë”ê°€ ì•„ë‹Œ ë°ì´í„° í–‰
                        row_text = ' '.join([cell.get_text(strip=True) for cell in cells])
                        
                        # IP ì£¼ì†Œ íŒ¨í„´ ì°¾ê¸°
                        ip_pattern = r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b'
                        ips_in_row = re.findall(ip_pattern, row_text)
                        
                        for ip in ips_in_row:
                            if ip not in ip_list and ip != '0.0.0.0':
                                ip_list.append(ip)
                                print(f"   ğŸ“ ë°œê²¬ëœ IP: {ip}")
            
            # í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ IP ê²€ìƒ‰ (í…Œì´ë¸” ì™¸ë¶€ì— ìˆì„ ìˆ˜ ìˆìŒ)
            all_text = soup.get_text()
            all_ips = re.findall(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', all_text)
            
            for ip in all_ips:
                if ip not in ip_list and ip not in ['0.0.0.0', '127.0.0.1']:
                    # ìœ íš¨í•œ ê³µì¸ IPì¸ì§€ í™•ì¸
                    parts = ip.split('.')
                    if (not (parts[0] == '192' and parts[1] == '168') and  # ì‚¬ì„¤ IP ì œì™¸
                        not (parts[0] == '10') and
                        not (parts[0] == '172' and 16 <= int(parts[1]) <= 31) and
                        not parts[0] in ['0', '127', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239']):
                        ip_list.append(ip)
            
            print(f"\nğŸ¯ ìµœì¢… ìˆ˜ì§‘ëœ IP ê°œìˆ˜: {len(ip_list)}")
            if ip_list:
                print("ìƒ˜í”Œ IPë“¤:")
                for ip in ip_list[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
                    print(f"  - {ip}")
                
                if len(ip_list) > 10:
                    print(f"  ... ê·¸ë¦¬ê³  {len(ip_list) - 10}ê°œ ë”")
                
                return True
            else:
                # ì‘ë‹µ ë‚´ìš© ë¶„ì„
                print("\nğŸ” ì‘ë‹µ ë‚´ìš© ë¶„ì„:")
                print(f"ì‘ë‹µ ê¸¸ì´: {len(collection_resp.text)} ë°”ì´íŠ¸")
                
                # ì¤‘ìš”í•œ í‚¤ì›Œë“œ ê²€ìƒ‰
                keywords = ['blacklist', 'ë¸”ë™ë¦¬ìŠ¤íŠ¸', 'IP', 'ìš”ì£¼ì˜', 'ì´', 'table', 'tbody']
                for keyword in keywords:
                    if keyword in collection_resp.text.lower():
                        print(f"  âœ… '{keyword}' í‚¤ì›Œë“œ ë°œê²¬")
                    else:
                        print(f"  âŒ '{keyword}' í‚¤ì›Œë“œ ì—†ìŒ")
                
                # JavaScriptë‚˜ AJAX ì½”ë“œ í™•ì¸
                if 'ajax' in collection_resp.text.lower() or 'json' in collection_resp.text.lower():
                    print("  âš ï¸ AJAX/JSON ì½”ë“œ ë°œê²¬ - ë™ì  ë¡œë”© ê°€ëŠ¥ì„±")
                
                return False
        else:
            print(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {collection_resp.status_code}")
            return False
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_regtech_collection()
    if success:
        print("\nğŸ‰ REGTECH ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ!")
    else:
        print("\nğŸ’¥ REGTECH ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")