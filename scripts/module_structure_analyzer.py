#!/usr/bin/env python3
"""
ëª¨ë“ˆ êµ¬ì¡° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
íŒŒì¼ í¬ê¸°, ì˜ì¡´ì„±, ì‘ì§‘ë„ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡° ìµœì í™” ì œì•ˆ

Sample input: Python í”„ë¡œì íŠ¸ ì†ŒìŠ¤ ë””ë ‰í† ë¦¬
Expected output: ëª¨ë“ˆ êµ¬ì¡° ë¶„ì„ ë³´ê³ ì„œ ë° ìµœì í™” ì œì•ˆ
"""

import ast
import logging
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict, Counter

logger = logging.getLogger(__name__)


class ModuleAnalyzer:
    """ëª¨ë“ˆ êµ¬ì¡° ë¶„ì„ê¸°"""

    def __init__(self):
        self.file_info = {}
        self.dependencies = defaultdict(set)
        self.reverse_dependencies = defaultdict(set)
        self.function_counts = {}
        self.class_counts = {}
        self.complexity_scores = {}

    def analyze_file(self, file_path: Path) -> Dict:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # ê¸°ë³¸ ì •ë³´
            lines = content.split("\n")
            line_count = len(lines)

            # AST íŒŒì‹±ìœ¼ë¡œ êµ¬ì¡° ë¶„ì„
            try:
                tree = ast.parse(content)
                info = self._analyze_ast(tree, content)
            except SyntaxError:
                # êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ìˆëŠ” íŒŒì¼ì€ ê¸°ë³¸ ì •ë³´ë§Œ
                info = {
                    "functions": 0,
                    "classes": 0,
                    "imports": [],
                    "complexity_score": 0,
                }

            # íŒŒì¼ ì •ë³´ ì €ì¥
            file_info = {
                "path": file_path,
                "line_count": line_count,
                "functions": info["functions"],
                "classes": info["classes"],
                "imports": info["imports"],
                "complexity_score": info["complexity_score"],
                "file_size_bytes": (
                    file_path.stat().st_size if file_path.exists() else 0
                ),
            }

            return file_info

        except Exception as e:
            logger.error(f"Error analyzing {file_path}: {e}")
            return {
                "path": file_path,
                "line_count": 0,
                "functions": 0,
                "classes": 0,
                "imports": [],
                "complexity_score": 0,
                "file_size_bytes": 0,
            }

    def _analyze_ast(self, tree: ast.AST, content: str) -> Dict:
        """ASTë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡° ì •ë³´ ì¶”ì¶œ"""
        functions = 0
        classes = 0
        imports = []
        complexity_score = 0

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions += 1
                # ë³µì¡ë„ ê³„ì‚° (ê°„ë‹¨íˆ ì¤‘ì²© ë ˆë²¨ê³¼ ë¶„ê¸°ë¡œ ê³„ì‚°)
                complexity_score += self._calculate_function_complexity(node)

            elif isinstance(node, ast.ClassDef):
                classes += 1
                complexity_score += 2  # í´ë˜ìŠ¤ëŠ” ê¸°ë³¸ ë³µì¡ë„ 2

            elif isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)

            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)

        return {
            "functions": functions,
            "classes": classes,
            "imports": imports,
            "complexity_score": complexity_score,
        }

    def _calculate_function_complexity(self, func_node: ast.FunctionDef) -> int:
        """í•¨ìˆ˜ì˜ ë³µì¡ë„ ê³„ì‚°"""
        complexity = 1  # ê¸°ë³¸ ë³µì¡ë„

        for node in ast.walk(func_node):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.Try, ast.With)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1

        return complexity

    def analyze_dependencies(self, src_path: Path) -> Dict:
        """ì˜ì¡´ì„± ë¶„ì„"""
        python_files = list(src_path.rglob("*.py"))

        for file_path in python_files:
            if any(exclude in str(file_path) for exclude in ["test_", "__pycache__"]):
                continue

            file_info = self.analyze_file(file_path)
            self.file_info[str(file_path)] = file_info

            # ì˜ì¡´ì„± ë§¤í•‘
            relative_path = file_path.relative_to(src_path)
            for import_name in file_info["imports"]:
                # í”„ë¡œì íŠ¸ ë‚´ë¶€ ì˜ì¡´ì„±ë§Œ ì¶”ì  (ìƒëŒ€ import)
                if import_name.startswith(".") or any(
                    part in import_name for part in ["core", "utils", "api"]
                ):
                    self.dependencies[str(relative_path)].add(import_name)
                    self.reverse_dependencies[import_name].add(str(relative_path))

        return {
            "total_files": len(self.file_info),
            "dependencies": dict(self.dependencies),
            "reverse_dependencies": dict(self.reverse_dependencies),
        }

    def find_structure_issues(self) -> Dict[str, List]:
        """êµ¬ì¡°ì  ë¬¸ì œì  ì‹ë³„"""
        issues = {
            "large_files": [],
            "complex_files": [],
            "high_dependency_files": [],
            "circular_dependencies": [],
            "god_objects": [],
            "suggested_splits": [],
        }

        for file_path, info in self.file_info.items():
            # í° íŒŒì¼ (400ì¤„ ì´ìƒ)
            if info["line_count"] > 400:
                issues["large_files"].append(
                    {
                        "file": file_path,
                        "lines": info["line_count"],
                        "functions": info["functions"],
                        "classes": info["classes"],
                    }
                )

            # ë³µì¡í•œ íŒŒì¼ (ë³µì¡ë„ ìŠ¤ì½”ì–´ 50 ì´ìƒ)
            if info["complexity_score"] > 50:
                issues["complex_files"].append(
                    {
                        "file": file_path,
                        "complexity": info["complexity_score"],
                        "functions": info["functions"],
                        "classes": info["classes"],
                    }
                )

            # ì˜ì¡´ì„±ì´ ë§ì€ íŒŒì¼ (10ê°œ ì´ìƒ)
            if len(info["imports"]) > 10:
                issues["high_dependency_files"].append(
                    {
                        "file": file_path,
                        "dependencies": len(info["imports"]),
                        "imports": info["imports"][:5],  # ì²˜ìŒ 5ê°œë§Œ
                    }
                )

            # God Object í›„ë³´ (í´ë˜ìŠ¤ ë§ê³  ë³µì¡ë„ ë†’ìŒ)
            if info["classes"] > 3 and info["complexity_score"] > 30:
                issues["god_objects"].append(
                    {
                        "file": file_path,
                        "classes": info["classes"],
                        "complexity": info["complexity_score"],
                        "lines": info["line_count"],
                    }
                )

            # ë¶„í•  ì œì•ˆ (í•¨ìˆ˜ê°€ ë§ê³  í° íŒŒì¼)
            if info["functions"] > 15 and info["line_count"] > 300:
                issues["suggested_splits"].append(
                    {
                        "file": file_path,
                        "functions": info["functions"],
                        "lines": info["line_count"],
                        "suggestion": f"Consider splitting into {info['functions']//10 + 1} modules",
                    }
                )

        return issues

    def generate_recommendations(self, issues: Dict) -> List[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if issues["large_files"]:
            recommendations.append(
                f"ğŸ“ {len(issues['large_files'])}ê°œì˜ í° íŒŒì¼ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. "
                "ê¸°ëŠ¥ë³„ë¡œ ë¶„í• ì„ ê³ ë ¤í•˜ì„¸ìš”."
            )

        if issues["complex_files"]:
            recommendations.append(
                f"ğŸ”„ {len(issues['complex_files'])}ê°œì˜ ë³µì¡í•œ íŒŒì¼ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. "
                "í•¨ìˆ˜ ë¶„í• ê³¼ ë¦¬íŒ©í† ë§ì„ ê³ ë ¤í•˜ì„¸ìš”."
            )

        if issues["high_dependency_files"]:
            recommendations.append(
                f"ğŸ”— {len(issues['high_dependency_files'])}ê°œì˜ íŒŒì¼ì´ ê³¼ë„í•œ ì˜ì¡´ì„±ì„ ê°€ì§‘ë‹ˆë‹¤. "
                "ì˜ì¡´ì„± ì£¼ì…ì´ë‚˜ ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”."
            )

        if issues["god_objects"]:
            recommendations.append(
                f"ğŸ‘¹ {len(issues['god_objects'])}ê°œì˜ God Object í›„ë³´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. "
                "ë‹¨ì¼ ì±…ì„ ì›ì¹™ì— ë”°ë¼ í´ë˜ìŠ¤ë¥¼ ë¶„í• í•˜ì„¸ìš”."
            )

        if issues["suggested_splits"]:
            recommendations.append(
                f"âœ‚ï¸ {len(issues['suggested_splits'])}ê°œì˜ íŒŒì¼ì´ ë¶„í•  í›„ë³´ì…ë‹ˆë‹¤. "
                "ê´€ë ¨ ê¸°ëŠ¥ë¼ë¦¬ ë¬¶ì–´ì„œ ë³„ë„ ëª¨ë“ˆë¡œ ë¶„ë¦¬í•˜ì„¸ìš”."
            )

        # ì¼ë°˜ì ì¸ ê¶Œì¥ì‚¬í•­
        recommendations.extend(
            [
                "ğŸ—ï¸ ê³µí†µ ê¸°ëŠ¥ì€ base_classes.pyì™€ common/ ëª¨ë“ˆì„ í™œìš©í•˜ì„¸ìš”.",
                "ğŸ“¦ ë¹„ìŠ·í•œ ê¸°ëŠ¥ë¼ë¦¬ëŠ” í•˜ìœ„ íŒ¨í‚¤ì§€ë¡œ ê·¸ë£¹í™”í•˜ì„¸ìš”.",
                "ğŸ”„ ìˆœí™˜ ì˜ì¡´ì„±ì´ ìˆë‹¤ë©´ ì¸í„°í˜ì´ìŠ¤ë‚˜ ì˜ì¡´ì„± ì£¼ì…ìœ¼ë¡œ í•´ê²°í•˜ì„¸ìš”.",
                "ğŸ“ ê° ëª¨ë“ˆì€ 500ì¤„ ì´í•˜, ë³µì¡ë„ 50 ì´í•˜ë¥¼ ìœ ì§€í•˜ì„¸ìš”.",
            ]
        )

        return recommendations


def generate_structure_report(src_path: Path) -> str:
    """êµ¬ì¡° ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    analyzer = ModuleAnalyzer()

    print("ğŸ” ëª¨ë“ˆ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")
    dep_info = analyzer.analyze_dependencies(src_path)

    print("ğŸ”§ êµ¬ì¡°ì  ë¬¸ì œì ì„ ì‹ë³„í•©ë‹ˆë‹¤...")
    issues = analyzer.find_structure_issues()

    print("ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    recommendations = analyzer.generate_recommendations(issues)

    # ë³´ê³ ì„œ ìƒì„±
    report_lines = []

    report_lines.append("=" * 80)
    report_lines.append("ğŸ“Š ëª¨ë“ˆ êµ¬ì¡° ë¶„ì„ ë³´ê³ ì„œ")
    report_lines.append("=" * 80)
    report_lines.append("")

    # ì „ì²´ í†µê³„
    report_lines.append("ğŸ“ˆ ì „ì²´ í†µê³„:")
    report_lines.append(f"  - ë¶„ì„ëœ íŒŒì¼: {dep_info['total_files']}ê°œ")

    total_lines = sum(info["line_count"] for info in analyzer.file_info.values())
    total_functions = sum(info["functions"] for info in analyzer.file_info.values())
    total_classes = sum(info["classes"] for info in analyzer.file_info.values())
    avg_complexity = (
        sum(info["complexity_score"] for info in analyzer.file_info.values())
        / len(analyzer.file_info)
        if analyzer.file_info
        else 0
    )

    report_lines.append(f"  - ì „ì²´ ì½”ë“œ ë¼ì¸: {total_lines:,}ì¤„")
    report_lines.append(f"  - ì „ì²´ í•¨ìˆ˜: {total_functions}ê°œ")
    report_lines.append(f"  - ì „ì²´ í´ë˜ìŠ¤: {total_classes}ê°œ")
    report_lines.append(f"  - í‰ê·  ë³µì¡ë„: {avg_complexity:.1f}")
    report_lines.append("")

    # ë¬¸ì œì  ìš”ì•½
    report_lines.append("âš ï¸ ë°œê²¬ëœ ë¬¸ì œì :")
    total_issues = sum(len(issue_list) for issue_list in issues.values())
    if total_issues == 0:
        report_lines.append("  ğŸ‰ êµ¬ì¡°ì  ë¬¸ì œì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    else:
        for issue_type, issue_list in issues.items():
            if issue_list:
                issue_name = issue_type.replace("_", " ").title()
                report_lines.append(f"  - {issue_name}: {len(issue_list)}ê°œ")
    report_lines.append("")

    # ìƒìœ„ ë¬¸ì œ íŒŒì¼ë“¤
    if issues["large_files"]:
        report_lines.append("ğŸ“ í° íŒŒì¼ë“¤ (ìƒìœ„ 5ê°œ):")
        for item in sorted(
            issues["large_files"], key=lambda x: x["lines"], reverse=True
        )[:5]:
            report_lines.append(
                f"  - {item['file']:50} ({item['lines']:3}ì¤„, {item['functions']:2}í•¨ìˆ˜, {item['classes']:2}í´ë˜ìŠ¤)"
            )
        report_lines.append("")

    if issues["complex_files"]:
        report_lines.append("ğŸ”„ ë³µì¡í•œ íŒŒì¼ë“¤ (ìƒìœ„ 5ê°œ):")
        for item in sorted(
            issues["complex_files"], key=lambda x: x["complexity"], reverse=True
        )[:5]:
            report_lines.append(
                f"  - {item['file']:50} (ë³µì¡ë„ {item['complexity']:2}, {item['functions']:2}í•¨ìˆ˜)"
            )
        report_lines.append("")

    # ê¶Œì¥ì‚¬í•­
    report_lines.append("ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­:")
    for rec in recommendations:
        report_lines.append(f"  {rec}")
    report_lines.append("")

    report_lines.append("=" * 80)

    return "\n".join(report_lines)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    src_path = Path("/home/jclee/app/blacklist/src")

    if not src_path.exists():
        print(f"âŒ ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {src_path}")
        return

    # êµ¬ì¡° ë¶„ì„ ì‹¤í–‰
    report = generate_structure_report(src_path)

    # ë³´ê³ ì„œ ì¶œë ¥
    print(report)

    # ë³´ê³ ì„œ íŒŒì¼ë¡œ ì €ì¥
    report_path = Path("CODE_QUALITY_MODULE_STRUCTURE_REPORT.md")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"ğŸ“„ ìƒì„¸ ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {report_path}")


if __name__ == "__main__":
    import sys

    all_validation_failures = []
    total_tests = 0

    # Test 1: AST parsing
    total_tests += 1
    try:
        test_code = "def test_func(): pass\nclass TestClass: pass"
        tree = ast.parse(test_code)
        if not isinstance(tree, ast.Module):
            all_validation_failures.append("AST test: Failed to parse test code")
    except Exception as e:
        all_validation_failures.append(f"AST test: Failed - {e}")

    # Test 2: Module analyzer creation
    total_tests += 1
    try:
        analyzer = ModuleAnalyzer()
        if not hasattr(analyzer, "analyze_file"):
            all_validation_failures.append("Analyzer test: Missing analyze_file method")
    except Exception as e:
        all_validation_failures.append(f"Analyzer test: Failed - {e}")

    # Test 3: Source path existence
    total_tests += 1
    try:
        src_path = Path("/home/jclee/app/blacklist/src")
        if not src_path.exists():
            all_validation_failures.append("Path test: Source directory does not exist")
    except Exception as e:
        all_validation_failures.append(f"Path test: Failed - {e}")

    # Final validation result
    if all_validation_failures:
        print(
            f"âŒ VALIDATION FAILED - {len(all_validation_failures)} of {total_tests} tests failed:"
        )
        for failure in all_validation_failures:
            print(f"  - {failure}")
        sys.exit(1)
    else:
        print(
            f"âœ… VALIDATION PASSED - All {total_tests} tests produced expected results"
        )
        print("Module structure analyzer is validated and ready to run")
        main()
        sys.exit(0)
