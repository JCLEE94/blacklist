#!/usr/bin/env python3
"""
REGTECH ì„¸ì…˜ ê¸°ë°˜ ìˆ˜ì§‘ê¸° - HAR ë¶„ì„ ê²°ê³¼ í™œìš©
ë‹¨ê³„ë³„ ì¸ì¦ í›„ Excel ë‹¤ìš´ë¡œë“œ
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

import requests
import pandas as pd
import json
import re
import os
import tempfile
from datetime import datetime, timedelta
from typing import List, Dict, Any
from src.config.settings import settings

class RegtechSessionCollector:
    """HAR ë¶„ì„ ê¸°ë°˜ ì„¸ì…˜ ì¸ì¦ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.base_url = "https://regtech.fsec.or.kr"
        self.session = requests.Session()
        self.authenticated = False
        
        # HARì—ì„œ ì¶”ì¶œí•œ ì •í™•í•œ ë¸Œë¼ìš°ì € í—¤ë”
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'sec-ch-ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"'
        })
    
    def authenticate(self) -> bool:
        """ë‹¨ê³„ë³„ ì¸ì¦ ìˆ˜í–‰"""
        print("ğŸ” REGTECH ì¸ì¦ ì‹œì‘...")
        
        try:
            # 1. ë©”ì¸ í˜ì´ì§€ ì ‘ì†í•˜ì—¬ ì„¸ì…˜ ì´ˆê¸°í™”
            print("1ï¸âƒ£ ë©”ì¸ í˜ì´ì§€ ì ‘ì†...")
            main_resp = self.session.get(f"{self.base_url}/main/main")
            print(f"   Status: {main_resp.status_code}")
            
            # 2. ë¡œê·¸ì¸ í¼ í˜ì´ì§€ ì ‘ì†
            print("2ï¸âƒ£ ë¡œê·¸ì¸ í¼ ì ‘ì†...")
            login_form_resp = self.session.get(f"{self.base_url}/login/loginForm")
            print(f"   Status: {login_form_resp.status_code}")
            
            # CSRF í† í°ì´ë‚˜ ìˆ¨ê²¨ì§„ í•„ë“œ ì¶”ì¶œ
            csrf_token = self._extract_csrf_token(login_form_resp.text)
            if csrf_token:
                print(f"   CSRF í† í° ë°œê²¬: {csrf_token[:20]}...")
            
            # 3. ë¡œê·¸ì¸ ì‹œë„
            print("3ï¸âƒ£ ë¡œê·¸ì¸ ì‹œë„...")
            login_data = {
                'memberId': settings.regtech_username,
                'memberPw': settings.regtech_password,
                'userType': '1'
            }
            
            # CSRF í† í°ì´ ìˆìœ¼ë©´ ì¶”ê°€
            if csrf_token:
                login_data['_token'] = csrf_token
            
            login_resp = self.session.post(
                f"{self.base_url}/login/addLogin",
                data=login_data,
                headers={
                    'Content-Type': 'application/x-www-form-urlencoded',
                    'Origin': self.base_url,
                    'Referer': f"{self.base_url}/login/loginForm",
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-User': '?1',
                    'Upgrade-Insecure-Requests': '1'
                }
            )
            
            print(f"   Status: {login_resp.status_code}")
            print(f"   Final URL: {login_resp.url}")
            print(f"   ì¿ í‚¤: {len(self.session.cookies)}ê°œ")
            
            # ë¡œê·¸ì¸ ì„±ê³µ ì—¬ë¶€ í™•ì¸
            if 'error=true' in login_resp.url or 'login' in login_resp.url.lower():
                print("   âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨")
                return False
            
            # 4. Advisory í˜ì´ì§€ ì ‘ì†í•˜ì—¬ ì„¸ì…˜ í™•ì¸
            print("4ï¸âƒ£ Advisory í˜ì´ì§€ ì ‘ì†...")
            advisory_resp = self.session.get(f"{self.base_url}/fcti/securityAdvisory/advisoryList")
            print(f"   Status: {advisory_resp.status_code}")
            
            if advisory_resp.status_code == 200 and 'ë¡œê·¸ì¸' not in advisory_resp.text:
                print("   âœ… ì„¸ì…˜ ì¸ì¦ ì„±ê³µ")
                self.authenticated = True
                return True
            else:
                print("   âŒ ì„¸ì…˜ ì¸ì¦ ì‹¤íŒ¨")
                return False
        
        except Exception as e:
            print(f"   âŒ ì¸ì¦ ì˜¤ë¥˜: {e}")
            return False
    
    def _extract_csrf_token(self, html_content: str) -> str:
        """HTMLì—ì„œ CSRF í† í° ì¶”ì¶œ"""
        # ë‹¤ì–‘í•œ CSRF í† í° íŒ¨í„´ ì‹œë„
        patterns = [
            r'name="_token"[^>]*value="([^"]+)"',
            r'name="csrf_token"[^>]*value="([^"]+)"',
            r'name="authenticity_token"[^>]*value="([^"]+)"',
            r'"_token"\s*:\s*"([^"]+)"',
            r"'_token'\s*:\s*'([^']+)'"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, html_content, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    def collect_blacklist_data(self, start_date: str = None, end_date: str = None, max_size: int = 5000) -> Dict[str, Any]:
        """ì¸ì¦ëœ ì„¸ì…˜ìœ¼ë¡œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘"""
        
        if not self.authenticated:
            print("âŒ ì¸ì¦ë˜ì§€ ì•Šì€ ìƒíƒœì…ë‹ˆë‹¤.")
            return {'success': False, 'error': 'Not authenticated'}
        
        print("ğŸ“Š ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # ê¸°ë³¸ ë‚ ì§œ ì„¤ì •
        if not end_date:
            end_date = datetime.now().strftime('%Y%m%d')
        if not start_date:
            start_date = (datetime.now() - timedelta(days=90)).strftime('%Y%m%d')
        
        print(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")
        
        # HAR ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì •í™•í•œ íŒŒë¼ë¯¸í„°
        form_data = [
            ("page", "0"),
            ("tabSort", "blacklist"),
            ("excelDownload", "security,blacklist,weakpoint,"),
            ("cveId", ""),
            ("ipId", ""),
            ("estId", ""),
            ("startDate", start_date),
            ("endDate", end_date),
            ("findCondition", "all"),
            ("findKeyword", ""),
            ("excelDown", "security"),
            ("excelDown", "blacklist"),
            ("excelDown", "weakpoint"),
            ("size", str(max_size))
        ]
        
        headers = {
            'Content-Type': 'application/x-www-form-urlencoded',
            'Origin': self.base_url,
            'Referer': f"{self.base_url}/fcti/securityAdvisory/advisoryList",
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin',
            'Sec-Fetch-User': '?1',
            'Upgrade-Insecure-Requests': '1'
        }
        
        try:
            print("ğŸ“¡ Excel ë‹¤ìš´ë¡œë“œ ìš”ì²­...")
            response = self.session.post(
                f"{self.base_url}/fcti/securityAdvisory/advisoryListDownloadXlsx",
                data=form_data,
                headers=headers,
                timeout=120,
                stream=True
            )
            
            print(f"ğŸ“Š ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            print(f"ğŸ“ Content-Type: {response.headers.get('Content-Type', 'N/A')}")
            print(f"ğŸ“ Content-Disposition: {response.headers.get('Content-Disposition', 'N/A')}")
            
            if response.status_code == 200:
                return self._process_response(response, start_date, end_date)
            else:
                return {
                    'success': False,
                    'error': f'HTTP {response.status_code}',
                    'response_preview': response.text[:300]
                }
                
        except Exception as e:
            print(f"âŒ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _process_response(self, response: requests.Response, start_date: str, end_date: str) -> Dict[str, Any]:
        """ì‘ë‹µ ì²˜ë¦¬ ë° ë°ì´í„° ì¶”ì¶œ"""
        
        content_type = response.headers.get('Content-Type', '').lower()
        content_disp = response.headers.get('Content-Disposition', '')
        
        print(f"ğŸ” ì‘ë‹µ ë¶„ì„: {content_type}")
        
        if 'excel' in content_type or 'spreadsheet' in content_type or 'filename=' in content_disp:
            print("ğŸ“‹ Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ!")
            return self._parse_excel_data(response.content, start_date, end_date)
        
        elif 'text/html' in content_type:
            html_content = response.text
            if 'ë¡œê·¸ì¸' in html_content or 'login' in html_content.lower():
                print("âŒ ì„¸ì…˜ ë§Œë£Œ - ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸")
                return {
                    'success': False,
                    'error': 'Session expired - redirected to login',
                    'requires_reauth': True
                }
            else:
                print("ğŸ” HTML ì‘ë‹µì—ì„œ IP ì¶”ì¶œ ì‹œë„")
                return self._parse_html_data(html_content, start_date, end_date)
        
        elif 'application/json' in content_type:
            print("ğŸ“Š JSON ì‘ë‹µ ì²˜ë¦¬")
            return self._parse_json_data(response.text, start_date, end_date)
        
        else:
            print(f"â“ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ í˜•ì‹: {content_type}")
            return {
                'success': False,
                'error': 'Unknown response format',
                'content_type': content_type,
                'content_preview': response.text[:500]
            }
    
    def _parse_excel_data(self, excel_content: bytes, start_date: str, end_date: str) -> Dict[str, Any]:
        """Excel íŒŒì¼ì—ì„œ IP ë°ì´í„° ì¶”ì¶œ"""
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                tmp_file.write(excel_content)
                tmp_path = tmp_file.name
            
            print(f"ğŸ“ ì„ì‹œ íŒŒì¼ ì €ì¥: {tmp_path}")
            
            # Excel íŒŒì¼ ì½ê¸°
            df = pd.read_excel(tmp_path)
            print(f"ğŸ“Š Excel ë°ì´í„°: {len(df)} í–‰, {len(df.columns)} ì—´")
            print(f"ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}")
            
            # IP ë°ì´í„° ì¶”ì¶œ
            ip_data = self._extract_ips_from_dataframe(df)
            
            # ê²°ê³¼ íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_dir = Path(__file__).parent.parent / 'data' / 'regtech'
            output_dir.mkdir(parents=True, exist_ok=True)
            
            excel_file = output_dir / f'regtech_session_{timestamp}.xlsx'
            json_file = output_dir / f'regtech_data_{timestamp}.json'
            
            # ì›ë³¸ Excel ì €ì¥
            with open(excel_file, 'wb') as f:
                f.write(excel_content)
            
            # JSONìœ¼ë¡œ ì €ì¥
            result_data = {
                'collection_date': timestamp,
                'period': f"{start_date}_{end_date}",
                'source_method': 'session_authenticated',
                'total_records': len(df),
                'ip_count': len(ip_data),
                'data': ip_data
            }
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_path)
            
            print(f"âœ… ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(ip_data)}ê°œ IP")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {json_file}")
            
            return {
                'success': True,
                'method': 'session_excel_download',
                'total_records': len(df),
                'ip_count': len(ip_data),
                'data': ip_data,
                'files': {
                    'excel': str(excel_file),
                    'json': str(json_file)
                }
            }
            
        except Exception as e:
            print(f"âŒ Excel íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': f'Excel parsing failed: {e}'
            }
    
    def _parse_html_data(self, html_content: str, start_date: str, end_date: str) -> Dict[str, Any]:
        """HTMLì—ì„œ IP ë°ì´í„° ì¶”ì¶œ"""
        
        # IP íŒ¨í„´ ì°¾ê¸°
        ip_pattern = r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b'
        ips = re.findall(ip_pattern, html_content)
        
        print(f"ğŸ” ë°œê²¬ëœ IP: {len(set(ips))}ê°œ")
        
        # ê³µì¸ IPë§Œ í•„í„°ë§
        public_ips = []
        for ip in set(ips):
            if self._is_public_ip(ip):
                public_ips.append({
                    'ip': ip,
                    'source': 'REGTECH',
                    'detection_date': datetime.now().strftime('%Y-%m-%d'),
                    'method': 'html_extraction'
                })
        
        return {
            'success': len(public_ips) > 0,
            'method': 'html_extraction',
            'ip_count': len(public_ips),
            'data': public_ips,
            'raw_ips_found': len(ips)
        }
    
    def _parse_json_data(self, json_text: str, start_date: str, end_date: str) -> Dict[str, Any]:
        """JSON ì‘ë‹µì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        try:
            data = json.loads(json_text)
            print(f"ğŸ“Š JSON ë°ì´í„° êµ¬ì¡°: {list(data.keys()) if isinstance(data, dict) else type(data)}")
            
            return {
                'success': True,
                'method': 'json_api',
                'data': data
            }
            
        except json.JSONDecodeError as e:
            return {
                'success': False,
                'error': f'JSON parsing failed: {e}'
            }
    
    def _extract_ips_from_dataframe(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
        """DataFrameì—ì„œ IP ë°ì´í„° ì¶”ì¶œ"""
        ip_data = []
        
        # IP ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
        ip_columns = []
        for col in df.columns:
            col_lower = str(col).lower()
            if any(keyword in col_lower for keyword in ['ip', 'ì•„ì´í”¼', 'addr', 'address']):
                ip_columns.append(col)
        
        print(f"ğŸ” IP ê´€ë ¨ ì»¬ëŸ¼: {ip_columns}")
        
        if not ip_columns:
            # ëª¨ë“  ì»¬ëŸ¼ì—ì„œ IP íŒ¨í„´ ì°¾ê¸°
            ip_pattern = r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b'
            for idx, row in df.iterrows():
                for col in df.columns:
                    cell_value = str(row[col])
                    ips = re.findall(ip_pattern, cell_value)
                    for ip in ips:
                        if self._is_public_ip(ip):
                            ip_data.append({
                                'ip': ip,
                                'source': 'REGTECH',
                                'detection_date': datetime.now().strftime('%Y-%m-%d'),
                                'column': col,
                                'row_index': idx,
                                'method': 'session_excel'
                            })
        else:
            # IP ì»¬ëŸ¼ì—ì„œ ì§ì ‘ ì¶”ì¶œ
            for col in ip_columns:
                for idx, ip in enumerate(df[col]):
                    ip_str = str(ip).strip()
                    if self._is_valid_ip(ip_str) and self._is_public_ip(ip_str):
                        ip_data.append({
                            'ip': ip_str,
                            'source': 'REGTECH',
                            'detection_date': datetime.now().strftime('%Y-%m-%d'),
                            'column': col,
                            'row_index': idx,
                            'method': 'session_excel',
                            'additional_data': {c: str(df.iloc[idx][c]) for c in df.columns if c != col}
                        })
        
        return ip_data
    
    def _is_valid_ip(self, ip: str) -> bool:
        """IP ì£¼ì†Œ ìœ íš¨ì„± ê²€ì¦"""
        try:
            parts = ip.split('.')
            if len(parts) != 4:
                return False
            for part in parts:
                if not (0 <= int(part) <= 255):
                    return False
            return True
        except:
            return False
    
    def _is_public_ip(self, ip: str) -> bool:
        """ê³µì¸ IP ì—¬ë¶€ í™•ì¸"""
        if not self._is_valid_ip(ip):
            return False
        
        parts = ip.split('.')
        first = int(parts[0])
        second = int(parts[1])
        
        # ì‚¬ì„¤ IP ì œì™¸
        if first == 10:
            return False
        if first == 172 and 16 <= second <= 31:
            return False
        if first == 192 and second == 168:
            return False
        if first == 127:
            return False
        if first == 0 or first >= 224:
            return False
        
        return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    collector = RegtechSessionCollector()
    
    # 1. ì¸ì¦ ìˆ˜í–‰
    if not collector.authenticate():
        print("âŒ ì¸ì¦ ì‹¤íŒ¨ - ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return
    
    # 2. ë°ì´í„° ìˆ˜ì§‘
    result = collector.collect_blacklist_data(max_size=5000)
    
    print("\\n" + "="*60)
    print("ğŸ“Š ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼")
    print("="*60)
    
    if result['success']:
        print(f"âœ… ì„±ê³µ: {result['method']}")
        print(f"ğŸ“Š ì´ ë ˆì½”ë“œ: {result.get('total_records', 'N/A')}")
        print(f"ğŸ¯ IP ê°œìˆ˜: {result.get('ip_count', 0)}")
        
        if 'files' in result:
            print(f"ğŸ“ ì €ì¥ íŒŒì¼:")
            for file_type, file_path in result['files'].items():
                print(f"  - {file_type}: {file_path}")
        
        if result.get('data'):
            print(f"\\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„°:")
            for i, item in enumerate(result['data'][:5]):
                print(f"  {i+1}. {item.get('ip', 'N/A')} - {item.get('detection_date', 'N/A')}")
    else:
        print(f"âŒ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
        if 'response_preview' in result:
            print(f"ğŸ“ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {result['response_preview']}")

if __name__ == "__main__":
    main()