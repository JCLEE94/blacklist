#!/usr/bin/env python3
"""
ê³ ê¸‰ ë¶„ì„ ì‹œìŠ¤í…œ - ìˆ˜ì§‘ëœ ë°ì´í„° í™œìš©
Advanced Analytics System - Utilizing Collected Data
"""

import ipaddress
import json
import logging
import sqlite3
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


class AdvancedAnalytics:
    """ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜ ê³ ê¸‰ ë¶„ì„"""

    def __init__(self, db_path: str = "instance/blacklist.db"):
        self.db_path = db_path

    def get_threat_intelligence_report(self) -> Dict[str, Any]:
        """ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ë³´ê³ ì„œ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ê¸°ë³¸ í†µê³„
            cursor.execute("SELECT COUNT(*) FROM blacklist_entries")
            total_threats = cursor.fetchone()[0]

            # ìœ„í—˜ë„ë³„ ë¶„í¬
            cursor.execute(
                """
                SELECT threat_level, COUNT(*) 
                FROM blacklist_entries 
                GROUP BY threat_level 
                ORDER BY COUNT(*) DESC
            """
            )
            threat_distribution = dict(cursor.fetchall())

            # êµ­ê°€ë³„ ìœ„í˜‘ ë¶„í¬ (ìƒìœ„ 15ê°œ)
            cursor.execute(
                """
                SELECT country, COUNT(*) as count,
                       threat_level,
                       GROUP_CONCAT(DISTINCT reason) as attack_types
                FROM blacklist_entries 
                WHERE country != 'UNKNOWN'
                GROUP BY country, threat_level
                ORDER BY count DESC
                LIMIT 15
            """
            )
            geo_threats = []
            for row in cursor.fetchall():
                country, count, threat_level, attack_types = row
                geo_threats.append(
                    {
                        "country": country,
                        "threat_count": count,
                        "threat_level": threat_level,
                        "attack_types": attack_types.split(",") if attack_types else [],
                    }
                )

            # ê³µê²© íŒ¨í„´ ë¶„ì„
            cursor.execute(
                """
                SELECT reason, COUNT(*) as frequency,
                       threat_level,
                       GROUP_CONCAT(DISTINCT country) as affected_countries
                FROM blacklist_entries 
                GROUP BY reason, threat_level
                ORDER BY frequency DESC
                LIMIT 20
            """
            )
            attack_patterns = []
            for row in cursor.fetchall():
                reason, freq, level, countries = row
                attack_patterns.append(
                    {
                        "attack_type": reason,
                        "frequency": freq,
                        "threat_level": level,
                        "affected_countries": countries.split(",") if countries else [],
                        "severity_score": self._calculate_severity_score(freq, level),
                    }
                )

            # ì‹œê°„ë³„ íŠ¸ë Œë“œ (ìµœê·¼ 30ì¼)
            cursor.execute(
                """
                SELECT collection_date, COUNT(*) as daily_count,
                       threat_level,
                       AVG(confidence_level) as avg_confidence
                FROM blacklist_entries 
                WHERE collection_date >= date('now', '-30 days')
                GROUP BY collection_date, threat_level
                ORDER BY collection_date DESC
            """
            )
            time_trends = []
            for row in cursor.fetchall():
                date, count, level, confidence = row
                time_trends.append(
                    {
                        "date": date,
                        "count": count,
                        "threat_level": level,
                        "confidence": round(confidence or 0, 2),
                    }
                )

            conn.close()

            return {
                "summary": {
                    "total_threats": total_threats,
                    "threat_distribution": threat_distribution,
                    "analysis_date": datetime.now().isoformat(),
                },
                "geographic_analysis": geo_threats,
                "attack_patterns": attack_patterns,
                "time_trends": time_trends,
                "risk_assessment": self._generate_risk_assessment(
                    threat_distribution, geo_threats
                ),
            }

        except Exception as e:
            logger.error(f"ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
            return {}

    def get_network_analysis(self) -> Dict[str, Any]:
        """ë„¤íŠ¸ì›Œí¬ ë¶„ì„ (IP ë²”ìœ„, ì„œë¸Œë„· ë“±)"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # IP ì£¼ì†Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            cursor.execute(
                "SELECT ip_address, country, threat_level FROM blacklist_entries"
            )
            ip_data = cursor.fetchall()

            # ì„œë¸Œë„· ë¶„ì„
            subnet_analysis = self._analyze_subnets(ip_data)

            # ì§€ë¦¬ì  í´ëŸ¬ìŠ¤í„° ë¶„ì„
            geo_clusters = self._analyze_geographic_clusters(ip_data)

            # ASN ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
            asn_analysis = self._analyze_asn_patterns(ip_data)

            conn.close()

            return {
                "subnet_analysis": subnet_analysis,
                "geographic_clusters": geo_clusters,
                "asn_analysis": asn_analysis,
                "network_summary": {
                    "total_ips": len(ip_data),
                    "unique_subnets": len(subnet_analysis.get("high_risk_subnets", [])),
                    "high_risk_countries": len(
                        [c for c in geo_clusters if c.get("risk_level") == "HIGH"]
                    ),
                },
            }

        except Exception as e:
            logger.error(f"ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}

    def get_attack_correlation_analysis(self) -> Dict[str, Any]:
        """ê³µê²© ìƒê´€ê´€ê³„ ë¶„ì„"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ê³µê²© ìœ í˜•ë³„ ìƒê´€ê´€ê³„
            cursor.execute(
                """
                SELECT reason, country, threat_level, 
                       collection_date, COUNT(*) as frequency
                FROM blacklist_entries 
                GROUP BY reason, country, threat_level, collection_date
                HAVING frequency > 1
                ORDER BY frequency DESC
                LIMIT 50
            """
            )

            correlations = []
            for row in cursor.fetchall():
                reason, country, level, date, freq = row
                correlations.append(
                    {
                        "attack_type": reason,
                        "country": country,
                        "threat_level": level,
                        "date": date,
                        "frequency": freq,
                        "correlation_score": self._calculate_correlation_score(
                            freq, level, country
                        ),
                    }
                )

            # ì‹œê°„ì  íŒ¨í„´ ë¶„ì„
            cursor.execute(
                """
                SELECT strftime('%H', created_at) as hour,
                       COUNT(*) as count,
                       threat_level
                FROM blacklist_entries 
                WHERE created_at IS NOT NULL
                GROUP BY hour, threat_level
                ORDER BY hour
            """
            )

            temporal_patterns = defaultdict(list)
            for row in cursor.fetchall():
                hour, count, level = row
                temporal_patterns[hour].append({"threat_level": level, "count": count})

            conn.close()

            return {
                "attack_correlations": correlations,
                "temporal_patterns": dict(temporal_patterns),
                "correlation_summary": {
                    "high_correlation_attacks": len(
                        [c for c in correlations if c["correlation_score"] > 0.7]
                    ),
                    "peak_hours": self._identify_peak_hours(temporal_patterns),
                },
            }

        except Exception as e:
            logger.error(f"ê³µê²© ìƒê´€ê´€ê³„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}

    def get_predictive_insights(self) -> Dict[str, Any]:
        """ì˜ˆì¸¡ ì¸ì‚¬ì´íŠ¸"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # íŠ¸ë Œë“œ ê¸°ë°˜ ì˜ˆì¸¡
            cursor.execute(
                """
                SELECT collection_date, COUNT(*) as daily_count
                FROM blacklist_entries 
                WHERE collection_date >= date('now', '-14 days')
                GROUP BY collection_date
                ORDER BY collection_date
            """
            )

            trend_data = cursor.fetchall()
            trend_prediction = self._predict_trends(trend_data)

            # ìœ„í—˜ ì§€ì—­ ì˜ˆì¸¡
            cursor.execute(
                """
                SELECT country, COUNT(*) as threat_count,
                       AVG(CASE 
                           WHEN threat_level = 'CRITICAL' THEN 4
                           WHEN threat_level = 'HIGH' THEN 3
                           WHEN threat_level = 'MEDIUM' THEN 2
                           ELSE 1 END) as avg_severity
                FROM blacklist_entries 
                WHERE collection_date >= date('now', '-7 days')
                GROUP BY country
                HAVING threat_count > 5
                ORDER BY avg_severity DESC, threat_count DESC
            """
            )

            risk_regions = []
            for row in cursor.fetchall():
                country, count, severity = row
                risk_regions.append(
                    {
                        "country": country,
                        "threat_count": count,
                        "avg_severity": round(severity, 2),
                        "risk_prediction": self._predict_country_risk(count, severity),
                    }
                )

            # ê³µê²© íŒ¨í„´ ì˜ˆì¸¡
            attack_predictions = self._predict_attack_patterns()

            conn.close()

            return {
                "trend_predictions": trend_prediction,
                "risk_regions": risk_regions,
                "attack_predictions": attack_predictions,
                "recommendations": self._generate_security_recommendations(
                    risk_regions, attack_predictions
                ),
            }

        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return {}

    def generate_threat_report_export(
        self, format_type: str = "json"
    ) -> Dict[str, Any]:
        """ìœ„í˜‘ ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸°"""
        try:
            # ëª¨ë“  ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘
            intelligence = self.get_threat_intelligence_report()
            network = self.get_network_analysis()
            correlations = self.get_attack_correlation_analysis()
            predictions = self.get_predictive_insights()

            comprehensive_report = {
                "report_metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "report_type": "comprehensive_threat_analysis",
                    "format": format_type,
                    "version": "1.0",
                },
                "executive_summary": self._create_executive_summary(
                    intelligence, network, predictions
                ),
                "threat_intelligence": intelligence,
                "network_analysis": network,
                "attack_correlations": correlations,
                "predictive_insights": predictions,
            }

            if format_type == "csv":
                # CSV í˜•íƒœë¡œ ë³€í™˜ (ê°„ì†Œí™”ëœ ë°ì´í„°)
                return self._convert_to_csv_format(comprehensive_report)
            elif format_type == "pdf":
                # PDF ìƒì„±ì„ ìœ„í•œ êµ¬ì¡°í™”ëœ ë°ì´í„°
                return self._prepare_for_pdf(comprehensive_report)

            return comprehensive_report

        except Exception as e:
            logger.error(f"ìœ„í˜‘ ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {e}")
            return {}

    def _calculate_severity_score(self, frequency: int, threat_level: str) -> float:
        """ì‹¬ê°ë„ ì ìˆ˜ ê³„ì‚°"""
        level_weights = {"CRITICAL": 1.0, "HIGH": 0.8, "MEDIUM": 0.6, "LOW": 0.4}

        base_score = level_weights.get(threat_level, 0.5)
        frequency_factor = min(frequency / 100, 1.0)  # ì •ê·œí™”

        return round(base_score * (0.7 + frequency_factor * 0.3), 2)

    def _analyze_subnets(self, ip_data: List[Tuple]) -> Dict[str, Any]:
        """ì„œë¸Œë„· ë¶„ì„"""
        subnet_counter = Counter()

        for ip, country, threat_level in ip_data:
            try:
                network = ipaddress.ip_network(f"{ip}/24", strict=False)
                subnet_counter[str(network)] += 1
            except:
                continue

        high_risk_subnets = [
            {"subnet": subnet, "threat_count": count}
            for subnet, count in subnet_counter.most_common(20)
            if count > 5
        ]

        return {
            "high_risk_subnets": high_risk_subnets,
            "total_subnets": len(subnet_counter),
            "avg_threats_per_subnet": (
                sum(subnet_counter.values()) / len(subnet_counter)
                if subnet_counter
                else 0
            ),
        }

    def _analyze_geographic_clusters(
        self, ip_data: List[Tuple]
    ) -> List[Dict[str, Any]]:
        """ì§€ë¦¬ì  í´ëŸ¬ìŠ¤í„° ë¶„ì„"""
        country_stats = defaultdict(lambda: {"count": 0, "threat_levels": Counter()})

        for ip, country, threat_level in ip_data:
            if country and country != "UNKNOWN":
                country_stats[country]["count"] += 1
                country_stats[country]["threat_levels"][threat_level] += 1

        clusters = []
        for country, stats in country_stats.items():
            critical_ratio = stats["threat_levels"].get("CRITICAL", 0) / stats["count"]
            high_ratio = stats["threat_levels"].get("HIGH", 0) / stats["count"]

            risk_level = "LOW"
            if critical_ratio > 0.3 or high_ratio > 0.5:
                risk_level = "HIGH"
            elif critical_ratio > 0.1 or high_ratio > 0.3:
                risk_level = "MEDIUM"

            clusters.append(
                {
                    "country": country,
                    "threat_count": stats["count"],
                    "risk_level": risk_level,
                    "threat_distribution": dict(stats["threat_levels"]),
                }
            )

        return sorted(clusters, key=lambda x: x["threat_count"], reverse=True)

    def _analyze_asn_patterns(self, ip_data: List[Tuple]) -> Dict[str, Any]:
        """ASN íŒ¨í„´ ë¶„ì„ (ê¸°ë³¸ì ì¸ ë¶„ì„)"""
        # ì‹¤ì œ ASN ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìœ¼ë¯€ë¡œ IP ë²”ìœ„ ê¸°ë°˜ ì¶”ì •
        private_ranges = 0
        public_ranges = 0

        for ip, _, _ in ip_data:
            try:
                ip_obj = ipaddress.ip_address(ip)
                if ip_obj.is_private:
                    private_ranges += 1
                else:
                    public_ranges += 1
            except:
                continue

        return {
            "private_ip_count": private_ranges,
            "public_ip_count": public_ranges,
            "private_ratio": (
                private_ranges / (private_ranges + public_ranges)
                if (private_ranges + public_ranges) > 0
                else 0
            ),
        }

    def _generate_risk_assessment(
        self, threat_dist: Dict, geo_threats: List
    ) -> Dict[str, Any]:
        """ìœ„í—˜ í‰ê°€ ìƒì„±"""
        total_threats = sum(threat_dist.values()) if threat_dist else 0
        critical_ratio = (
            threat_dist.get("CRITICAL", 0) / total_threats if total_threats > 0 else 0
        )

        risk_level = "LOW"
        if critical_ratio > 0.2:
            risk_level = "CRITICAL"
        elif critical_ratio > 0.1:
            risk_level = "HIGH"
        elif critical_ratio > 0.05:
            risk_level = "MEDIUM"

        return {
            "overall_risk_level": risk_level,
            "critical_threat_ratio": round(critical_ratio, 3),
            "high_risk_countries": len(
                [g for g in geo_threats if g.get("threat_count", 0) > 50]
            ),
            "recommendation": self._get_risk_recommendation(risk_level),
        }

    def _get_risk_recommendation(self, risk_level: str) -> str:
        """ìœ„í—˜ ìˆ˜ì¤€ë³„ ê¶Œì¥ì‚¬í•­"""
        recommendations = {
            "CRITICAL": "ì¦‰ì‹œ ë³´ì•ˆ ëŒ€ì‘íŒ€ ì•Œë¦¼ ë° ê¸´ê¸‰ ë°©í™”ë²½ ê·œì¹™ ì—…ë°ì´íŠ¸ í•„ìš”",
            "HIGH": "24ì‹œê°„ ë‚´ ë³´ì•ˆ ì •ì±… ê²€í†  ë° ì¶”ê°€ ëª¨ë‹ˆí„°ë§ ì„¤ì • ê¶Œì¥",
            "MEDIUM": "ì£¼ê°„ ë³´ì•ˆ ê²€í†  ì‹œ ê³ ë ¤ì‚¬í•­ìœ¼ë¡œ í¬í•¨",
            "LOW": "ì •ê¸° ëª¨ë‹ˆí„°ë§ ìœ ì§€",
        }
        return recommendations.get(risk_level, "ì¶”ê°€ ë¶„ì„ í•„ìš”")

    def _calculate_correlation_score(
        self, frequency: int, threat_level: str, country: str
    ) -> float:
        """ìƒê´€ê´€ê³„ ì ìˆ˜ ê³„ì‚°"""
        base_score = 0.5

        # ë¹ˆë„ ê°€ì¤‘ì¹˜
        if frequency > 10:
            base_score += 0.3
        elif frequency > 5:
            base_score += 0.2

        # ìœ„í˜‘ ìˆ˜ì¤€ ê°€ì¤‘ì¹˜
        level_weights = {"CRITICAL": 0.3, "HIGH": 0.2, "MEDIUM": 0.1}
        base_score += level_weights.get(threat_level, 0)

        return min(base_score, 1.0)

    def _identify_peak_hours(self, temporal_patterns: Dict) -> List[str]:
        """í”¼í¬ ì‹œê°„ëŒ€ ì‹ë³„"""
        hour_totals = {}
        for hour, patterns in temporal_patterns.items():
            total = sum(p["count"] for p in patterns)
            hour_totals[hour] = total

        avg_total = sum(hour_totals.values()) / len(hour_totals) if hour_totals else 0
        peak_hours = [
            hour for hour, total in hour_totals.items() if total > avg_total * 1.5
        ]

        return sorted(peak_hours)

    def _predict_trends(self, trend_data: List[Tuple]) -> Dict[str, Any]:
        """íŠ¸ë Œë“œ ì˜ˆì¸¡ (ê°„ë‹¨í•œ ì„ í˜• ì¶”ì„¸)"""
        if len(trend_data) < 3:
            return {"prediction": "insufficient_data"}

        # ìµœê·¼ 7ì¼ í‰ê· ê³¼ ì´ì „ 7ì¼ í‰ê·  ë¹„êµ
        recent_avg = sum(row[1] for row in trend_data[-7:]) / min(7, len(trend_data))
        previous_avg = (
            sum(row[1] for row in trend_data[-14:-7]) / min(7, len(trend_data) - 7)
            if len(trend_data) > 7
            else recent_avg
        )

        trend_direction = "stable"
        change_rate = 0

        if previous_avg > 0:
            change_rate = (recent_avg - previous_avg) / previous_avg
            if change_rate > 0.1:
                trend_direction = "increasing"
            elif change_rate < -0.1:
                trend_direction = "decreasing"

        return {
            "trend_direction": trend_direction,
            "change_rate": round(change_rate, 3),
            "recent_avg": round(recent_avg, 1),
            "prediction_confidence": 0.7 if len(trend_data) > 10 else 0.5,
        }

    def _predict_country_risk(self, threat_count: int, avg_severity: float) -> str:
        """êµ­ê°€ë³„ ìœ„í—˜ë„ ì˜ˆì¸¡"""
        risk_score = (threat_count / 100) * 0.6 + (avg_severity / 4) * 0.4

        if risk_score > 0.7:
            return "HIGH"
        elif risk_score > 0.4:
            return "MEDIUM"
        else:
            return "LOW"

    def _predict_attack_patterns(self) -> Dict[str, Any]:
        """ê³µê²© íŒ¨í„´ ì˜ˆì¸¡"""
        # ê°„ë‹¨í•œ íŒ¨í„´ ì˜ˆì¸¡ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ML ëª¨ë¸ ì‚¬ìš©)
        return {
            "predicted_attack_types": [
                "WordPress ì¸ì¦ìš°íšŒ ê³µê²©",
                "Apache HTTP Server ê²½ë¡œìš°íšŒ ê³µê²©",
            ],
            "confidence": 0.75,
            "time_horizon": "7_days",
        }

    def _generate_security_recommendations(
        self, risk_regions: List, attack_predictions: Dict
    ) -> List[str]:
        """ë³´ì•ˆ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        high_risk_countries = [
            r["country"] for r in risk_regions if r.get("risk_prediction") == "HIGH"
        ]
        if high_risk_countries:
            recommendations.append(
                f"ê³ ìœ„í—˜ êµ­ê°€({', '.join(high_risk_countries[:3])}) IP ë²”ìœ„ì— ëŒ€í•œ ì¶”ê°€ ëª¨ë‹ˆí„°ë§ ì„¤ì •"
            )

        if attack_predictions.get("confidence", 0) > 0.7:
            recommendations.append("WordPress ë° Apache ì„œë²„ ë³´ì•ˆ íŒ¨ì¹˜ ìƒíƒœ ì ê²€")

        recommendations.extend(
            [
                "ë°©í™”ë²½ ê·œì¹™ ì •ê¸° ì—…ë°ì´íŠ¸ (ì£¼ 1íšŒ)",
                "ì¹¨ì… íƒì§€ ì‹œìŠ¤í…œ(IDS) ì‹œê·¸ë‹ˆì²˜ ìµœì‹ í™”",
                "ë³´ì•ˆ ë¡œê·¸ ë¶„ì„ ìë™í™” ë„êµ¬ í™œìš©",
            ]
        )

        return recommendations

    def _create_executive_summary(
        self, intelligence: Dict, network: Dict, predictions: Dict
    ) -> Dict[str, Any]:
        """ê²½ì˜ì§„ ìš”ì•½ ìƒì„±"""
        total_threats = intelligence.get("summary", {}).get("total_threats", 0)
        risk_level = intelligence.get("risk_assessment", {}).get(
            "overall_risk_level", "UNKNOWN"
        )

        return {
            "total_threats_identified": total_threats,
            "overall_risk_level": risk_level,
            "key_findings": [
                f"ì´ {total_threats}ê°œì˜ ìœ„í˜‘ IP ì‹ë³„",
                f"ì „ì²´ ìœ„í—˜ ìˆ˜ì¤€: {risk_level}",
                f"ê³ ìœ„í—˜ ì„œë¸Œë„· {len(network.get('subnet_analysis', {}).get('high_risk_subnets', []))}ê°œ ë°œê²¬",
            ],
            "immediate_actions_required": risk_level in ["CRITICAL", "HIGH"],
        }

    def _convert_to_csv_format(self, report: Dict) -> Dict[str, Any]:
        """CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        # CSV ë³€í™˜ ë¡œì§ (ê°„ì†Œí™”)
        return {"format": "csv", "data": "CSV conversion not implemented in this demo"}

    def _prepare_for_pdf(self, report: Dict) -> Dict[str, Any]:
        """PDF ì¤€ë¹„"""
        # PDF ì¤€ë¹„ ë¡œì§ (ê°„ì†Œí™”)
        return {"format": "pdf", "data": "PDF preparation not implemented in this demo"}


if __name__ == "__main__":
    # ê³ ê¸‰ ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    analytics = AdvancedAnalytics()

    print("ğŸ” ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ë³´ê³ ì„œ ìƒì„±...")
    intelligence = analytics.get_threat_intelligence_report()
    if intelligence:
        summary = intelligence.get("summary", {})
        print(f"  - ì´ ìœ„í˜‘: {summary.get('total_threats', 0)}ê°œ")
        print(f"  - ìœ„í—˜ë„ ë¶„í¬: {summary.get('threat_distribution', {})}")

    print("\nğŸŒ ë„¤íŠ¸ì›Œí¬ ë¶„ì„...")
    network = analytics.get_network_analysis()
    if network:
        net_summary = network.get("network_summary", {})
        print(f"  - ì´ IP: {net_summary.get('total_ips', 0)}ê°œ")
        print(f"  - ê³ ìœ„í—˜ ì„œë¸Œë„·: {net_summary.get('unique_subnets', 0)}ê°œ")

    print("\nğŸ”— ê³µê²© ìƒê´€ê´€ê³„ ë¶„ì„...")
    correlations = analytics.get_attack_correlation_analysis()
    if correlations:
        corr_summary = correlations.get("correlation_summary", {})
        print(
            f"  - ê³ ìƒê´€ê´€ê³„ ê³µê²©: {corr_summary.get('high_correlation_attacks', 0)}ê°œ"
        )
        print(f"  - í”¼í¬ ì‹œê°„ëŒ€: {corr_summary.get('peak_hours', [])}")

    print("\nğŸ”® ì˜ˆì¸¡ ì¸ì‚¬ì´íŠ¸...")
    predictions = analytics.get_predictive_insights()
    if predictions:
        trend = predictions.get("trend_predictions", {})
        print(f"  - íŠ¸ë Œë“œ ë°©í–¥: {trend.get('trend_direction', 'unknown')}")
        print(f"  - ë³€í™”ìœ¨: {trend.get('change_rate', 0)*100:.1f}%")

        recs = predictions.get("recommendations", [])
        print(f"  - ê¶Œì¥ì‚¬í•­: {len(recs)}ê°œ")
