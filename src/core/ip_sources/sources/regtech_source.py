#!/usr/bin/env python3
"""
RegTech (ê¸ˆë³´ì›) IP ì†ŒìŠ¤
ê¸ˆìœµë³´ì•ˆì› ë ˆê·¸í…Œí¬ í¬í„¸ì—ì„œ ìš”ì£¼ì˜ IP ìˆ˜ì§‘
"""

import requests
import json
import re
import os
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from .base_source import BaseIPSource
import glob

class RegTechSource(BaseIPSource):
    """RegTech ê¸ˆìœµë³´ì•ˆì› IP ì†ŒìŠ¤"""
    
    def __init__(self, config=None):
        super().__init__()
        self.name = "regtech_fsec"
        self.description = "ê¸ˆìœµë³´ì•ˆì› ë ˆê·¸í…Œí¬ í¬í„¸ ìš”ì£¼ì˜ IP"
        self.base_url = "https://regtech.fsec.or.kr"
        self.priority = 8  # ë†’ì€ ìš°ì„ ìˆœìœ„
        
        # ì„¤ì • ë¡œë“œ
        self.config = config or {}
        self.username = self.config.get('username') or os.getenv('BLACKLIST_USERNAME')
        self.password = self.config.get('password') or os.getenv('BLACKLIST_PASSWORD')
        
        # ì„¸ì…˜ ì´ˆê¸°í™”
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        
        self._logged_in = False
    
    def is_available(self):
        """ì†ŒìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        if not self.username or not self.password:
            return False, "ë¸”ë™ë¦¬ìŠ¤íŠ¸ ê³„ì • ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        
        try:
            # ë ˆê·¸í…Œí¬ ì‚¬ì´íŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
            response = self.session.get(f"{self.base_url}/", timeout=10)
            if response.status_code == 200:
                return True, "RegTech ì‚¬ì´íŠ¸ ì ‘ê·¼ ê°€ëŠ¥"
            else:
                return False, f"RegTech ì‚¬ì´íŠ¸ ì ‘ê·¼ ì‹¤íŒ¨: {response.status_code}"
        except Exception as e:
            return False, f"RegTech ì‚¬ì´íŠ¸ ì—°ê²° ì˜¤ë¥˜: {e}"
    
    def collect_ips(self, **kwargs):
        """IP ìˆ˜ì§‘ ì‹¤í–‰"""
        try:
            print(f"ğŸ›ï¸ {self.name} ì†ŒìŠ¤ì—ì„œ IP ìˆ˜ì§‘ ì‹œì‘...")
            
            # 1. ì—‘ì…€ íŒŒì¼ ê¸°ë°˜ ìˆ˜ì§‘ (ìš°ì„ )
            excel_ips = self._collect_from_excel_files()
            
            # 2. ì›¹ ìŠ¤í¬ë˜í•‘ ìˆ˜ì§‘ (ë³´ì¡°)
            web_ips = self._collect_from_web_scraping()
            
            # 3. ê¸°ì¡´ íŒŒì‹±ëœ ë°ì´í„° ë¡œë“œ
            cached_ips = self._load_cached_data()
            
            # ëª¨ë“  IP í†µí•©
            all_ips = set()
            all_ips.update(excel_ips)
            all_ips.update(web_ips)
            all_ips.update(cached_ips)
            
            # ê²°ê³¼ ì •ë¦¬
            final_ips = sorted(list(all_ips))
            
            result = {
                'ips': final_ips,
                'total_count': len(final_ips),
                'source_breakdown': {
                    'excel_files': len(excel_ips),
                    'web_scraping': len(web_ips),
                    'cached_data': len(cached_ips)
                },
                'collection_method': 'multi_source_regtech',
                'timestamp': datetime.now().isoformat()
            }
            
            print(f"   âœ… ì´ {len(final_ips)}ê°œ IP ìˆ˜ì§‘ ì™„ë£Œ")
            print(f"      - ì—‘ì…€: {len(excel_ips)}ê°œ")
            print(f"      - ì›¹: {len(web_ips)}ê°œ") 
            print(f"      - ìºì‹œ: {len(cached_ips)}ê°œ")
            
            return result
            
        except Exception as e:
            print(f"   âŒ RegTech IP ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {'ips': [], 'total_count': 0, 'error': str(e)}
    
    def _collect_from_excel_files(self):
        """ì—‘ì…€ íŒŒì¼ì—ì„œ IP ìˆ˜ì§‘"""
        excel_ips = set()
        
        try:
            # RegTech ê´€ë ¨ ì—‘ì…€ íŒŒì¼ ì°¾ê¸°
            excel_patterns = [
                "downloads/regtech_excel/*.xlsx",
                "downloads/regtech_excel/*.xls",
                "data/blacklist/regtech*/*.xlsx"
            ]
            
            found_files = []
            for pattern in excel_patterns:
                found_files.extend(glob.glob(pattern, recursive=True))
            
            if not found_files:
                return excel_ips
            
            print(f"   ğŸ“Š {len(found_files)}ê°œ ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
            
            for file_path in found_files:
                try:
                    # ì—‘ì…€ íŒŒì¼ ì½ê¸°
                    excel_data = pd.read_excel(file_path, sheet_name=None)
                    
                    for sheet_name, df in excel_data.items():
                        # ê° ì…€ì—ì„œ IP ì°¾ê¸°
                        for idx, row in df.iterrows():
                            for col_name, cell_value in row.items():
                                str_value = str(cell_value) if pd.notna(cell_value) else ""
                                
                                # IP íŒ¨í„´ ì°¾ê¸°
                                ip_matches = re.findall(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b', str_value)
                                for ip in ip_matches:
                                    if self._is_valid_public_ip(ip):
                                        excel_ips.add(ip)
                                        
                except Exception as e:
                    print(f"      âš ï¸ ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({file_path}): {e}")
                    continue
            
            print(f"      âœ… ì—‘ì…€ì—ì„œ {len(excel_ips)}ê°œ IP ì¶”ì¶œ")
            
        except Exception as e:
            print(f"      âŒ ì—‘ì…€ íŒŒì¼ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return excel_ips
    
    def _collect_from_web_scraping(self):
        """ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ IP ìˆ˜ì§‘"""
        web_ips = set()
        
        try:
            if not self.username or not self.password:
                print(f"      âš ï¸ ì›¹ ìŠ¤í¬ë˜í•‘: ê³„ì • ì •ë³´ ì—†ìŒ")
                return web_ips
            
            # ë¡œê·¸ì¸ ì‹œë„
            if self._login():
                print(f"      ğŸ” ë¡œê·¸ì¸ ì„±ê³µ, ì›¹ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                
                # ë³´ì•ˆ ê¶Œê³ ì‚¬í•­ í˜ì´ì§€ì—ì„œ IP ìˆ˜ì§‘
                advisory_url = f"{self.base_url}/fcti/securityAdvisory/advisoryList"
                
                for page in range(1, 6):  # ìµœëŒ€ 5í˜ì´ì§€
                    try:
                        params = {'page': page, 'size': 100}
                        response = self.session.get(advisory_url, params=params, timeout=30)
                        
                        if response.status_code == 200:
                            page_ips = self._extract_ips_from_html(response.text)
                            web_ips.update(page_ips)
                            
                            if not page_ips:  # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                                break
                        else:
                            break
                            
                    except Exception as e:
                        print(f"         âš ï¸ í˜ì´ì§€ {page} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        break
                
                print(f"      âœ… ì›¹ì—ì„œ {len(web_ips)}ê°œ IP ìˆ˜ì§‘")
            else:
                print(f"      âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨, ì›¹ ìˆ˜ì§‘ ê±´ë„ˆëœ€")
        
        except Exception as e:
            print(f"      âŒ ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        
        return web_ips
    
    def _load_cached_data(self):
        """ê¸°ì¡´ íŒŒì‹±ëœ ë°ì´í„° ë¡œë“œ"""
        cached_ips = set()
        
        try:
            # ê¸°ì¡´ ì €ì¥ëœ RegTech ë°ì´í„° ë””ë ‰í† ë¦¬ë“¤
            data_dirs = [
                "data/blacklist/regtech_watchlist",
                "data/blacklist/regtech_comprehensive", 
                "data/blacklist/regtech_excel_parsed",
                "data/blacklist/regtech_integrated"
            ]
            
            for data_dir in data_dirs:
                if os.path.exists(data_dir):
                    # ìµœì‹  ì›”ë³„ ë°ì´í„° ë¡œë“œ
                    month_dirs = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])
                    
                    for month_dir in month_dirs[-3:]:  # ìµœê·¼ 3ê°œì›”
                        month_path = os.path.join(data_dir, month_dir)
                        
                        # IP íŒŒì¼ë“¤ ì°¾ê¸°
                        ip_files = glob.glob(f"{month_path}/*ips*.txt")
                        
                        for ip_file in ip_files:
                            try:
                                with open(ip_file, 'r') as f:
                                    for line in f:
                                        ip = line.strip()
                                        if self._is_valid_public_ip(ip):
                                            cached_ips.add(ip)
                            except Exception as e:
                                continue
            
            if cached_ips:
                print(f"      âœ… ìºì‹œì—ì„œ {len(cached_ips)}ê°œ IP ë¡œë“œ")
            
        except Exception as e:
            print(f"      âŒ ìºì‹œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return cached_ips
    
    def _login(self):
        """RegTech ë¡œê·¸ì¸"""
        if self._logged_in:
            return True
        
        try:
            # ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì†
            login_url = f"{self.base_url}/member/login"
            login_page = self.session.get(login_url, timeout=30)
            
            if login_page.status_code != 200:
                return False
            
            # ë¡œê·¸ì¸ ë°ì´í„°
            login_data = {
                'username': self.username,
                'password': self.password
            }
            
            # ë¡œê·¸ì¸ ìš”ì²­
            login_response = self.session.post(login_url, data=login_data, timeout=30, allow_redirects=True)
            
            # ë¡œê·¸ì¸ ì„±ê³µ í™•ì¸
            if 'login' not in login_response.url.lower():
                self._logged_in = True
                return True
            
            return False
            
        except Exception as e:
            print(f"         âŒ ë¡œê·¸ì¸ ì˜¤ë¥˜: {e}")
            return False
    
    def _extract_ips_from_html(self, html_content):
        """HTMLì—ì„œ IP ì¶”ì¶œ"""
        page_ips = set()
        
        try:
            # IP íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ
            ip_pattern = r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b'
            found_ips = re.findall(ip_pattern, html_content)
            
            for ip in found_ips:
                if self._is_valid_public_ip(ip):
                    page_ips.add(ip)
        
        except Exception as e:
            print(f"         âŒ HTML IP ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return page_ips
    
    def _is_valid_public_ip(self, ip_string):
        """ê³µì¸ IP ìœ íš¨ì„± ê²€ì¦"""
        try:
            parts = ip_string.split('.')
            if len(parts) != 4:
                return False
            
            for part in parts:
                num = int(part)
                if not (0 <= num <= 255):
                    return False
            
            # ì‚¬ì„¤ IPë‚˜ ë¡œì»¬ IP ì œì™¸
            if (ip_string.startswith(('192.168.', '10.', '172.')) or
                ip_string.startswith(('127.', '0.0.', '255.255.')) or
                ip_string in ['0.0.0.0', '255.255.255.255']):
                return False
            
            return True
            
        except:
            return False
    
    def get_source_info(self):
        """ì†ŒìŠ¤ ì •ë³´ ë°˜í™˜"""
        return {
            'name': self.name,
            'description': self.description,
            'type': 'regtech_portal',
            'priority': self.priority,
            'requires_auth': True,
            'data_types': ['excel_files', 'web_scraping', 'cached_data'],
            'update_frequency': 'daily',
            'reliability': 'high'
        }