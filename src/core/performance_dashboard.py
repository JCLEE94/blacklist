"""
ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

ì´ ëª¨ë“ˆì€ Blacklist ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ 
ì‹œê°í™”í•˜ëŠ” ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import time
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import threading
from collections import defaultdict, deque
import psutil
import sqlite3

from flask import Blueprint, render_template_string, jsonify, request
from loguru import logger

try:
    from src.utils.performance_cache import get_global_performance_cache
    from src.utils.async_processor import get_global_async_processor
    from src.utils.memory_optimizer import get_global_memory_optimizer
except ImportError:
    # í´ë°± ì„í¬íŠ¸
    get_global_performance_cache = lambda: None
    get_global_async_processor = lambda: None
    get_global_memory_optimizer = lambda: None


@dataclass
class PerformanceMetric:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    timestamp: datetime
    response_time_ms: float
    memory_usage_mb: float
    cpu_usage_percent: float
    active_connections: int
    cache_hit_rate: float
    database_queries: int
    errors_count: int


@dataclass
class AlertRule:
    """ì•Œë¦¼ ê·œì¹™"""
    name: str
    condition: str  # "response_time > 1000", "memory_usage > 80"
    severity: str   # "warning", "critical"
    enabled: bool = True
    last_triggered: Optional[datetime] = None


class PerformanceDashboard:
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ"""
    
    def __init__(self, max_metrics: int = 1000):
        self.max_metrics = max_metrics
        self.metrics_history = deque(maxlen=max_metrics)
        self.alert_rules = []
        self.active_alerts = []
        
        # ì‹¤ì‹œê°„ ë°ì´í„°
        self.current_connections = 0
        self.request_count = 0
        self.error_count = 0
        self.total_response_time = 0.0
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self._lock = threading.RLock()
        
        # ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
        self.monitoring_active = False
        self.monitoring_thread = None
        
        # ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •
        self._setup_default_alerts()
        
        logger.info("Performance dashboard initialized")

    def _setup_default_alerts(self):
        """ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •"""
        default_rules = [
            AlertRule("High Response Time", "response_time_ms > 1000", "warning"),
            AlertRule("Critical Response Time", "response_time_ms > 5000", "critical"),
            AlertRule("High Memory Usage", "memory_usage_mb > 500", "warning"),
            AlertRule("Critical Memory Usage", "memory_usage_mb > 1000", "critical"),
            AlertRule("High CPU Usage", "cpu_usage_percent > 80", "warning"),
            AlertRule("Low Cache Hit Rate", "cache_hit_rate < 50", "warning"),
            AlertRule("High Error Rate", "errors_count > 10", "critical"),
        ]
        
        self.alert_rules.extend(default_rules)

    def record_request(self, response_time_ms: float, status_code: int = 200):
        """ìš”ì²­ ê¸°ë¡"""
        with self._lock:
            self.request_count += 1
            self.total_response_time += response_time_ms
            
            if status_code >= 400:
                self.error_count += 1

    def record_connection(self, delta: int):
        """ì—°ê²° ìˆ˜ ë³€ê²½ ê¸°ë¡"""
        with self._lock:
            self.current_connections = max(0, self.current_connections + delta)

    def collect_metrics(self) -> PerformanceMetric:
        """í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        with self._lock:
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            memory = psutil.virtual_memory()
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            # í”„ë¡œì„¸ìŠ¤ ë©”íŠ¸ë¦­
            process = psutil.Process()
            process_memory_mb = process.memory_info().rss / 1024 / 1024
            
            # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
            avg_response_time = (
                self.total_response_time / self.request_count 
                if self.request_count > 0 else 0.0
            )
            
            # ìºì‹œ ë©”íŠ¸ë¦­
            cache_hit_rate = 0.0
            try:
                cache = get_global_performance_cache()
                if cache:
                    stats = cache.get_stats()
                    cache_hit_rate = stats.get("hit_rate_percent", 0.0)
            except Exception:
                pass
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìˆ˜ (ì¶”ì •)
            db_queries = self.request_count * 1.5  # í‰ê· ì ìœ¼ë¡œ ìš”ì²­ë‹¹ 1.5ê°œ ì¿¼ë¦¬
            
            metric = PerformanceMetric(
                timestamp=datetime.now(),
                response_time_ms=avg_response_time,
                memory_usage_mb=process_memory_mb,
                cpu_usage_percent=cpu_percent,
                active_connections=self.current_connections,
                cache_hit_rate=cache_hit_rate,
                database_queries=int(db_queries),
                errors_count=self.error_count
            )
            
            # ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì €ì¥
            self.metrics_history.append(metric)
            
            # ì•Œë¦¼ ê²€ì‚¬
            self._check_alerts(metric)
            
            return metric

    def _check_alerts(self, metric: PerformanceMetric):
        """ì•Œë¦¼ ê·œì¹™ ê²€ì‚¬"""
        metric_dict = asdict(metric)
        current_time = datetime.now()
        
        for rule in self.alert_rules:
            if not rule.enabled:
                continue
            
            try:
                # ì¡°ê±´ í‰ê°€
                condition = rule.condition
                for key, value in metric_dict.items():
                    if isinstance(value, (int, float)):
                        condition = condition.replace(key, str(value))
                
                if eval(condition):
                    # ì•Œë¦¼ ë°œìƒ (ì¤‘ë³µ ë°©ì§€: 5ë¶„ ë‚´ ë™ì¼ ì•Œë¦¼ ë¬´ì‹œ)
                    if (rule.last_triggered is None or 
                        current_time - rule.last_triggered > timedelta(minutes=5)):
                        
                        alert = {
                            "rule_name": rule.name,
                            "severity": rule.severity,
                            "message": f"{rule.name}: {rule.condition}",
                            "timestamp": current_time.isoformat(),
                            "metric_value": metric_dict
                        }
                        
                        self.active_alerts.append(alert)
                        rule.last_triggered = current_time
                        
                        logger.warning(f"Performance alert: {alert['message']}")
                        
                        # ìµœëŒ€ ì•Œë¦¼ ìˆ˜ ì œí•œ
                        if len(self.active_alerts) > 100:
                            self.active_alerts = self.active_alerts[-50:]
                
            except Exception as e:
                logger.error(f"Alert rule evaluation failed: {rule.condition} - {e}")

    def get_dashboard_data(self) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë°˜í™˜"""
        with self._lock:
            current_metric = self.collect_metrics()
            
            # íˆìŠ¤í† ë¦¬ ë°ì´í„° (ìµœê·¼ 100ê°œ)
            recent_metrics = list(self.metrics_history)[-100:]
            
            # ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„
            timestamps = [m.timestamp.isoformat() for m in recent_metrics]
            response_times = [m.response_time_ms for m in recent_metrics]
            memory_usage = [m.memory_usage_mb for m in recent_metrics]
            cpu_usage = [m.cpu_usage_percent for m in recent_metrics]
            cache_hit_rates = [m.cache_hit_rate for m in recent_metrics]
            
            # í†µê³„ ê³„ì‚°
            if recent_metrics:
                avg_response_time = sum(response_times) / len(response_times)
                max_response_time = max(response_times)
                min_response_time = min(response_times)
                avg_memory_usage = sum(memory_usage) / len(memory_usage)
                avg_cpu_usage = sum(cpu_usage) / len(cpu_usage)
                avg_cache_hit_rate = sum(cache_hit_rates) / len(cache_hit_rates)
            else:
                avg_response_time = max_response_time = min_response_time = 0
                avg_memory_usage = avg_cpu_usage = avg_cache_hit_rate = 0
            
            # ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°
            performance_grade = self._calculate_performance_grade(current_metric)
            
            # í™œì„± ì•Œë¦¼ (ìµœê·¼ 10ê°œ)
            recent_alerts = self.active_alerts[-10:] if self.active_alerts else []
            
            return {
                "current_metrics": asdict(current_metric),
                "statistics": {
                    "avg_response_time_ms": round(avg_response_time, 2),
                    "max_response_time_ms": round(max_response_time, 2),
                    "min_response_time_ms": round(min_response_time, 2),
                    "avg_memory_usage_mb": round(avg_memory_usage, 2),
                    "avg_cpu_usage_percent": round(avg_cpu_usage, 2),
                    "avg_cache_hit_rate": round(avg_cache_hit_rate, 2),
                    "total_requests": self.request_count,
                    "total_errors": self.error_count,
                    "error_rate_percent": round(
                        (self.error_count / self.request_count * 100) 
                        if self.request_count > 0 else 0, 2
                    )
                },
                "time_series": {
                    "timestamps": timestamps,
                    "response_times": response_times,
                    "memory_usage": memory_usage,
                    "cpu_usage": cpu_usage,
                    "cache_hit_rates": cache_hit_rates
                },
                "performance_grade": performance_grade,
                "active_alerts": recent_alerts,
                "system_info": self._get_system_info(),
                "optimization_suggestions": self._get_optimization_suggestions(current_metric)
            }

    def _calculate_performance_grade(self, metric: PerformanceMetric) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°"""
        score = 100
        grade = "A+"
        
        # ì‘ë‹µ ì‹œê°„ ì ìˆ˜ (40ì )
        if metric.response_time_ms <= 50:
            response_score = 40
        elif metric.response_time_ms <= 200:
            response_score = 35
        elif metric.response_time_ms <= 1000:
            response_score = 25
        elif metric.response_time_ms <= 5000:
            response_score = 10
        else:
            response_score = 0
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš© ì ìˆ˜ (25ì )
        if metric.memory_usage_mb <= 100:
            memory_score = 25
        elif metric.memory_usage_mb <= 300:
            memory_score = 20
        elif metric.memory_usage_mb <= 500:
            memory_score = 15
        elif metric.memory_usage_mb <= 1000:
            memory_score = 10
        else:
            memory_score = 0
        
        # CPU ì‚¬ìš© ì ìˆ˜ (20ì )
        if metric.cpu_usage_percent <= 20:
            cpu_score = 20
        elif metric.cpu_usage_percent <= 50:
            cpu_score = 15
        elif metric.cpu_usage_percent <= 80:
            cpu_score = 10
        elif metric.cpu_usage_percent <= 95:
            cpu_score = 5
        else:
            cpu_score = 0
        
        # ìºì‹œ íš¨ìœ¨ì„± ì ìˆ˜ (15ì )
        if metric.cache_hit_rate >= 90:
            cache_score = 15
        elif metric.cache_hit_rate >= 75:
            cache_score = 12
        elif metric.cache_hit_rate >= 50:
            cache_score = 8
        elif metric.cache_hit_rate >= 25:
            cache_score = 4
        else:
            cache_score = 0
        
        total_score = response_score + memory_score + cpu_score + cache_score
        
        # ë“±ê¸‰ ê³„ì‚°
        if total_score >= 95:
            grade = "A+"
        elif total_score >= 90:
            grade = "A"
        elif total_score >= 85:
            grade = "A-"
        elif total_score >= 80:
            grade = "B+"
        elif total_score >= 75:
            grade = "B"
        elif total_score >= 70:
            grade = "B-"
        elif total_score >= 65:
            grade = "C+"
        elif total_score >= 60:
            grade = "C"
        elif total_score >= 55:
            grade = "C-"
        elif total_score >= 50:
            grade = "D"
        else:
            grade = "F"
        
        return {
            "total_score": total_score,
            "grade": grade,
            "breakdown": {
                "response_time": response_score,
                "memory_usage": memory_score,
                "cpu_usage": cpu_score,
                "cache_efficiency": cache_score
            }
        }

    def _get_system_info(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
        try:
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            return {
                "cpu_count": psutil.cpu_count(),
                "memory_total_gb": round(memory.total / 1024 / 1024 / 1024, 2),
                "disk_total_gb": round(disk.total / 1024 / 1024 / 1024, 2),
                "disk_free_gb": round(disk.free / 1024 / 1024 / 1024, 2),
                "python_version": f"{psutil.version_info}",
                "uptime_seconds": time.time() - psutil.boot_time()
            }
        except Exception as e:
            logger.error(f"Failed to get system info: {e}")
            return {}

    def _get_optimization_suggestions(self, metric: PerformanceMetric) -> List[str]:
        """ìµœì í™” ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        if metric.response_time_ms > 1000:
            suggestions.append("ğŸš€ API ì‘ë‹µ ì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤. ìºì‹± ì „ëµì„ ê²€í† í•˜ì„¸ìš”.")
        
        if metric.memory_usage_mb > 500:
            suggestions.append("ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        if metric.cpu_usage_percent > 80:
            suggestions.append("âš¡ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        if metric.cache_hit_rate < 75:
            suggestions.append("ğŸ“Š ìºì‹œ ì ì¤‘ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. ìºì‹œ TTL ì„¤ì •ì„ ê²€í† í•˜ì„¸ìš”.")
        
        if metric.errors_count > 5:
            suggestions.append("âŒ ì˜¤ë¥˜ ë°œìƒë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ì—ëŸ¬ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        if len(suggestions) == 0:
            suggestions.append("âœ… ì‹œìŠ¤í…œì´ ìµœì  ìƒíƒœë¡œ ë™ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        return suggestions

    def start_monitoring(self, interval: float = 10.0):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            args=(interval,),
            daemon=True,
            name="performance_monitor"
        )
        self.monitoring_thread.start()
        logger.info(f"Performance monitoring started (interval: {interval}s)")

    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        logger.info("Performance monitoring stopped")

    def _monitoring_loop(self, interval: float):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring_active:
            try:
                self.collect_metrics()
                time.sleep(interval)
            except Exception as e:
                logger.error(f"Performance monitoring error: {e}")
                time.sleep(interval)

    def reset_counters(self):
        """ì¹´ìš´í„° ë¦¬ì…‹"""
        with self._lock:
            self.request_count = 0
            self.error_count = 0
            self.total_response_time = 0.0
            self.active_alerts.clear()
            logger.info("Performance counters reset")


# ê¸€ë¡œë²Œ ëŒ€ì‹œë³´ë“œ ì¸ìŠ¤í„´ìŠ¤
_global_dashboard = None

def get_global_dashboard() -> PerformanceDashboard:
    """ê¸€ë¡œë²Œ ëŒ€ì‹œë³´ë“œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_dashboard
    
    if _global_dashboard is None:
        _global_dashboard = PerformanceDashboard()
        _global_dashboard.start_monitoring()
    
    return _global_dashboard


# Flask ë¸”ë£¨í”„ë¦°íŠ¸
dashboard_bp = Blueprint('performance_dashboard', __name__)

@dashboard_bp.route('/performance')
def performance_dashboard():
    """ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ í˜ì´ì§€"""
    return render_template_string(DASHBOARD_HTML_TEMPLATE)

@dashboard_bp.route('/api/performance/metrics')
def get_performance_metrics():
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ API"""
    dashboard = get_global_dashboard()
    data = dashboard.get_dashboard_data()
    return jsonify(data)

@dashboard_bp.route('/api/performance/reset', methods=['POST'])
def reset_performance_counters():
    """ì„±ëŠ¥ ì¹´ìš´í„° ë¦¬ì…‹ API"""
    dashboard = get_global_dashboard()
    dashboard.reset_counters()
    return jsonify({"success": True, "message": "Performance counters reset"})


# HTML í…œí”Œë¦¿
DASHBOARD_HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blacklist System - Performance Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; }
        .header { text-align: center; margin-bottom: 30px; }
        .metrics-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin-bottom: 30px; }
        .metric-card { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .metric-value { font-size: 2em; font-weight: bold; color: #333; }
        .metric-label { color: #666; margin-top: 5px; }
        .chart-container { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 20px; }
        .grade { font-size: 3em; font-weight: bold; text-align: center; padding: 20px; }
        .grade.A { color: #4CAF50; }
        .grade.B { color: #FF9800; }
        .grade.C { color: #FF5722; }
        .grade.D, .grade.F { color: #F44336; }
        .alerts { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .alert { padding: 10px; margin: 5px 0; border-radius: 4px; }
        .alert.warning { background: #FFF3CD; border-left: 4px solid #FF9800; }
        .alert.critical { background: #F8D7DA; border-left: 4px solid #F44336; }
        .suggestions { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ Blacklist System Performance Dashboard</h1>
            <p>ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” í˜„í™©</p>
        </div>

        <div class="metrics-grid">
            <div class="metric-card">
                <div class="metric-value" id="response-time">-</div>
                <div class="metric-label">í‰ê·  ì‘ë‹µì‹œê°„ (ms)</div>
            </div>
            <div class="metric-card">
                <div class="metric-value" id="memory-usage">-</div>
                <div class="metric-label">ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)</div>
            </div>
            <div class="metric-card">
                <div class="metric-value" id="cpu-usage">-</div>
                <div class="metric-label">CPU ì‚¬ìš©ë¥  (%)</div>
            </div>
            <div class="metric-card">
                <div class="metric-value" id="cache-hit-rate">-</div>
                <div class="metric-label">ìºì‹œ ì ì¤‘ë¥  (%)</div>
            </div>
            <div class="metric-card">
                <div class="metric-value" id="active-connections">-</div>
                <div class="metric-label">í™œì„± ì—°ê²° ìˆ˜</div>
            </div>
            <div class="metric-card">
                <div class="grade" id="performance-grade">-</div>
                <div class="metric-label">ì„±ëŠ¥ ë“±ê¸‰</div>
            </div>
        </div>

        <div class="chart-container">
            <h3>ğŸ“ˆ ì‘ë‹µì‹œê°„ íŠ¸ë Œë“œ</h3>
            <canvas id="responseTimeChart" width="400" height="100"></canvas>
        </div>

        <div class="chart-container">
            <h3>ğŸ’¾ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰</h3>
            <canvas id="resourceChart" width="400" height="100"></canvas>
        </div>

        <div class="alerts">
            <h3>ğŸš¨ í™œì„± ì•Œë¦¼</h3>
            <div id="alerts-container">ë¡œë”© ì¤‘...</div>
        </div>

        <div class="suggestions">
            <h3>ğŸ’¡ ìµœì í™” ì œì•ˆ</h3>
            <div id="suggestions-container">ë¡œë”© ì¤‘...</div>
        </div>
    </div>

    <script>
        let responseTimeChart, resourceChart;
        
        function initCharts() {
            // ì‘ë‹µì‹œê°„ ì°¨íŠ¸
            const rtCtx = document.getElementById('responseTimeChart').getContext('2d');
            responseTimeChart = new Chart(rtCtx, {
                type: 'line',
                data: {
                    labels: [],
                    datasets: [{
                        label: 'ì‘ë‹µì‹œê°„ (ms)',
                        data: [],
                        borderColor: '#4CAF50',
                        tension: 0.1
                    }]
                },
                options: {
                    responsive: true,
                    scales: {
                        y: { beginAtZero: true }
                    }
                }
            });

            // ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì°¨íŠ¸
            const resCtx = document.getElementById('resourceChart').getContext('2d');
            resourceChart = new Chart(resCtx, {
                type: 'line',
                data: {
                    labels: [],
                    datasets: [
                        {
                            label: 'ë©”ëª¨ë¦¬ (MB)',
                            data: [],
                            borderColor: '#2196F3',
                            tension: 0.1
                        },
                        {
                            label: 'CPU (%)',
                            data: [],
                            borderColor: '#FF9800',
                            tension: 0.1
                        }
                    ]
                },
                options: {
                    responsive: true,
                    scales: {
                        y: { beginAtZero: true }
                    }
                }
            });
        }

        function updateDashboard() {
            fetch('/api/performance/metrics')
                .then(response => response.json())
                .then(data => {
                    // ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                    document.getElementById('response-time').textContent = 
                        data.statistics.avg_response_time_ms.toFixed(1);
                    document.getElementById('memory-usage').textContent = 
                        data.current_metrics.memory_usage_mb.toFixed(1);
                    document.getElementById('cpu-usage').textContent = 
                        data.current_metrics.cpu_usage_percent.toFixed(1);
                    document.getElementById('cache-hit-rate').textContent = 
                        data.current_metrics.cache_hit_rate.toFixed(1);
                    document.getElementById('active-connections').textContent = 
                        data.current_metrics.active_connections;

                    // ì„±ëŠ¥ ë“±ê¸‰
                    const gradeElement = document.getElementById('performance-grade');
                    gradeElement.textContent = data.performance_grade.grade;
                    gradeElement.className = 'grade ' + data.performance_grade.grade.charAt(0);

                    // ì°¨íŠ¸ ì—…ë°ì´íŠ¸
                    updateCharts(data.time_series);

                    // ì•Œë¦¼ ì—…ë°ì´íŠ¸
                    updateAlerts(data.active_alerts);

                    // ì œì•ˆ ì—…ë°ì´íŠ¸
                    updateSuggestions(data.optimization_suggestions);
                })
                .catch(error => console.error('Error:', error));
        }

        function updateCharts(timeSeries) {
            const labels = timeSeries.timestamps.map(ts => 
                new Date(ts).toLocaleTimeString()
            );

            // ì‘ë‹µì‹œê°„ ì°¨íŠ¸
            responseTimeChart.data.labels = labels;
            responseTimeChart.data.datasets[0].data = timeSeries.response_times;
            responseTimeChart.update();

            // ë¦¬ì†ŒìŠ¤ ì°¨íŠ¸
            resourceChart.data.labels = labels;
            resourceChart.data.datasets[0].data = timeSeries.memory_usage;
            resourceChart.data.datasets[1].data = timeSeries.cpu_usage;
            resourceChart.update();
        }

        function updateAlerts(alerts) {
            const container = document.getElementById('alerts-container');
            if (alerts.length === 0) {
                container.innerHTML = '<p>âœ… í™œì„± ì•Œë¦¼ì´ ì—†ìŠµë‹ˆë‹¤.</p>';
                return;
            }

            container.innerHTML = alerts.map(alert => 
                `<div class="alert ${alert.severity}">
                    <strong>${alert.rule_name}</strong> - ${alert.message}
                    <br><small>${new Date(alert.timestamp).toLocaleString()}</small>
                </div>`
            ).join('');
        }

        function updateSuggestions(suggestions) {
            const container = document.getElementById('suggestions-container');
            container.innerHTML = suggestions.map(suggestion => 
                `<p>${suggestion}</p>`
            ).join('');
        }

        // ì´ˆê¸°í™”
        document.addEventListener('DOMContentLoaded', function() {
            initCharts();
            updateDashboard();
            setInterval(updateDashboard, 5000); // 5ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
        });
    </script>
</body>
</html>
"""


if __name__ == "__main__":
    """ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ê²€ì¦"""
    import sys
    
    dashboard = PerformanceDashboard()
    dashboard.start_monitoring(interval=1.0)
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        import random
        
        for i in range(10):
            # ê°€ìƒ ìš”ì²­ ê¸°ë¡
            response_time = random.uniform(50, 500)
            status_code = 200 if random.random() > 0.1 else 500
            dashboard.record_request(response_time, status_code)
            
            # ê°€ìƒ ì—°ê²° ë³€í™”
            if random.random() > 0.5:
                dashboard.record_connection(1)
            else:
                dashboard.record_connection(-1)
            
            time.sleep(0.5)
        
        # ëŒ€ì‹œë³´ë“œ ë°ì´í„° í™•ì¸
        data = dashboard.get_dashboard_data()
        
        print("âœ… ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ê²€ì¦ ì™„ë£Œ")
        print(f"ğŸ“Š í˜„ì¬ ë©”íŠ¸ë¦­: {data['current_metrics']}")
        print(f"ğŸ¯ ì„±ëŠ¥ ë“±ê¸‰: {data['performance_grade']['grade']} ({data['performance_grade']['total_score']}ì )")
        print(f"ğŸ’¡ ìµœì í™” ì œì•ˆ: {len(data['optimization_suggestions'])}ê°œ")
        
        dashboard.stop_monitoring()
        sys.exit(0)
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)