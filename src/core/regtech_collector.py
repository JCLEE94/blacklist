#!/usr/bin/env python3
"""
REGTECH ÏûêÎèô ÏàòÏßë ÏãúÏä§ÌÖú - HAR Î∂ÑÏÑù Í∏∞Î∞ò Ï†ïÎ¶¨Îêú Î≤ÑÏ†Ñ
"""

import os
import json
import logging
import time
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from pathlib import Path
import threading
from dataclasses import dataclass
import re
from bs4 import BeautifulSoup
import io
import tempfile

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    logging.warning("pandas not available - Excel download will not work")

from src.core.models import BlacklistEntry
from src.config.settings import settings

logger = logging.getLogger(__name__)


@dataclass
class RegtechCollectionStats:
    """REGTECH ÏàòÏßë ÌÜµÍ≥Ñ"""
    start_time: datetime
    end_time: Optional[datetime] = None
    total_collected: int = 0
    successful_collections: int = 0
    failed_collections: int = 0
    pages_processed: int = 0
    duplicate_count: int = 0
    error_count: int = 0
    source_method: str = "unknown"


class RegtechCollector:
    """
    REGTECH ÏûêÎèô ÏàòÏßë ÏãúÏä§ÌÖú - HAR Î∂ÑÏÑù Í∏∞Î∞ò Íµ¨ÌòÑ
    """
    
    def __init__(self, data_dir: str, cache_backend=None):
        self.data_dir = data_dir
        self.regtech_dir = os.path.join(data_dir, 'regtech')
        
        # ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
        os.makedirs(self.regtech_dir, exist_ok=True)
        
        # REGTECH API ÏÑ§Ï†ï (Ïø†ÌÇ§ Í∏∞Î∞ò Ïù∏Ï¶ù)
        self.base_url = "https://regtech.fsec.or.kr"
        self.advisory_endpoint = "/fcti/securityAdvisory/advisoryList"
        
        # Ïø†ÌÇ§ ÏÑ§Ï†ï (e.ps1ÏóêÏÑú Ï∂îÏ∂úÌïú Í∞íÎì§)
        self.cookies = {
            '_ga': 'GA1.1.1689204774.1752555033',
            'regtech-front': '2F3B7CE1B26084FCD546BDB56CE9ABAC',
            'regtech-va': 'BearereyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJuZXh0cmFkZSIsIm9yZ2FubmFtZSI6IuuEpeyKpO2KuOugiOydtOuTnCIsImlkIjoibmV4dHJhZGUiLCJleHAiOjE3NTI4Mjk2NDUsInVzZXJuYW1lIjoi7J6l7ZmN7KSAIn0.ha36VHXTf1AnziAChasI68mh9nrDawyrKRXyXKV6liPCOA1MFnoR5kTg3pSw3RNM_zkDD2NnfX5PcbdzwPET1w',
            '_ga_7WRDYHF66J': 'GS2.1.s1752743223$o3$g1$t1752746099$j38$l0$h0'
        }
        
        # ÏàòÏßë ÌÜµÍ≥Ñ
        self.stats = RegtechCollectionStats(start_time=datetime.now())
        
        logger.info(f"REGTECH ÏàòÏßëÍ∏∞ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å (Ïø†ÌÇ§ Í∏∞Î∞ò Ïù∏Ï¶ù): {self.regtech_dir}")
    
    def collect_from_web(self, max_pages: int = 5, page_size: int = 100, 
                        parallel_workers: int = 1, start_date: str = None, 
                        end_date: str = None) -> List[BlacklistEntry]:
        """
        REGTECH Excel Îã§Ïö¥Î°úÎìú Î∞©ÏãùÏúºÎ°ú Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
        """
        logger.info(f"üîÑ REGTECH Excel Îã§Ïö¥Î°úÎìú ÏàòÏßë ÏãúÏûë")
        logger.info(f"üìù ÏàòÏßë ÏßÑÌñâ ÏÉÅÌô©ÏùÑ ÏÉÅÏÑ∏Ìûà Î°úÍπÖÌï©ÎãàÎã§")
        
        # ÏùºÏùº ÏàòÏßë Ïó¨Î∂Ä ÌôïÏù∏
        is_daily_collection = False
        
        # Í∏∞Î≥∏ ÎÇ†Ïßú ÏÑ§Ï†ï (ÌååÎùºÎØ∏ÌÑ∞Î°ú Ï†úÍ≥µÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞)
        if not start_date or not end_date:
            end_dt = datetime.now()
            start_dt = end_dt - timedelta(days=90)  # 90ÏùºÎ°ú ÌôïÎåÄ
            start_date = start_dt.strftime('%Y%m%d')
            end_date = end_dt.strftime('%Y%m%d')
        else:
            # ÏãúÏûëÏùºÍ≥º Ï¢ÖÎ£åÏùºÏù¥ Í∞ôÏúºÎ©¥ ÏùºÏùº ÏàòÏßë
            if start_date == end_date:
                is_daily_collection = True
                logger.info(f"üìÖ ÏùºÏùº ÏûêÎèô ÏàòÏßë Î™®Îìú: {start_date} ÌïòÎ£® Îç∞Ïù¥ÌÑ∞Îßå ÏàòÏßë")
        
        logger.info(f"üìÜ REGTECH ÏàòÏßë ÎÇ†Ïßú Î≤îÏúÑ: {start_date} ~ {end_date}")
        
        if is_daily_collection:
            logger.info(f"üîî ÏùºÏùº ÏàòÏßë Ïã§Ìñâ Ï§ë - Í∏àÏùº({start_date}) Ïã†Í∑ú ÌÉêÏßÄ IPÎßå ÏàòÏßëÌï©ÎãàÎã§")
        
        self.stats = RegtechCollectionStats(
            start_time=datetime.now(),
            source_method="excel_download"
        )
        
        try:
            # ÏÑ∏ÏÖò ÏÉùÏÑ± Î∞è Î°úÍ∑∏Ïù∏
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            })
            
            # Î°úÍ∑∏Ïù∏ ÏàòÌñâ
            logger.info("üîê REGTECH Î°úÍ∑∏Ïù∏ ÏãúÎèÑ Ï§ë...")
            if not self._perform_login(session):
                logger.error("‚ùå REGTECH Î°úÍ∑∏Ïù∏ Ïã§Ìå®")
                return []
            logger.info("‚úÖ REGTECH Î°úÍ∑∏Ïù∏ ÏÑ±Í≥µ")
            
            # Excel Îã§Ïö¥Î°úÎìú Î∞©ÏãùÏúºÎ°ú Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
            logger.info("üìä Excel Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú ÏãúÏûë...")
            collected_ips = self._download_excel_data(session, start_date, end_date)
            logger.info(f"üìã Excel Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å: {len(collected_ips)}Í∞ú IP ÏàòÏßë")
            
            if collected_ips:
                self.stats.total_collected = len(collected_ips)
                self.stats.successful_collections = len(collected_ips)
                self.stats.end_time = datetime.now()
                
                # ÏùºÏùº ÏàòÏßë Ïó¨Î∂Ä ÌôïÏù∏
                if start_date == end_date:
                    logger.info(f"‚úÖ REGTECH ÏùºÏùº ÏàòÏßë ÏôÑÎ£å ({start_date}): {len(collected_ips)}Í∞ú Ïã†Í∑ú IP Ï∂îÍ∞Ä")
                    logger.info(f"üìä Í∏àÏùº ÌÉêÏßÄ ÌÜµÍ≥Ñ:")
                    logger.info(f"   - Ïã†Í∑ú ÌÉêÏßÄ IP: {len(collected_ips)}Í∞ú")
                    logger.info(f"   - ÏàòÏßë ÏãúÍ∞Ñ: {self.stats.end_time - self.stats.start_time}")
                else:
                    logger.info(f"‚úÖ REGTECH Excel ÏàòÏßë ÏôÑÎ£å: {len(collected_ips)}Í∞ú IP")
                return collected_ips
            else:
                # Excel Îã§Ïö¥Î°úÎìú Ïã§Ìå®Ïãú Í∏∞Ï°¥ HTML ÌååÏã± Î∞©Ïãù ÏãúÎèÑ
                logger.warning("Excel Îã§Ïö¥Î°úÎìú Ïã§Ìå®, HTML ÌååÏã± Î∞©ÏãùÏúºÎ°ú Ïû¨ÏãúÎèÑ")
                return self._collect_html_fallback(session, start_date, end_date, max_pages, page_size)
            
        except Exception as e:
            logger.error(f"REGTECH ÏàòÏßë Ï§ë Ïò§Î•ò: {e}")
            self.stats.error_count += 1
            return []
    
    def _parse_html_response(self, html_content: str) -> List[BlacklistEntry]:
        """
        HAR Î∂ÑÏÑù Í∏∞Î∞ò HTML ÏùëÎãµ ÌååÏã± - Ïã§Ï†ú REGTECH ÌÖåÏù¥Î∏î Íµ¨Ï°∞ Í∏∞Î∞ò
        """
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            ip_entries = []
            
            # REGTECH ÏöîÏ£ºÏùò IP ÌÖåÏù¥Î∏î Ï∞æÍ∏∞
            tables = soup.find_all('table')
            
            for table in tables:
                # captionÏù¥ "ÏöîÏ£ºÏùò IP Î™©Î°ù"Ïù∏ ÌÖåÏù¥Î∏î Ï∞æÍ∏∞
                caption = table.find('caption')
                if caption and 'ÏöîÏ£ºÏùò IP' in caption.text:
                    logger.info("üìã ÏöîÏ£ºÏùò IP ÌÖåÏù¥Î∏î Î∞úÍ≤¨")
                    
                    # tbodyÏùò Î™®Îì† tr Ï∞æÍ∏∞
                    tbody = table.find('tbody')
                    if tbody:
                        rows = tbody.find_all('tr')
                        logger.info(f"üìä ÌÖåÏù¥Î∏îÏóêÏÑú {len(rows)}Í∞úÏùò Ìñâ Î∞úÍ≤¨")
                        
                        for row in rows:
                            cells = row.find_all('td')
                            
                            # REGTECH ÌÖåÏù¥Î∏î Íµ¨Ï°∞: IP, Íµ≠Í∞Ä, Îì±Î°ùÏÇ¨Ïú†, Îì±Î°ùÏùº, Ìï¥Ï†úÏùº, Ï°∞ÌöåÏàò
                            if len(cells) >= 6:
                                try:
                                    ip_text = cells[0].get_text(strip=True)
                                    country = cells[1].get_text(strip=True)
                                    
                                    # Îì±Î°ùÏÇ¨Ïú†ÏóêÏÑú attack_type Ï∂îÏ∂ú
                                    reason_cell = cells[2]
                                    attack_type = reason_cell.get_text(strip=True)
                                    
                                    # ÎÇ†Ïßú Ï†ïÎ≥¥
                                    detection_date = cells[3].get_text(strip=True)
                                    release_date = cells[4].get_text(strip=True) if len(cells) > 4 else ''
                                    views = cells[5].get_text(strip=True) if len(cells) > 5 else '0'
                                    
                                    # IP Ï£ºÏÜå Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù
                                    if self._is_valid_ip(ip_text):
                                        # extra_dataÏóê Ï∂îÍ∞Ä Ï†ïÎ≥¥ Ï†ÄÏû•
                                        extra_data = {
                                            'release_date': release_date,
                                            'views': views
                                        }
                                        
                                        ip_entry = BlacklistEntry(
                                            ip_address=ip_text,
                                            country=country,
                                            reason=attack_type,
                                            source='REGTECH',
                                            reg_date=detection_date,
                                            exp_date=release_date,
                                            is_active=True,
                                            threat_level='high',
                                            source_details={'type': 'REGTECH', 'attack': attack_type}
                                        )
                                        ip_entries.append(ip_entry)
                                        logger.debug(f"IP ÏàòÏßë: {ip_text} ({country}) - {attack_type}")
                                
                                except Exception as e:
                                    logger.debug(f"Ìñâ ÌååÏã± Ï§ë Ïò§Î•ò (Î¨¥Ïãú): {e}")
                                    continue
                    else:
                        # tbodyÍ∞Ä ÏóÜÎäî Í≤ΩÏö∞ Î™®Îì† tr Í≤ÄÏÉâ
                        rows = table.find_all('tr')
                        for row in rows[1:]:  # Ìó§Îçî Ï†úÏô∏
                            cells = row.find_all('td')
                            if len(cells) >= 4:
                                try:
                                    ip_text = cells[0].get_text(strip=True)
                                    if self._is_valid_ip(ip_text):
                                        country = cells[1].get_text(strip=True) if len(cells) > 1 else 'Unknown'
                                        attack_type = cells[2].get_text(strip=True) if len(cells) > 2 else 'REGTECH'
                                        detection_date = cells[3].get_text(strip=True) if len(cells) > 3 else datetime.now().strftime('%Y-%m-%d')
                                        
                                        ip_entry = BlacklistEntry(
                                            ip_address=ip_text,
                                            country=country,
                                            reason=attack_type,
                                            source='REGTECH',
                                            reg_date=detection_date,
                                            is_active=True,
                                            threat_level='high'
                                        )
                                        ip_entries.append(ip_entry)
                                except Exception as e:
                                    logger.debug(f"Ìñâ ÌååÏã± Ï§ë Ïò§Î•ò (Î¨¥Ïãú): {e}")
                                    continue
            
            # ÌÖåÏù¥Î∏îÏùÑ Ï∞æÏßÄ Î™ªÌïú Í≤ΩÏö∞ Í≤ΩÍ≥†
            if not ip_entries:
                logger.warning("ÏöîÏ£ºÏùò IP ÌÖåÏù¥Î∏îÏùÑ Ï∞æÏßÄ Î™ªÌñàÍ±∞ÎÇò Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏùå")
                
                # ÎîîÎ≤ÑÍπÖÏùÑ ÏúÑÌï¥ Ï¥ù Í±¥Ïàò ÌôïÏù∏
                total_elem = soup.find('em')
                if total_elem:
                    total_text = total_elem.get_text(strip=True)
                    logger.info(f"ÌéòÏù¥ÏßÄÏóê ÌëúÏãúÎêú Ï¥ù Í±¥Ïàò: {total_text}")
            
            return ip_entries
            
        except Exception as e:
            logger.error(f"HTML ÌååÏã± Ï§ë Ïò§Î•ò: {e}")
            return []
    
    def _perform_login(self, session: requests.Session) -> bool:
        """REGTECH Ïø†ÌÇ§ Í∏∞Î∞ò Ïù∏Ï¶ù ÏÑ§Ï†ï (e.ps1 Î∞©Ïãù)"""
        try:
            logger.info("REGTECH Ïø†ÌÇ§ Í∏∞Î∞ò Ïù∏Ï¶ù ÏÑ§Ï†ï ÏãúÏûë")
            
            # Í∏∞Ï°¥ Ïø†ÌÇ§ ÏÑ§Ï†ï
            for name, value in self.cookies.items():
                session.cookies.set(name, value, domain='.regtech.fsec.or.kr')
            
            # Ï∂îÍ∞Ä Ìó§Îçî ÏÑ§Ï†ï
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'same-origin'
            })
            
            # Ïø†ÌÇ§ Ïú†Ìö®ÏÑ± Í∞ÑÎã® ÌÖåÏä§Ìä∏
            test_resp = session.get(f"{self.base_url}/fcti/securityAdvisory/advisoryList", timeout=30)
            if test_resp.status_code == 200:
                logger.info("REGTECH Ïø†ÌÇ§ Í∏∞Î∞ò Ïù∏Ï¶ù ÏÑ±Í≥µ")
                return True
            else:
                logger.error(f"REGTECH Ïø†ÌÇ§ Ïù∏Ï¶ù Ïã§Ìå®: {test_resp.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"REGTECH Ïø†ÌÇ§ Ïù∏Ï¶ù Ï§ë Ïò§Î•ò: {e}")
            return False
            
            logger.info(f"REGTECH Î°úÍ∑∏Ïù∏ ÏãúÏûë: {username}")
            
            # 1. Î©îÏù∏ ÌéòÏù¥ÏßÄ Ï†ëÏÜç (ÏÑ∏ÏÖò Ï¥àÍ∏∞Ìôî)
            main_resp = session.get(f"{self.base_url}/main/main", timeout=30)
            if main_resp.status_code != 200:
                logger.error(f"Î©îÏù∏ ÌéòÏù¥ÏßÄ Ï†ëÏÜç Ïã§Ìå®: {main_resp.status_code}")
                return False
            time.sleep(1)
            
            # 2. Î°úÍ∑∏Ïù∏ Ìèº Ï†ëÏÜç
            form_resp = session.get(f"{self.base_url}/login/loginForm", timeout=30)
            if form_resp.status_code != 200:
                logger.error(f"Î°úÍ∑∏Ïù∏ Ìèº Ï†ëÏÜç Ïã§Ìå®: {form_resp.status_code}")
                return False
            time.sleep(1)
            
            # 3. Ïã§Ï†ú Î°úÍ∑∏Ïù∏ ÏàòÌñâ
            login_data = {
                'login_error': '',
                'txId': '',
                'token': '',
                'memberId': '',
                'smsTimeExcess': 'N',
                'username': username,
                'password': password
            }
            
            login_resp = session.post(
                f"{self.base_url}/login/addLogin",
                data=login_data,
                headers={
                    'Content-Type': 'application/x-www-form-urlencoded',
                    'Origin': self.base_url,
                    'Referer': f"{self.base_url}/login/loginForm"
                },
                allow_redirects=True,
                timeout=30
            )
            
            if login_resp.status_code != 200:
                logger.error(f"Î°úÍ∑∏Ïù∏ ÏöîÏ≤≠ Ïã§Ìå®: {login_resp.status_code}")
                return False
            
            # Bearer Token ÌôïÏù∏ Î∞è Authorization Ìó§Îçî ÏÑ§Ï†ï
            bearer_token = None
            for cookie in session.cookies:
                if cookie.name == 'regtech-va' and cookie.value.startswith('Bearer'):
                    bearer_token = cookie.value
                    session.headers['Authorization'] = bearer_token
                    logger.info("Bearer Token ÌöçÎìù Î∞è Ìó§Îçî ÏÑ§Ï†ï ÏôÑÎ£å")
                    break
            
            if not bearer_token:
                logger.error("Bearer TokenÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏùå")
                return False
            
            # ÏûêÎèô Ïù∏Ï¶ù Î™®ÎìàÏóê ÌÜ†ÌÅ∞ Ï†ÄÏû•
            try:
                from .regtech_auto_login import get_regtech_auth
                auth = get_regtech_auth()
                auth._current_token = bearer_token
                auth._save_token_to_file(bearer_token)
            except:
                pass
            
            logger.info("REGTECH Î°úÍ∑∏Ïù∏ ÏÑ±Í≥µ")
            return True
                
        except Exception as e:
            logger.error(f"REGTECH Î°úÍ∑∏Ïù∏ Ï§ë Ïò§Î•ò: {e}")
            return False
    
    def _download_excel_data(self, session: requests.Session, start_date: str, end_date: str) -> List[BlacklistEntry]:
        """Excel ÌååÏùº Îã§Ïö¥Î°úÎìú Î∞©ÏãùÏúºÎ°ú Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        if not PANDAS_AVAILABLE:
            logger.error("pandasÍ∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏïÑ Excel Îã§Ïö¥Î°úÎìúÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§")
            return []
        
        try:
            # Excel Îã§Ïö¥Î°úÎìú ÏóîÎìúÌè¨Ïù∏Ìä∏
            excel_url = f"{self.base_url}/fcti/securityAdvisory/advisoryListDownloadXlsx"
            
            # POST Îç∞Ïù¥ÌÑ∞
            excel_data = {
                'page': '0',
                'tabSort': 'blacklist',
                'excelDownload': 'blacklist,',
                'cveId': '',
                'ipId': '',
                'estId': '',
                'startDate': start_date,
                'endDate': end_date,
                'findCondition': 'all',
                'findKeyword': '',
                'excelDown': 'blacklist',
                'size': '10'
            }
            
            # Ï∂îÍ∞Ä Ìó§Îçî
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Origin': self.base_url,
                'Referer': f"{self.base_url}/fcti/securityAdvisory/advisoryList",
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'same-origin'
            }
            
            # ÏùºÏùº ÏàòÏßë Ïó¨Î∂Ä ÌôïÏù∏
            is_daily = (start_date == end_date)
            if is_daily:
                logger.info(f"üìÖ ÏùºÏùº ÏàòÏßë Î™®Îìú - {start_date} ÌïòÎ£® Îç∞Ïù¥ÌÑ∞Îßå Îã§Ïö¥Î°úÎìú")
            
            logger.info(f"üì• Excel ÌååÏùº Îã§Ïö¥Î°úÎìú Ï§ë... (Í∏∞Í∞Ñ: {start_date} ~ {end_date})")
            response = session.post(
                excel_url,
                data=excel_data,
                headers=headers,
                timeout=60,
                stream=True
            )
            
            if response.status_code == 200:
                # Excel ÌååÏùºÏù∏ÏßÄ ÌôïÏù∏
                content_type = response.headers.get('Content-Type', '')
                if 'excel' in content_type or 'spreadsheet' in content_type or 'octet-stream' in content_type or not content_type:
                    # Î©îÎ™®Î¶¨ÏóêÏÑú Excel ÌååÏùº ÏùΩÍ∏∞
                    excel_content = io.BytesIO(response.content)
                    
                    try:
                        df = pd.read_excel(excel_content)
                        logger.info(f"‚úÖ Excel Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏÑ±Í≥µ: {len(df)} Ìñâ")
                        
                        if is_daily:
                            logger.info(f"üìä ÏùºÏùº ÏàòÏßë Í≤∞Í≥º: {start_date}Ïóê ÌÉêÏßÄÎêú {len(df)}Í∞ú IP Î∞úÍ≤¨")
                        
                        # IP Ïª¨Îüº Ï∞æÍ∏∞
                        ip_column = None
                        logger.info(f"Excel Ïª¨Îüº Î™©Î°ù: {list(df.columns)}")
                        for col in df.columns:
                            if 'IP' in col.upper() or 'ip' in col:
                                ip_column = col
                                logger.info(f"IP Ïª¨Îüº Î∞úÍ≤¨: '{col}'")
                                break
                        
                        if not ip_column:
                            logger.error("Excel ÌååÏùºÏóêÏÑú IP Ïª¨ÎüºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§")
                            return []
                        
                        # BlacklistEntry Í∞ùÏ≤¥Î°ú Î≥ÄÌôò
                        ip_entries = []
                        invalid_count = 0
                        logger.info(f"IP Ï≤òÎ¶¨ ÏãúÏûë (Ï¥ù {len(df)}Í∞ú)")
                        
                        for idx, row in df.iterrows():
                            try:
                                ip = str(row[ip_column]).strip()
                                
                                # IP Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù
                                if not self._is_valid_ip(ip):
                                    invalid_count += 1
                                    if invalid_count <= 5:
                                        logger.debug(f"Î¨¥Ìö®Ìïú IP: '{ip}' (Ìñâ {idx})")
                                    continue
                                
                                # Îã§Î•∏ Ïª¨Îüº Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
                                country = str(row.get('Íµ≠Í∞Ä', 'Unknown')).strip()
                                attack_type = str(row.get('Îì±Î°ùÏÇ¨Ïú†', 'REGTECH')).strip()
                                
                                # ÏõêÎ≥∏ Îì±Î°ùÏùº ÌååÏã± (ExcelÏóêÏÑú Ïã§Ï†ú ÎÇ†Ïßú Ïª¨Îüº ÏÇ¨Ïö©)
                                detection_date_raw = row.get('Îì±Î°ùÏùº')
                                if pd.notna(detection_date_raw):
                                    if isinstance(detection_date_raw, pd.Timestamp):
                                        detection_date = detection_date_raw.strftime('%Y-%m-%d')
                                    else:
                                        # Î¨∏ÏûêÏó¥Ïù∏ Í≤ΩÏö∞ ÌååÏã± ÏãúÎèÑ
                                        try:
                                            parsed_date = pd.to_datetime(str(detection_date_raw))
                                            detection_date = parsed_date.strftime('%Y-%m-%d')
                                        except:
                                            detection_date = datetime.now().strftime('%Y-%m-%d')
                                else:
                                    detection_date = datetime.now().strftime('%Y-%m-%d')
                                
                                release_date_raw = row.get('Ìï¥Ï†úÏùº')
                                if pd.notna(release_date_raw):
                                    if isinstance(release_date_raw, pd.Timestamp):
                                        release_date = release_date_raw.strftime('%Y-%m-%d')
                                    else:
                                        release_date = str(release_date_raw).strip()
                                else:
                                    release_date = ''
                                
                                # extra_data
                                extra_data = {
                                    'release_date': release_date,
                                    'excel_row': idx + 1
                                }
                                
                                entry = BlacklistEntry(
                                    ip_address=ip,
                                    country=country,
                                    reason=attack_type,
                                    source='REGTECH',
                                    reg_date=detection_date,
                                    exp_date=release_date,
                                    is_active=True,
                                    threat_level='high',
                                    source_details={'type': 'REGTECH', 'attack': attack_type}
                                )
                                
                                ip_entries.append(entry)
                                if len(ip_entries) <= 5:
                                    logger.info(f"IP Ï∂îÍ∞ÄÎê®: {ip} ({country}) - {attack_type}")
                                
                            except Exception as e:
                                logger.warning(f"Ìñâ {idx} Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {e}")
                                if idx < 5:  # Ï≤òÏùå 5Í∞úÎßå ÏûêÏÑ∏Ìûà Í∏∞Î°ù
                                    import traceback
                                    logger.warning(f"ÏÉÅÏÑ∏ Ïò§Î•ò: {traceback.format_exc()}")
                                continue
                        
                        # Ï§ëÎ≥µ Ï†úÍ±∞
                        unique_ips = []
                        seen_ips = set()
                        
                        for entry in ip_entries:
                            if entry.ip_address not in seen_ips:
                                unique_ips.append(entry)
                                seen_ips.add(entry.ip_address)
                            else:
                                self.stats.duplicate_count += 1
                        
                        # ÏùºÏùº ÏàòÏßë ÌÜµÍ≥Ñ Î°úÍ∑∏
                        if is_daily:
                            logger.info(f"üìä {start_date} ÏùºÏùº ÏàòÏßë ÏÉÅÏÑ∏ ÌÜµÍ≥Ñ:")
                            logger.info(f"   - Ï†ÑÏ≤¥ Ìñâ Ïàò: {len(df)}Í∞ú")
                            logger.info(f"   - Ïú†Ìö®Ìïú IP: {len(unique_ips)}Í∞ú")
                            logger.info(f"   - Ï§ëÎ≥µ Ï†úÍ±∞: {self.stats.duplicate_count}Í∞ú")
                            logger.info(f"   - Î¨¥Ìö®Ìïú IP: {invalid_count}Í∞ú")
                            
                            # Íµ≠Í∞ÄÎ≥Ñ ÌÜµÍ≥Ñ
                            if unique_ips:
                                country_stats = {}
                                for entry in unique_ips:
                                    country = entry.country or 'Unknown'
                                    country_stats[country] = country_stats.get(country, 0) + 1
                                
                                logger.info(f"   - Íµ≠Í∞ÄÎ≥Ñ Î∂ÑÌè¨:")
                                for country, count in sorted(country_stats.items(), key=lambda x: x[1], reverse=True)[:5]:
                                    logger.info(f"     ‚Ä¢ {country}: {count}Í∞ú")
                        else:
                            logger.info(f"ExcelÏóêÏÑú {len(unique_ips)}Í∞ú Í≥†Ïú† IP Ï∂îÏ∂ú (Ï§ëÎ≥µ {self.stats.duplicate_count}Í∞ú Ï†úÍ±∞)")
                            logger.info(f"Î¨¥Ìö®Ìïú IP Ïàò: {invalid_count}")
                        
                        if len(unique_ips) == 0:
                            logger.warning(f"‚ö†Ô∏è IPÍ∞Ä ÌïòÎÇòÎèÑ Ï∂îÏ∂úÎêòÏßÄ ÏïäÏùå. Ï†ÑÏ≤¥ {len(df)}Ìñâ Ï§ë Î¨¥Ìö® {invalid_count}Í∞ú")
                        return unique_ips
                        
                    except Exception as e:
                        logger.error(f"Excel ÌååÏùº ÌååÏã± Ïò§Î•ò: {e}")
                        return []
                else:
                    logger.error(f"ExcelÏù¥ ÏïÑÎãå ÏùëÎãµ ÌÉÄÏûÖ: {content_type}")
                    return []
            else:
                logger.error(f"Excel Îã§Ïö¥Î°úÎìú Ïã§Ìå®: {response.status_code}")
                return []
                
        except Exception as e:
            logger.error(f"Excel Îã§Ïö¥Î°úÎìú Ï§ë Ïò§Î•ò: {e}")
            return []
    
    def _collect_html_fallback(self, session: requests.Session, start_date: str, end_date: str, 
                               max_pages: int, page_size: int) -> List[BlacklistEntry]:
        """HTML ÌååÏã± Î∞©Ïãù Ìè¥Î∞±"""
        logger.info("HTML ÌååÏã± Î∞©ÏãùÏúºÎ°ú ÏàòÏßë ÏãúÎèÑ")
        collected_ips = []
        
        for page in range(max_pages):
            logger.info(f"REGTECH ÌéòÏù¥ÏßÄ {page + 1}/{max_pages} ÏàòÏßë Ï§ë...")
            
            collection_data = {
                'page': str(page),
                'tabSort': 'blacklist',
                'excelDownload': '',
                'cveId': '',
                'ipId': '',
                'estId': '',
                'startDate': start_date,
                'endDate': end_date,
                'findCondition': 'all',
                'findKeyword': '',
                'size': str(page_size)
            }
            
            response = session.post(
                f"{self.base_url}{self.advisory_endpoint}",
                data=collection_data,
                headers={
                    'Content-Type': 'application/x-www-form-urlencoded',
                    'Referer': f"{self.base_url}{self.advisory_endpoint}"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                page_ips = self._parse_html_response(response.text)
                
                if page_ips:
                    collected_ips.extend(page_ips)
                    self.stats.pages_processed += 1
                    logger.info(f"ÌéòÏù¥ÏßÄ {page + 1}: {len(page_ips)}Í∞ú IP ÏàòÏßë")
                else:
                    logger.warning(f"ÌéòÏù¥ÏßÄ {page + 1}: IP Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå")
                    break
            else:
                logger.error(f"ÌéòÏù¥ÏßÄ {page + 1} ÏöîÏ≤≠ Ïã§Ìå®: {response.status_code}")
                break
        
        # Ï§ëÎ≥µ Ï†úÍ±∞
        unique_ips = []
        seen_ips = set()
        
        for ip_entry in collected_ips:
            if ip_entry.ip_address not in seen_ips:
                unique_ips.append(ip_entry)
                seen_ips.add(ip_entry.ip_address)
            else:
                self.stats.duplicate_count += 1
        
        return unique_ips
    
    def _is_valid_ip(self, ip: str) -> bool:
        """IP Ï£ºÏÜå Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù"""
        try:
            if not ip or not isinstance(ip, str):
                return False
            
            # IP Ìå®ÌÑ¥ Í≤ÄÏ¶ù
            import re
            ip_pattern = re.compile(r'^(?:[0-9]{1,3}\.){3}[0-9]{1,3}$')
            if not ip_pattern.match(ip):
                return False
            
            # Í∞Å Ïò•ÌÖü Î≤îÏúÑ Í≤ÄÏ¶ù
            parts = ip.split('.')
            for part in parts:
                if not 0 <= int(part) <= 255:
                    return False
            
            # ÏÇ¨ÏÑ§ IP Î∞è ÌäπÏàò IP Ï†úÏô∏
            if parts[0] == '192' and parts[1] == '168':
                return False
            if parts[0] == '10':
                return False
            if parts[0] == '172' and 16 <= int(parts[1]) <= 31:
                return False
            if parts[0] in ['0', '127', '255']:
                return False
            
            return True
            
        except:
            return False


def create_regtech_collector(data_dir: str, cache_backend=None) -> RegtechCollector:
    """REGTECH ÏàòÏßëÍ∏∞ Ìå©ÌÜ†Î¶¨ Ìï®Ïàò"""
    return RegtechCollector(data_dir, cache_backend)