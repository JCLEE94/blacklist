#!/usr/bin/env python3
"""
í†µí•© ë¸”ë™ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬ ì„œë¹„ìŠ¤
ëª¨ë“  ë¸”ë™ë¦¬ìŠ¤íŠ¸ ìš´ì˜ì„ í•˜ë‚˜ë¡œ í†µí•©í•œ ì„œë¹„ìŠ¤
"""
import os
import logging
import asyncio
import json
import sqlite3
from typing import Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime

from .container import get_container
from .regtech_collector import RegtechCollector
from .secudium_collector import SecudiumCollector
from .blacklist_unified import UnifiedBlacklistManager
from .collection_manager import CollectionManager

logger = logging.getLogger(__name__)

@dataclass
class ServiceHealth:
    status: str
    components: Dict[str, str]
    timestamp: datetime
    version: str

class UnifiedBlacklistService:
    """
    í†µí•© ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì„œë¹„ìŠ¤ - ëª¨ë“  ê¸°ëŠ¥ì„ í•˜ë‚˜ë¡œ í†µí•©
    REGTECH, SECUDIUM ìˆ˜ì§‘ë¶€í„° API ì„œë¹™ê¹Œì§€ ë‹¨ì¼ ì„œë¹„ìŠ¤ë¡œ ì²˜ë¦¬
    """
    
    def __init__(self):
        self.container = get_container()
        self.logger = logging.getLogger(__name__)
        
        # ì„œë¹„ìŠ¤ ìƒíƒœ
        self._running = False
        self._components = {}
        
        # í†µí•© ì„¤ì •
        self.config = {
            'regtech_enabled': os.getenv('REGTECH_ENABLED', 'true').lower() == 'true',
            'secudium_enabled': os.getenv('SECUDIUM_ENABLED', 'true').lower() == 'true',
            'auto_collection': os.getenv('AUTO_COLLECTION', 'true').lower() == 'true',
            'collection_interval': int(os.getenv('COLLECTION_INTERVAL', 3600)),
            'service_name': 'blacklist-unified',
            'version': '3.0.0'
        }
        
        # ìˆ˜ì§‘ ë¡œê·¸ ì €ì¥ (ë©”ëª¨ë¦¬, ìµœëŒ€ 1000ê°œ)
        self.collection_logs = []
        self.max_logs = 1000
        
        # ìˆ˜ì§‘ ìƒíƒœ ê´€ë¦¬ (ë©”ëª¨ë¦¬)
        self.collection_enabled = True
        self.daily_collection_enabled = False
        
        # Initialize core services immediately
        try:
            self.blacklist_manager = self.container.resolve('blacklist_manager')
            self.cache = self.container.resolve('cache_manager')
            # Try to get collection_manager
            try:
                self.collection_manager = self.container.resolve('collection_manager')
            except Exception as e:
                self.logger.warning(f"Collection Manager not available: {e}")
                self.collection_manager = None
        except Exception as e:
            self.logger.error(f"Failed to initialize core services: {e}")
            self.blacklist_manager = None
            self.cache = None
            self.collection_manager = None
        
        # ë¡œê·¸ í…Œì´ë¸” ì´ˆê¸°í™”
        self._ensure_log_table()
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ ë¡œê·¸ ë¡œë“œ
        try:
            existing_logs = self._load_logs_from_db(100)
            self.collection_logs = existing_logs
        except Exception as e:
            self.logger.warning(f"Failed to load existing logs: {e}")
        
        # Mark as running for basic health checks
        self._running = True
        
        # ìµœì´ˆ ì‹¤í–‰ ì‹œ ìë™ ìˆ˜ì§‘ ìˆ˜í–‰
        self._check_and_perform_initial_collection()
        
    def _check_and_perform_initial_collection(self):
        """ìµœì´ˆ ì‹¤í–‰ ì‹œ ìë™ ìˆ˜ì§‘ ìˆ˜í–‰"""
        try:
            if self.collection_manager and self.collection_manager.is_initial_collection_needed():
                self.logger.info("ğŸ”¥ ìµœì´ˆ ì‹¤í–‰ ê°ì§€ - ìë™ ìˆ˜ì§‘ ì‹œì‘...")
                
                # ìˆ˜ì§‘ í™œì„±í™” (ì´ë¯¸ í™œì„±í™”ë˜ì–´ ìˆì§€ë§Œ í™•ì‹¤íˆ)
                if not self.collection_manager.collection_enabled:
                    self.collection_manager.enable_collection()
                
                # ë¹„ë™ê¸° ì‘ì—…ì„ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
                import asyncio
                import threading
                
                def run_initial_collection():
                    try:
                        # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        
                        # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ìˆ˜ì§‘
                        today = datetime.now()
                        start_date = (today - timedelta(days=90)).strftime('%Y%m%d')
                        end_date = today.strftime('%Y%m%d')
                        
                        self.logger.info(f"ğŸ“… ìµœì´ˆ ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")
                        
                        # REGTECH ìˆ˜ì§‘
                        self.logger.info("ğŸ”„ REGTECH ìµœì´ˆ ìˆ˜ì§‘ ì‹œì‘...")
                        regtech_result = self.collection_manager.trigger_regtech_collection(start_date, end_date)
                        if regtech_result.get('success'):
                            self.logger.info(f"âœ… REGTECH ìˆ˜ì§‘ ì„±ê³µ: {regtech_result.get('message', '')}")
                        else:
                            self.logger.warning(f"âš ï¸ REGTECH ìˆ˜ì§‘ ì‹¤íŒ¨: {regtech_result.get('message', '')}")
                        
                        # SECUDIUM ìˆ˜ì§‘
                        self.logger.info("ğŸ”„ SECUDIUM ìµœì´ˆ ìˆ˜ì§‘ ì‹œì‘...")
                        secudium_result = self.collection_manager.trigger_secudium_collection()
                        if secudium_result.get('success'):
                            self.logger.info(f"âœ… SECUDIUM ìˆ˜ì§‘ ì„±ê³µ: {secudium_result.get('message', '')}")
                        else:
                            self.logger.warning(f"âš ï¸ SECUDIUM ìˆ˜ì§‘ ì‹¤íŒ¨: {secudium_result.get('message', '')}")
                        
                        # ìµœì´ˆ ìˆ˜ì§‘ ì™„ë£Œ í‘œì‹œ
                        self.collection_manager.mark_initial_collection_done()
                        self.logger.info("ğŸ‰ ìµœì´ˆ ìˆ˜ì§‘ ì™„ë£Œ!")
                        
                        # ìˆ˜ì§‘ ë¡œê·¸ ì¶”ê°€
                        self.add_collection_log('system', 'initial_collection_complete', {
                            'regtech': regtech_result,
                            'secudium': secudium_result
                        })
                        
                    except Exception as e:
                        self.logger.error(f"ìµœì´ˆ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        import traceback
                        self.logger.error(traceback.format_exc())
                
                # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                collection_thread = threading.Thread(target=run_initial_collection)
                collection_thread.daemon = True
                collection_thread.start()
                
        except Exception as e:
            self.logger.error(f"ìµœì´ˆ ìˆ˜ì§‘ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def start(self) -> None:
        """í†µí•© ì„œë¹„ìŠ¤ ì‹œì‘"""
        self.logger.info("ğŸš€ í†µí•© ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì„œë¹„ìŠ¤ ì‹œì‘...")
        
        try:
            # 1. ì˜ì¡´ì„± ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™”
            await self._initialize_container()
            
            # 2. í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
            await self._initialize_components()
            
            # 3. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘
            if self.config['auto_collection']:
                await self._start_background_tasks()
            
            self._running = True
            self.logger.info("âœ… í†µí•© ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì„œë¹„ìŠ¤ ì‹œì‘ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨: {e}")
            raise
    
    async def stop(self) -> None:
        """í†µí•© ì„œë¹„ìŠ¤ ì •ì§€"""
        self.logger.info("ğŸ›‘ í†µí•© ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì„œë¹„ìŠ¤ ì •ì§€...")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì •ì§€
        if hasattr(self, '_background_tasks'):
            for task in self._background_tasks:
                task.cancel()
        
        # ì»´í¬ë„ŒíŠ¸ ì •ë¦¬
        await self._cleanup_components()
        
        self._running = False
        self.logger.info("âœ… í†µí•© ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì„œë¹„ìŠ¤ ì •ì§€ ì™„ë£Œ")
    
    async def _initialize_container(self):
        """ì˜ì¡´ì„± ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™”"""
        self.logger.info("ğŸ“¦ ì˜ì¡´ì„± ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™” ì¤‘...")
        
        # Already initialized in __init__, just verify they exist
        if not self.blacklist_manager:
            self.logger.error("blacklist_manager not initialized")
            raise RuntimeError("Required service 'blacklist_manager' not available")
        
        if not self.cache:
            self.logger.error("cache not initialized")
            raise RuntimeError("Required service 'cache' not available")
        
        self.logger.info("âœ… ì˜ì¡´ì„± ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def _initialize_components(self):
        """í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        self.logger.info("âš™ï¸ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì¤‘...")
        
        # REGTECH ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        if self.config['regtech_enabled']:
            self._components['regtech'] = RegtechCollector('data', self.cache)
            self.logger.info("âœ… REGTECH ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        # SECUDIUM ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        if self.config['secudium_enabled']:
            self._components['secudium'] = SecudiumCollector('data', self.cache)
            self.logger.info("âœ… SECUDIUM ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        self.logger.info("âœ… ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def _start_background_tasks(self):
        """ë°±ê·¸ë¼ìš´ë“œ ìë™ ìˆ˜ì§‘ ì‘ì—… ì‹œì‘"""
        self.logger.info("ğŸ”„ ìë™ ìˆ˜ì§‘ ì‘ì—… ì‹œì‘...")
        
        self._background_tasks = []
        
        # ì£¼ê¸°ì  ìˆ˜ì§‘ ì‘ì—…
        collection_task = asyncio.create_task(self._periodic_collection())
        self._background_tasks.append(collection_task)
        
        self.logger.info("âœ… ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘ ì™„ë£Œ")
    
    async def _periodic_collection(self):
        """ì£¼ê¸°ì  ë°ì´í„° ìˆ˜ì§‘"""
        while self._running:
            try:
                # ì¼ì¼ ìë™ ìˆ˜ì§‘ì´ í™œì„±í™”ëœ ê²½ìš°ë§Œ ì‹¤í–‰
                if self.collection_manager and hasattr(self.collection_manager, 'daily_collection_enabled'):
                    if self.collection_manager.daily_collection_enabled:
                        # ë§ˆì§€ë§‰ ìˆ˜ì§‘ì´ ì˜¤ëŠ˜ì´ ì•„ë‹ˆë©´ ìˆ˜ì§‘ ì‹¤í–‰
                        last_collection = self.collection_manager.last_daily_collection
                        if not last_collection or not last_collection.startswith(datetime.now().strftime('%Y-%m-%d')):
                            self.logger.info("ğŸ”„ ì¼ì¼ ìë™ ìˆ˜ì§‘ ì‹œì‘...")
                            
                            # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ìˆ˜ì§‘
                            today = datetime.now()
                            start_date = today.strftime('%Y%m%d')
                            end_date = today.strftime('%Y%m%d')
                            
                            # REGTECH ìˆ˜ì§‘ (í•˜ë£¨ ë‹¨ìœ„)
                            result = await self._collect_regtech_data_with_date(start_date, end_date)
                            
                            if result.get('success'):
                                self.logger.info(f"âœ… ì¼ì¼ ìë™ ìˆ˜ì§‘ ì™„ë£Œ: {result.get('total_collected', 0)}ê°œ IP")
                                
                                # ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œê°„ ì—…ë°ì´íŠ¸
                                self.collection_manager.last_daily_collection = datetime.now().isoformat()
                                self.collection_manager.config['last_daily_collection'] = self.collection_manager.last_daily_collection
                                self.collection_manager._save_collection_config()
                            else:
                                self.logger.warning("âš ï¸ ì¼ì¼ ìë™ ìˆ˜ì§‘ ì‹¤íŒ¨")
                
                # ë‹¤ìŒ ì²´í¬ê¹Œì§€ ëŒ€ê¸° (1ì‹œê°„)
                await asyncio.sleep(3600)
                
            except Exception as e:
                self.logger.error(f"âŒ ì£¼ê¸°ì  ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ í›„ ì¬ì‹œë„
    
    async def _cleanup_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì •ë¦¬"""
        self.logger.info("ğŸ§¹ ì»´í¬ë„ŒíŠ¸ ì •ë¦¬ ì¤‘...")
        
        for name, component in self._components.items():
            try:
                if hasattr(component, 'cleanup'):
                    await component.cleanup()
            except Exception as e:
                self.logger.warning(f"ì»´í¬ë„ŒíŠ¸ {name} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # === í†µí•© API ë©”ì„œë“œë“¤ ===
    
    async def collect_all_data(self, force: bool = False) -> Dict[str, Any]:
        """ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
        self.logger.info("ğŸ”„ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        results = {}
        total_success = 0
        total_failed = 0
        
        # REGTECH ìˆ˜ì§‘
        if 'regtech' in self._components:
            try:
                regtech_result = await self._collect_regtech_data(force)
                results['regtech'] = regtech_result
                if regtech_result.get('success'):
                    total_success += 1
                else:
                    total_failed += 1
            except Exception as e:
                self.logger.error(f"REGTECH ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                results['regtech'] = {'success': False, 'error': str(e)}
                total_failed += 1
        
        # SECUDIUM ìˆ˜ì§‘
        if 'secudium' in self._components:
            try:
                secudium_result = await self._collect_secudium_data(force)
                results['secudium'] = secudium_result
                if secudium_result.get('success'):
                    total_success += 1
                else:
                    total_failed += 1
            except Exception as e:
                self.logger.error(f"SECUDIUM ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                results['secudium'] = {'success': False, 'error': str(e)}
                total_failed += 1
        
        return {
            'success': total_success > 0,
            'results': results,
            'summary': {
                'successful_sources': total_success,
                'failed_sources': total_failed,
                'timestamp': datetime.now().isoformat()
            }
        }
    
    async def _collect_regtech_data(self, force: bool = False) -> Dict[str, Any]:
        """REGTECH ë°ì´í„° ìˆ˜ì§‘"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None, 
            self._components['regtech'].auto_collect
        )
    
    async def _collect_regtech_data_with_date(self, start_date: str, end_date: str) -> Dict[str, Any]:
        """REGTECH ë°ì´í„° ìˆ˜ì§‘ (ë‚ ì§œ ì§€ì •)"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None,
            self._components['regtech'].collect_from_web,
            5,  # max_pages
            100,  # page_size
            1,  # parallel_workers
            start_date,
            end_date
        )
    
    async def _collect_secudium_data(self, force: bool = False) -> Dict[str, Any]:
        """SECUDIUM ë°ì´í„° ìˆ˜ì§‘"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None, 
            self._components['secudium'].auto_collect
        )
    
    async def search_ip(self, ip: str) -> Dict[str, Any]:
        """í†µí•© IP ê²€ìƒ‰"""
        try:
            # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ í†µí•œ í†µí•© ê²€ìƒ‰
            result = self.blacklist_manager.search_ip(ip)
            return {
                'success': True,
                'ip': ip,
                'result': result,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"IP ê²€ìƒ‰ ì‹¤íŒ¨ ({ip}): {e}")
            return {
                'success': False,
                'ip': ip,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    async def get_active_blacklist(self, format_type: str = 'json') -> Dict[str, Any]:
        """í™œì„± ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ"""
        try:
            # Check if blacklist_manager is available
            if not self.blacklist_manager:
                return {
                    'success': False,
                    'error': "Blacklist manager not initialized",
                    'timestamp': datetime.now().isoformat()
                }
            
            if format_type == 'fortigate':
                # FortiGate í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                active_ips = self.blacklist_manager.get_active_ips()
                result = {
                    "version": "1.0",
                    "name": "Blacklist IPs",
                    "category": "Secudium Blacklist",
                    "description": "Threat Intelligence Blacklist",
                    "entries": [{"ip": ip} for ip in sorted(active_ips)],
                    "total_count": len(active_ips),
                    "generated_at": datetime.now().isoformat()
                }
            else:
                active_ips = self.blacklist_manager.get_active_ips()
                result = {
                    "ips": list(active_ips),
                    "count": len(active_ips),
                    "timestamp": datetime.now().isoformat()
                }
            
            return {
                'success': True,
                'format': format_type,
                'data': result,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    async def get_statistics(self) -> Dict[str, Any]:
        """í†µí•© ì‹œìŠ¤í…œ í†µê³„"""
        try:
            # Check if blacklist_manager is available
            if not self.blacklist_manager:
                return {
                    'success': False,
                    'error': "Blacklist manager not initialized",
                    'timestamp': datetime.now().isoformat()
                }
            
            # Get system health which includes stats
            health_data = self.blacklist_manager.get_system_health()
            
            # Extract stats from health data
            stats = {
                'total_ips': len(self.blacklist_manager.get_active_ips()),
                'sources': health_data.get('sources', {}),
                'status': health_data.get('status', 'unknown'),
                'last_update': health_data.get('last_update', None)
            }
            
            # ì„œë¹„ìŠ¤ ìƒíƒœ ì¶”ê°€
            stats['service'] = {
                'name': self.config['service_name'],
                'version': self.config['version'],
                'running': self._running,
                'components': list(self._components.keys()),
                'auto_collection': self.config['auto_collection'],
                'collection_interval': self.config['collection_interval']
            }
            
            return {
                'success': True,
                'statistics': stats,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def get_health(self) -> ServiceHealth:
        """ì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬"""
        component_status = {}
        
        for name, component in self._components.items():
            try:
                # ê° ì»´í¬ë„ŒíŠ¸ì˜ ìƒíƒœ í™•ì¸
                if hasattr(component, 'get_health'):
                    component_status[name] = component.get_health()
                else:
                    component_status[name] = "healthy"
            except Exception as e:
                component_status[name] = f"error: {e}"
        
        # ì „ì²´ ìƒíƒœ ê²°ì •
        overall_status = "healthy" if self._running else "stopped"
        if any("error" in status for status in component_status.values()):
            overall_status = "degraded"
        
        return ServiceHealth(
            status=overall_status,
            components=component_status,
            timestamp=datetime.now(),
            version=self.config['version']
        )
    
    
    def initialize_database_tables(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ê°•ì œ ì´ˆê¸°í™”"""
        try:
            # Use blacklist_manager's database path
            if hasattr(self.blacklist_manager, 'db_path'):
                db_path = self.blacklist_manager.db_path
            else:
                db_path = os.path.join('/app' if os.path.exists('/app') else '.', 'instance/blacklist.db')
            
            self.logger.info(f"Initializing database tables at: {db_path}")
            
            import sqlite3
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # Create blacklist_ip table if not exists
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS blacklist_ip (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ip TEXT NOT NULL UNIQUE,
                    created_at TEXT NOT NULL,
                    detection_date TEXT,
                    attack_type TEXT,
                    country TEXT,
                    source TEXT,
                    confidence_score REAL DEFAULT 1.0,
                    is_active INTEGER DEFAULT 1,
                    last_seen TEXT
                )
            """)
            
            # Create ip_detection table if not exists
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS ip_detection (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ip TEXT NOT NULL,
                    created_at TEXT NOT NULL,
                    source TEXT NOT NULL,
                    attack_type TEXT,
                    confidence_score REAL DEFAULT 1.0,
                    FOREIGN KEY (ip) REFERENCES blacklist_ip(ip)
                )
            """)
            
            # Create collection_logs table if not exists
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS collection_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    source TEXT NOT NULL,
                    action TEXT NOT NULL,
                    details TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Create indexes
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_blacklist_ip_source ON blacklist_ip(source)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_blacklist_ip_created_at ON blacklist_ip(created_at)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_collection_logs_created_at ON collection_logs(created_at DESC)")
            
            conn.commit()
            conn.close()
            
            self.logger.info("Database tables initialized successfully")
            return {
                'success': True,
                'message': 'Database tables initialized',
                'database_path': db_path
            }
            
        except Exception as e:
            self.logger.error(f"Failed to initialize database tables: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def clear_all_database_data(self) -> Dict[str, Any]:
        """ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„° ì‚­ì œ"""
        try:
            # Use blacklist_manager to clear data
            if self.blacklist_manager:
                self.blacklist_manager.clear_all()
                return {
                    'success': True,
                    'message': 'All database data cleared'
                }
            else:
                return {
                    'success': False,
                    'error': 'Blacklist manager not available'
                }
        except Exception as e:
            self.logger.error(f"Failed to clear database data: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def set_daily_collection_config(self, enabled: bool, strategy: str, collection_days: int) -> Dict[str, Any]:
        """ì¼ì¼ ìˆ˜ì§‘ ì„¤ì •"""
        try:
            self.daily_collection_enabled = enabled
            self.add_collection_log('system', 'daily_collection_config', {
                'enabled': enabled,
                'strategy': strategy,
                'collection_days': collection_days
            })
            return {
                'success': True,
                'enabled': enabled,
                'strategy': strategy,
                'collection_days': collection_days
            }
        except Exception as e:
            self.logger.error(f"Failed to set daily collection config: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    # Removed duplicate clear_all_data method - using the comprehensive one at line 1431
    
    def _get_source_counts_from_db(self) -> Dict[str, int]:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì†ŒìŠ¤ë³„ IP ê°œìˆ˜ ì¡°íšŒ"""
        source_counts = {'REGTECH': 0, 'SECUDIUM': 0, 'PUBLIC': 0}
        try:
            # Use blacklist_manager's database path
            if hasattr(self.blacklist_manager, 'db_path'):
                db_path = self.blacklist_manager.db_path
            else:
                # Fallback to instance path
                db_path = os.path.join('/app' if os.path.exists('/app') else '.', 'instance/blacklist.db')
            
            import sqlite3
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT source, COUNT(*) FROM blacklist_ip GROUP BY source")
            for row in cursor.fetchall():
                if row[0] in source_counts:
                    source_counts[row[0]] = row[1]
            conn.close()
        except Exception as e:
            self.logger.warning(f"Failed to get source counts from database: {e}")
        return source_counts
    
    def get_blacklist_summary(self) -> Dict[str, Any]:
        """ë¸”ë™ë¦¬ìŠ¤íŠ¸ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        try:
            # Get system health which contains the summary info
            health = self.get_system_health()
            return {
                'total_ips': health.get('total_ips', 0),
                'active_ips': health.get('active_ips', 0),
                'regtech_count': health.get('regtech_count', 0),
                'secudium_count': health.get('secudium_count', 0),
                'public_count': health.get('public_count', 0),
                'status': health.get('status', 'unknown'),
                'last_update': health.get('last_update', None)
            }
        except Exception as e:
            self.logger.error(f"Failed to get blacklist summary: {e}")
            return {
                'total_ips': 0,
                'active_ips': 0,
                'regtech_count': 0,
                'secudium_count': 0,
                'public_count': 0,
                'status': 'error',
                'error': str(e)
            }
    
    def get_collection_status(self) -> Dict[str, Any]:
        """ìˆ˜ì§‘ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        try:
            # ë©”ëª¨ë¦¬ ìƒíƒœì™€ DB í†µê³„ ì¡°í•©
            stats = self.get_blacklist_summary()
            
            return {
                'collection_enabled': self.collection_enabled,
                'daily_collection_enabled': self.daily_collection_enabled,
                'status': 'active' if self.collection_enabled else 'inactive',
                'sources': {
                    'regtech': {
                        'enabled': True,
                        'status': 'ready',
                        'last_collection': None
                    },
                    'secudium': {
                        'enabled': True,
                        'status': 'ready', 
                        'last_collection': None
                    }
                },
                'stats': {
                    'total_ips': stats.get('total_ips', 0),
                    'active_ips': stats.get('active_ips', 0),
                    'regtech_count': stats.get('regtech_count', 0),
                    'secudium_count': stats.get('secudium_count', 0),
                    'today_collected': 0
                },
                'last_collection': None,
                'last_enabled_at': None,
                'last_disabled_at': None
            }
        except Exception as e:
            self.logger.error(f"ìˆ˜ì§‘ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'collection_enabled': False,
                'daily_collection_enabled': False,
                'status': 'error',
                'error': str(e),
                'sources': {},
                'stats': {
                    'total_ips': 0,
                    'active_ips': 0,
                    'regtech_count': 0,
                    'secudium_count': 0,
                    'today_collected': 0
                }
            }
    
    def get_system_health(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í—¬ìŠ¤ ì •ë³´ ë°˜í™˜ (unified_routesì—ì„œ ì‚¬ìš©)"""
        try:
            # Check if blacklist_manager is available
            if not self.blacklist_manager:
                return {
                    'status': 'unhealthy',
                    'total_ips': 0,
                    'active_ips': 0,
                    'error': 'Blacklist manager not initialized'
                }
            
            # Get active IPs
            active_ips = self.blacklist_manager.get_active_ips()
            if isinstance(active_ips, tuple):
                active_ips = active_ips[0]  # Get the actual list from tuple
            
            total_ips = len(active_ips) if active_ips else 0
            
            # Get actual counts by source from database
            source_counts = {'REGTECH': 0, 'SECUDIUM': 0, 'PUBLIC': 0}
            try:
                # Use blacklist_manager's database path
                if hasattr(self.blacklist_manager, 'db_path'):
                    db_path = self.blacklist_manager.db_path
                else:
                    # Fallback to instance path
                    db_path = os.path.join('/app' if os.path.exists('/app') else '.', 'instance/blacklist.db')
                
                self.logger.info(f"Getting source counts from database: {db_path}")
                self.logger.info(f"Database file exists: {os.path.exists(db_path)}")
                if os.path.exists(db_path):
                    self.logger.info(f"Database file size: {os.path.getsize(db_path)} bytes")
                
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                
                # Check if table exists
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='blacklist_ip'")
                table_exists = cursor.fetchone()
                self.logger.info(f"blacklist_ip table exists: {table_exists is not None}")
                
                if not table_exists:
                    self.logger.warning("blacklist_ip table does not exist! Creating tables...")
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS blacklist_ip (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            ip TEXT NOT NULL UNIQUE,
                            created_at TEXT NOT NULL,
                            detection_date TEXT,
                            attack_type TEXT,
                            country TEXT,
                            source TEXT,
                            confidence_score REAL DEFAULT 1.0,
                            is_active INTEGER DEFAULT 1,
                            last_seen TEXT
                        )
                    """)
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS ip_detection (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            ip TEXT NOT NULL,
                            created_at TEXT NOT NULL,
                            source TEXT NOT NULL,
                            attack_type TEXT,
                            confidence_score REAL DEFAULT 1.0
                        )
                    """)
                    cursor.execute("CREATE INDEX IF NOT EXISTS idx_blacklist_ip_source ON blacklist_ip(source)")
                    conn.commit()
                    self.logger.info("Database tables created successfully!")
                
                if table_exists or True:  # Always check after potential creation
                    # First check if table exists and has data
                    cursor.execute("SELECT COUNT(*) FROM blacklist_ip")
                    total_in_db = cursor.fetchone()[0]
                    self.logger.info(f"Total IPs in database: {total_in_db}")
                    
                    # ë” ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´
                    if total_in_db > 0:
                        cursor.execute("SELECT source, COUNT(*) FROM blacklist_ip GROUP BY source")
                        for row in cursor.fetchall():
                            self.logger.info(f"Source {row[0]}: {row[1]} IPs")
                            if row[0] in source_counts:
                                source_counts[row[0]] = row[1]
                        
                        # ìµœê·¼ ì¶”ê°€ëœ ë°ì´í„° í™•ì¸
                        cursor.execute("SELECT ip, source, created_at FROM blacklist_ip ORDER BY created_at DESC LIMIT 5")
                        recent_ips = cursor.fetchall()
                        self.logger.info(f"Recent IPs added: {recent_ips}")
                    else:
                        self.logger.warning("No IPs found in database - checking table structure...")
                        cursor.execute("PRAGMA table_info(blacklist_ip)")
                        table_info = cursor.fetchall()
                        self.logger.info(f"Table structure: {table_info}")
                        
                        # ëª¨ë“  í…Œì´ë¸” í™•ì¸
                        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                        all_tables = cursor.fetchall()
                        self.logger.info(f"All tables in database: {all_tables}")
                    
                    total_ips = total_in_db  # Use the actual count from database
                conn.close()
            except Exception as e:
                self.logger.warning(f"Failed to get source counts: {e}")
                import traceback
                self.logger.warning(f"Traceback: {traceback.format_exc()}")
            
            return {
                'status': 'healthy' if self._running else 'stopped',
                'total_ips': total_ips,
                'active_ips': total_ips,
                'regtech_count': source_counts.get('REGTECH', 0),
                'secudium_count': source_counts.get('SECUDIUM', 0),
                'public_count': source_counts.get('PUBLIC', 0),
                'sources': {
                    'regtech': {'enabled': self.config.get('regtech_enabled', False), 'count': source_counts.get('REGTECH', 0)},
                    'secudium': {'enabled': self.config.get('secudium_enabled', False), 'count': source_counts.get('SECUDIUM', 0)}
                },
                'last_update': datetime.now().isoformat(),
                'cache_available': self.cache is not None,
                'database_connected': True,
                'version': self.config.get('version', '3.0.0')
            }
        except Exception as e:
            self.logger.error(f"Failed to get system health: {e}")
            return {
                'status': 'error',
                'total_ips': 0,
                'active_ips': 0,
                'error': str(e)
            }
    
    def get_system_stats(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""
        return self.get_system_health()  # Reuse system health data
    
    def add_collection_log(self, source: str, action: str, details: Dict[str, Any] = None):
        """ìˆ˜ì§‘ ë¡œê·¸ ì¶”ê°€ - ë©”ëª¨ë¦¬ì™€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        current_time = datetime.now()
        
        # ìƒì„¸í•œ ë©”ì‹œì§€ ìƒì„±
        detailed_message = self._create_detailed_log_message(source, action, details, current_time)
        
        log_entry = {
            'timestamp': current_time.isoformat(),
            'source': source,
            'action': action,
            'details': details or {},
            'message': detailed_message  # ìƒì„¸ ë©”ì‹œì§€ ì¶”ê°€
        }
        
        # ë©”ëª¨ë¦¬ì— ë¡œê·¸ ì¶”ê°€
        self.collection_logs.append(log_entry)
        
        # ìµœëŒ€ ê°œìˆ˜ ìœ ì§€
        if len(self.collection_logs) > self.max_logs:
            self.collection_logs = self.collection_logs[-self.max_logs:]
            
        # ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥
        try:
            self._save_log_to_db(log_entry)
        except Exception as e:
            self.logger.warning(f"Failed to save log to database: {e}")
            
        # ì½˜ì†”ì—ë„ ì¶œë ¥ (ìƒì„¸ ë©”ì‹œì§€ ì‚¬ìš©)
        self.logger.info(f"ğŸ“ {detailed_message}")
    
    def _create_detailed_log_message(self, source: str, action: str, details: Dict[str, Any], timestamp: datetime) -> str:
        """ìƒì„¸í•œ ë¡œê·¸ ë©”ì‹œì§€ ìƒì„± - ì‚¬ìš©ì ìš”ì²­ í˜•ì‹: '2020-00.00 regtech/secudium(ì— ë”°ë¼ì„œ) **ê°œ ì•„ì´í”¼ ìˆ˜ì§‘ë¨'"""
        
        # ë‚ ì§œ í˜•ì‹ ìƒì„±
        date_str = timestamp.strftime('%Y-%m.%d')
        
        # ì†ŒìŠ¤ëª… ì •ë¦¬
        source_name = source.upper()
        if source_name == 'REGTECH':
            source_display = 'REGTECH'
        elif source_name == 'SECUDIUM':
            source_display = 'SECUDIUM'
        else:
            source_display = source_name
            
        # ì•¡ì…˜ì— ë”°ë¥¸ ë©”ì‹œì§€ ìƒì„±
        if action == 'collection_complete':
            ip_count = details.get('ip_count', 0) if details else 0
            message = f"{date_str} {source_display}ì—ì„œ {ip_count}ê°œ ì•„ì´í”¼ ìˆ˜ì§‘ë¨"
            
        elif action == 'collection_start':
            message = f"{date_str} {source_display} ìˆ˜ì§‘ ì‹œì‘"
            
        elif action == 'collection_failed':
            error_msg = details.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜') if details else 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
            message = f"{date_str} {source_display} ìˆ˜ì§‘ ì‹¤íŒ¨: {error_msg}"
            
        elif action == 'collection_enabled':
            message = f"{date_str} {source_display} ìˆ˜ì§‘ í™œì„±í™”ë¨"
            
        elif action == 'collection_disabled':
            message = f"{date_str} {source_display} ìˆ˜ì§‘ ë¹„í™œì„±í™”ë¨"
            
        elif action == 'collection_triggered':
            message = f"{date_str} {source_display} ìˆ˜ë™ ìˆ˜ì§‘ íŠ¸ë¦¬ê±°ë¨"
            
        elif action == 'collection_progress':
            progress_msg = details.get('message', 'ì§„í–‰ ì¤‘') if details else 'ì§„í–‰ ì¤‘'
            message = f"{date_str} {source_display} ì§„í–‰: {progress_msg}"
            
        else:
            # ê¸°ë³¸ í˜•ì‹
            message = f"{date_str} {source_display}: {action}"
            
        return message
    
    def get_collection_logs(self, limit: int = 100) -> list:
        """ìµœê·¼ ìˆ˜ì§‘ ë¡œê·¸ ë°˜í™˜ - ë°ì´í„°ë² ì´ìŠ¤ì™€ ë©”ëª¨ë¦¬ì—ì„œ í†µí•©"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìµœê·¼ ë¡œê·¸ ì¡°íšŒ
            db_logs = self._load_logs_from_db(limit)
            
            # ë©”ëª¨ë¦¬ì˜ ìµœì‹  ë¡œê·¸ì™€ ë³‘í•©
            all_logs = db_logs + self.collection_logs[-50:]  # ë©”ëª¨ë¦¬ì—ì„œ ìµœì‹  50ê°œ
            
            # ì¤‘ë³µ ì œê±° ë° ì‹œê°„ìˆœ ì •ë ¬
            unique_logs = {}
            for log in all_logs:
                key = f"{log['timestamp']}_{log['source']}_{log['action']}"
                unique_logs[key] = log
                
            sorted_logs = sorted(unique_logs.values(), 
                               key=lambda x: x['timestamp'], reverse=True)
            
            return sorted_logs[:limit]
        except Exception as e:
            self.logger.warning(f"Failed to load logs from database: {e}")
            # ë°ì´í„°ë² ì´ìŠ¤ ì‹¤íŒ¨ ì‹œ ë©”ëª¨ë¦¬ ë¡œê·¸ë§Œ ë°˜í™˜
            return self.collection_logs[-limit:]

    def _save_log_to_db(self, log_entry: Dict[str, Any]):
        """ë¡œê·¸ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ê²°ì • - ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            db_path = None
            if self.blacklist_manager and hasattr(self.blacklist_manager, 'db_path'):
                db_path = self.blacklist_manager.db_path
            else:
                # ì„¤ì •ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ URI ê°€ì ¸ì˜¤ê¸°
                from src.config.settings import settings
                
                db_uri = settings.database_uri
                # sqlite:///path/to/db.db í˜•ì‹ì—ì„œ ê²½ë¡œ ì¶”ì¶œ
                if db_uri.startswith('sqlite:///'):
                    db_path = db_uri[10:]  # 'sqlite:///' ì œê±°
                elif db_uri.startswith('sqlite://'):
                    db_path = db_uri[9:]   # 'sqlite://' ì œê±°
                else:
                    # Fallback - ì„¤ì •ì—ì„œ instance ë””ë ‰í† ë¦¬ ì‚¬ìš©
                    db_path = str(settings.instance_dir / 'blacklist.db')
            
            # JSONìœ¼ë¡œ details ì§ë ¬í™”
            details_json = json.dumps(log_entry['details']) if log_entry['details'] else '{}'
            
            query = """
            INSERT INTO collection_logs (timestamp, source, action, details, created_at)
            VALUES (?, ?, ?, ?, datetime('now'))
            """
            
            with sqlite3.connect(db_path) as conn:
                conn.execute(query, (
                    log_entry['timestamp'],
                    log_entry['source'],
                    log_entry['action'],
                    details_json
                ))
                conn.commit()
                
        except Exception as e:
            self.logger.warning(f"Failed to save log to database: {e}")
            
    def _load_logs_from_db(self, limit: int = 100) -> list:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ê²°ì • - ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            db_path = None
            if self.blacklist_manager and hasattr(self.blacklist_manager, 'db_path'):
                db_path = self.blacklist_manager.db_path
            else:
                # ì„¤ì •ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ URI ê°€ì ¸ì˜¤ê¸°
                from src.config.settings import settings
                import re
                
                db_uri = settings.database_uri
                # sqlite:///path/to/db.db í˜•ì‹ì—ì„œ ê²½ë¡œ ì¶”ì¶œ
                if db_uri.startswith('sqlite:///'):
                    db_path = db_uri[10:]  # 'sqlite:///' ì œê±°
                elif db_uri.startswith('sqlite://'):
                    db_path = db_uri[9:]   # 'sqlite://' ì œê±°
                else:
                    # Fallback - ì„¤ì •ì—ì„œ instance ë””ë ‰í† ë¦¬ ì‚¬ìš©
                    db_path = str(settings.instance_dir / 'blacklist.db')
                    
            query = """
            SELECT timestamp, source, action, details
            FROM collection_logs
            ORDER BY created_at DESC
            LIMIT ?
            """
            
            with sqlite3.connect(db_path) as conn:
                cursor = conn.execute(query, (limit,))
                rows = cursor.fetchall()
                
                logs = []
                for row in rows:
                    try:
                        details = json.loads(row[3]) if row[3] else {}
                    except (json.JSONDecodeError, TypeError):
                        details = {}
                        
                    logs.append({
                        'timestamp': row[0],
                        'source': row[1],
                        'action': row[2],
                        'details': details
                    })
                    
                return logs
                
        except Exception as e:
            self.logger.warning(f"Failed to load logs from database: {e}")
            return []
            
    def _ensure_log_table(self):
        """ë¡œê·¸ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ê²°ì • - ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            db_path = None
            if self.blacklist_manager and hasattr(self.blacklist_manager, 'db_path'):
                db_path = self.blacklist_manager.db_path
            else:
                # ì„¤ì •ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ URI ê°€ì ¸ì˜¤ê¸°
                from src.config.settings import settings
                
                db_uri = settings.database_uri
                # sqlite:///path/to/db.db í˜•ì‹ì—ì„œ ê²½ë¡œ ì¶”ì¶œ
                if db_uri.startswith('sqlite:///'):
                    db_path = db_uri[10:]  # 'sqlite:///' ì œê±°
                elif db_uri.startswith('sqlite://'):
                    db_path = db_uri[9:]   # 'sqlite://' ì œê±°
                else:
                    # Fallback - ì„¤ì •ì—ì„œ instance ë””ë ‰í† ë¦¬ ì‚¬ìš©
                    db_path = str(settings.instance_dir / 'blacklist.db')
            
            query = """
            CREATE TABLE IF NOT EXISTS collection_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                source TEXT NOT NULL,
                action TEXT NOT NULL,
                details TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
            """
            
            with sqlite3.connect(db_path) as conn:
                conn.execute(query)
                conn.commit()
                
                # ì¸ë±ìŠ¤ ìƒì„±
                conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_collection_logs_created_at 
                ON collection_logs(created_at DESC)
                """)
                conn.commit()
                
            self.logger.info(f"Collection logs table ensured at: {db_path}")
                
        except Exception as e:
            self.logger.warning(f"Failed to create log table: {e}")
    
    def clear_collection_logs(self):
        """ìˆ˜ì§‘ ë¡œê·¸ ì´ˆê¸°í™”"""
        self.collection_logs = []
        self.logger.info("ìˆ˜ì§‘ ë¡œê·¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    def get_active_blacklist_ips(self) -> list:
        """í™œì„± ë¸”ë™ë¦¬ìŠ¤íŠ¸ IP ëª©ë¡ ë°˜í™˜"""
        try:
            if not self.blacklist_manager:
                return []
            
            active_ips = self.blacklist_manager.get_active_ips()
            if isinstance(active_ips, tuple):
                active_ips = active_ips[0]  # Get the actual list from tuple
            
            return list(active_ips) if active_ips else []
        except Exception as e:
            self.logger.error(f"Failed to get active blacklist IPs: {e}")
            return []
    
    def format_for_fortigate(self, ips: list) -> Dict[str, Any]:
        """FortiGate í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        return {
            "threat_feed": {
                "name": "Nextrade Blacklist",
                "description": "í†µí•© ìœ„í˜‘ IP ëª©ë¡",
                "entries": [{"ip": ip, "type": "malicious"} for ip in ips]
            },
            "total_count": len(ips),
            "last_updated": datetime.utcnow().isoformat()
        }
    
    def get_blacklist_paginated(self, page: int = 1, per_page: int = 100, source_filter: str = None) -> Dict[str, Any]:
        """í˜ì´ì§•ëœ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        try:
            ips = self.get_active_blacklist_ips()
            
            # Simple pagination
            start = (page - 1) * per_page
            end = start + per_page
            paginated_ips = ips[start:end]
            
            return {
                'page': page,
                'per_page': per_page,
                'total': len(ips),
                'pages': (len(ips) + per_page - 1) // per_page,
                'data': paginated_ips
            }
        except Exception as e:
            self.logger.error(f"Failed to get paginated blacklist: {e}")
            return {
                'page': page,
                'per_page': per_page,
                'total': 0,
                'pages': 0,
                'data': []
            }
    
    def search_ip(self, ip: str) -> Dict[str, Any]:
        """ë‹¨ì¼ IP ê²€ìƒ‰"""
        try:
            if not self.blacklist_manager:
                return {'found': False, 'ip': ip, 'error': 'Blacklist manager not initialized'}
            
            active_ips = self.get_active_blacklist_ips()
            found = ip in active_ips
            
            return {
                'found': found,
                'ip': ip,
                'status': 'active' if found else 'not_found',
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"Failed to search IP {ip}: {e}")
            return {'found': False, 'ip': ip, 'error': str(e)}
    
    def search_batch_ips(self, ips: list) -> Dict[str, Any]:
        """ë°°ì¹˜ IP ê²€ìƒ‰"""
        results = {}
        for ip in ips:
            results[ip] = self.search_ip(ip)
        return results
    
    def get_analytics_summary(self, days: int = 7) -> Dict[str, Any]:
        """ë¶„ì„ ìš”ì•½ ë°˜í™˜"""
        return {
            'period_days': days,
            'total_ips': len(self.get_active_blacklist_ips()),
            'new_ips_today': 0,  # Placeholder
            'removed_ips_today': 0,  # Placeholder
            'top_sources': [
                {'name': 'REGTECH', 'count': 0},
                {'name': 'SECUDIUM', 'count': 0}
            ],
            'timestamp': datetime.now().isoformat()
        }
    
    def get_daily_stats(self, days: int = 30) -> list:
        """ì¼ë³„ í†µê³„ ë°˜í™˜"""
        from datetime import timedelta
        
        stats = []
        end_date = datetime.now()
        
        for i in range(days):
            date = end_date - timedelta(days=i)
            date_str = date.strftime('%Y-%m-%d')
            
            # Get stats for this specific date
            daily_stat = {
                'date': date_str,
                'total_ips': 0,
                'regtech_count': 0,
                'secudium_count': 0,
                'public_count': 0,
                'new_ips': 0,
                'expired_ips': 0
            }
            
            # Try to get data from database
            if self.blacklist_manager:
                try:
                    conn = sqlite3.connect(self.blacklist_manager.db_path)
                    cursor = conn.cursor()
                    
                    # Count total IPs by source for this date (using detection_date - ì‹¤ì œ ë“±ë¡ì¼)
                    cursor.execute("""
                        SELECT source, COUNT(*) 
                        FROM blacklist_ip 
                        WHERE DATE(detection_date) = ?
                        GROUP BY source
                    """, (date_str,))
                    
                    for row in cursor.fetchall():
                        source = row[0]
                        count = row[1]
                        if source == 'REGTECH':
                            daily_stat['regtech_count'] = count
                        elif source == 'SECUDIUM':
                            daily_stat['secudium_count'] = count
                        elif source == 'PUBLIC':
                            daily_stat['public_count'] = count
                        daily_stat['total_ips'] += count
                    
                    # Count new IPs for this date (using detection_date - ì‹¤ì œ ë“±ë¡ì¼)
                    cursor.execute("""
                        SELECT COUNT(*) 
                        FROM blacklist_ip 
                        WHERE DATE(detection_date) = ?
                    """, (date_str,))
                    daily_stat['new_ips'] = cursor.fetchone()[0]
                    
                    conn.close()
                except Exception as e:
                    self.logger.warning(f"Failed to get daily stats for {date_str}: {e}")
            
            # Check collection logs for this date
            for log in self.collection_logs:
                if log.get('timestamp', '').startswith(date_str):
                    if 'collection_completed' in log.get('action', ''):
                        details = log.get('details', {})
                        if details.get('ip_count', 0) > 0:
                            daily_stat['total_ips'] = max(daily_stat['total_ips'], details['ip_count'])
                            source = log.get('source', '').upper()
                            if source == 'REGTECH':
                                daily_stat['regtech_count'] = details['ip_count']
                            elif source == 'SECUDIUM':
                                daily_stat['secudium_count'] = details['ip_count']
            
            stats.append(daily_stat)
        
        # Reverse to show newest first
        return list(reversed(stats))
    
    def enable_collection(self) -> Dict[str, Any]:
        """ìˆ˜ì§‘ ì‹œìŠ¤í…œ í™œì„±í™” (ë™ê¸° ë²„ì „)"""
        try:
            # ê¸°ì¡´ ë°ì´í„° í´ë¦¬ì–´
            self.clear_all_database_data()
            
            # ë©”ëª¨ë¦¬ì—ì„œ ìˆ˜ì§‘ ìƒíƒœ í™œì„±í™”
            self.collection_enabled = True
            
            self.logger.info("âœ… ìˆ˜ì§‘ ì‹œìŠ¤í…œ í™œì„±í™”ë¨ (ê¸°ì¡´ ë°ì´í„° í´ë¦¬ì–´ë¨)")
            return {
                'success': True, 
                'message': 'ìˆ˜ì§‘ ì‹œìŠ¤í…œì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ë°ì´í„°ê°€ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤.', 
                'collection_enabled': True
            }
        except Exception as e:
            self.logger.error(f"ìˆ˜ì§‘ ì‹œìŠ¤í…œ í™œì„±í™” ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def disable_collection(self) -> Dict[str, Any]:
        """ìˆ˜ì§‘ ì‹œìŠ¤í…œ ë¹„í™œì„±í™” (ë™ê¸° ë²„ì „)"""
        try:
            # ë©”ëª¨ë¦¬ì—ì„œ ìˆ˜ì§‘ ìƒíƒœ ë¹„í™œì„±í™”
            self.collection_enabled = False
            
            self.logger.info("â¹ï¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ë¹„í™œì„±í™”ë¨")
            return {
                'success': True, 
                'message': 'ìˆ˜ì§‘ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤', 
                'collection_enabled': False
            }
        except Exception as e:
            self.logger.error(f"ìˆ˜ì§‘ ì‹œìŠ¤í…œ ë¹„í™œì„±í™” ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def enable_daily_collection(self) -> Dict[str, Any]:
        """ì¼ì¼ ìë™ ìˆ˜ì§‘ í™œì„±í™”"""
        try:
            # ë©”ëª¨ë¦¬ì—ì„œ ì¼ì¼ ìˆ˜ì§‘ ìƒíƒœ í™œì„±í™”
            self.daily_collection_enabled = True
            
            self.logger.info("ğŸ“… ì¼ì¼ ìë™ ìˆ˜ì§‘ í™œì„±í™”ë¨")
            return {
                'success': True, 
                'message': 'ì¼ì¼ ìë™ ìˆ˜ì§‘ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤', 
                'daily_collection_enabled': True
            }
        except Exception as e:
            self.logger.error(f"ì¼ì¼ ìë™ ìˆ˜ì§‘ í™œì„±í™” ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def disable_daily_collection(self) -> Dict[str, Any]:
        """ì¼ì¼ ìë™ ìˆ˜ì§‘ ë¹„í™œì„±í™”"""
        try:
            # ë©”ëª¨ë¦¬ì—ì„œ ì¼ì¼ ìˆ˜ì§‘ ìƒíƒœ ë¹„í™œì„±í™”
            self.daily_collection_enabled = False
            
            self.logger.info("ğŸ“… ì¼ì¼ ìë™ ìˆ˜ì§‘ ë¹„í™œì„±í™”ë¨")
            return {
                'success': True, 
                'message': 'ì¼ì¼ ìë™ ìˆ˜ì§‘ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤', 
                'daily_collection_enabled': False
            }
        except Exception as e:
            self.logger.error(f"ì¼ì¼ ìë™ ìˆ˜ì§‘ ë¹„í™œì„±í™” ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def trigger_collection(self, source: str = 'all') -> str:
        """ìˆ˜ë™ ìˆ˜ì§‘ íŠ¸ë¦¬ê±°"""
        import uuid
        task_id = str(uuid.uuid4())
        self.logger.info(f"Manual collection triggered: {source} (task_id: {task_id})")
        # TODO: Implement actual collection trigger based on source parameter
        return task_id
    
    def get_enhanced_blacklist(self, page: int = 1, per_page: int = 50, include_metadata: bool = True, source_filter: str = None) -> Dict[str, Any]:
        """í–¥ìƒëœ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ"""
        try:
            ips = self.get_active_blacklist_ips()
            
            # Simple pagination
            start = (page - 1) * per_page
            end = start + per_page
            paginated_ips = ips[start:end]
            
            # Add metadata if requested
            if include_metadata:
                data = [
                    {
                        'ip': ip,
                        'source': 'unknown',
                        'added_date': datetime.now().isoformat(),
                        'threat_level': 'high',
                        'category': 'malicious'
                    }
                    for ip in paginated_ips
                ]
            else:
                data = paginated_ips
            
            return {
                'page': page,
                'per_page': per_page,
                'total': len(ips),
                'pages': (len(ips) + per_page - 1) // per_page,
                'data': data,
                'metadata_included': include_metadata
            }
        except Exception as e:
            self.logger.error(f"Failed to get enhanced blacklist: {e}")
            return {
                'page': page,
                'per_page': per_page,
                'total': 0,
                'pages': 0,
                'data': [],
                'error': str(e)
            }
    
    def get_monthly_stats(self, start_date: str, end_date: str) -> Dict[str, Any]:
        """ì›”ë³„ í†µê³„ ì¡°íšŒ"""
        try:
            # Get stats from blacklist manager if available
            if self.blacklist_manager and hasattr(self.blacklist_manager, 'get_stats_for_period'):
                stats = self.blacklist_manager.get_stats_for_period(start_date, end_date)
                return stats
            
            # Fallback to basic stats
            total_ips = len(self.get_active_blacklist_ips())
            return {
                'total_ips': total_ips,
                'first_detection': start_date,
                'last_detection': end_date,
                'sources': {
                    'REGTECH': 0,
                    'SECUDIUM': 0
                }
            }
        except Exception as e:
            self.logger.error(f"Failed to get monthly stats: {e}")
            return {
                'total_ips': 0,
                'first_detection': None,
                'last_detection': None,
                'sources': {}
            }
    
    def cleanup_old_data(self, cutoff_date: str) -> Dict[str, Any]:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        try:
            # Use blacklist manager's cleanup function if available
            if self.blacklist_manager and hasattr(self.blacklist_manager, 'cleanup_old_data'):
                result = self.blacklist_manager.cleanup_old_data(cutoff_date)
                return result
            
            # Fallback response
            return {
                'success': True,
                'deleted_count': 0,
                'message': 'Cleanup function not available in current configuration'
            }
        except Exception as e:
            self.logger.error(f"Failed to cleanup old data: {e}")
            return {
                'success': False,
                'deleted_count': 0,
                'message': str(e)
            }
    
    def clear_all_data(self) -> Dict[str, Any]:
        """ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ í´ë¦¬ì–´ - ëª¨ë“  í…Œì´ë¸”ì˜ ë°ì´í„° ì‚­ì œ ë° ID ì‹œí€€ìŠ¤ ë¦¬ì…‹"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ê²°ì •
            db_path = None
            if self.blacklist_manager and hasattr(self.blacklist_manager, 'db_path'):
                db_path = self.blacklist_manager.db_path
            else:
                from src.config.settings import settings
                db_uri = settings.database_uri
                if db_uri.startswith('sqlite:///'):
                    db_path = db_uri[10:]
                elif db_uri.startswith('sqlite://'):
                    db_path = db_uri[9:]
                else:
                    db_path = str(settings.instance_dir / 'blacklist.db')
            
            if not db_path or not os.path.exists(db_path):
                return {
                    'success': False,
                    'error': 'Database file not found'
                }
            
            import sqlite3
            
            # ë¨¼ì € ë°ì´í„° ì‚­ì œ ì‘ì—… ìˆ˜í–‰
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                
                # ëª¨ë“  í…Œì´ë¸”ì˜ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                table_counts = {}
                tables_to_clear = ['blacklist_ip', 'ip_detection', 'collection_logs']
                
                for table in tables_to_clear:
                    try:
                        cursor.execute(f"SELECT COUNT(*) FROM {table}")
                        count = cursor.fetchone()[0]
                        table_counts[table] = count
                    except sqlite3.OperationalError:
                        # í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ 0ìœ¼ë¡œ ì„¤ì •
                        table_counts[table] = 0
                
                total_deleted = sum(table_counts.values())
                
                # ëª¨ë“  í…Œì´ë¸” ë°ì´í„° ì‚­ì œ
                for table in tables_to_clear:
                    try:
                        cursor.execute(f"DELETE FROM {table}")
                        self.logger.info(f"Cleared {table_counts.get(table, 0)} records from {table}")
                    except sqlite3.OperationalError as e:
                        self.logger.warning(f"Could not clear table {table}: {e}")
                
                # SQLite ìë™ ì¦ê°€ ì‹œí€€ìŠ¤ ë¦¬ì…‹
                for table in tables_to_clear:
                    try:
                        cursor.execute(f"DELETE FROM sqlite_sequence WHERE name='{table}'")
                        self.logger.info(f"Reset auto-increment sequence for {table}")
                    except sqlite3.OperationalError:
                        # sqlite_sequence í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ í•´ë‹¹ í…Œì´ë¸”ì— í•­ëª©ì´ ì—†ìœ¼ë©´ ë¬´ì‹œ
                        pass
                
                conn.commit()
            
            # VACUUMì€ ë³„ë„ ì—°ê²°ì—ì„œ ì‹¤í–‰ (ìë™ ì»¤ë°‹ ëª¨ë“œ)
            try:
                conn = sqlite3.connect(db_path)
                conn.execute("VACUUM")
                conn.close()
                self.logger.info("Database optimized with VACUUM")
            except Exception as e:
                self.logger.warning(f"VACUUM failed: {e}")
                
                # ë©”ëª¨ë¦¬ ìºì‹œë„ í´ë¦¬ì–´
                if hasattr(self, 'collection_logs'):
                    self.collection_logs = []
                
                # í†µê³„ ìºì‹œ í´ë¦¬ì–´ (ìˆë‹¤ë©´)
                if self.cache:
                    try:
                        # ìºì‹œì˜ ëª¨ë“  blacklist ê´€ë ¨ í‚¤ í´ë¦¬ì–´
                        self.cache.clear()
                        self.logger.info("Cache cleared")
                    except Exception as e:
                        self.logger.warning(f"Failed to clear cache: {e}")
                
                self.logger.info(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì™„ì „ í´ë¦¬ì–´ ì™„ë£Œ: {total_deleted}ê°œ ë ˆì½”ë“œ ì‚­ì œ, ID ì‹œí€€ìŠ¤ ë¦¬ì…‹")
                
                # ìˆ˜ì§‘ ë¡œê·¸ ì¶”ê°€
                self.add_collection_log('SYSTEM', 'database_cleared', {
                    'total_deleted': total_deleted,
                    'cleared_tables': list(table_counts.keys()),
                    'table_counts': table_counts
                })
                
                return {
                    'success': True,
                    'message': f'ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤.',
                    'cleared_tables': list(table_counts.keys()),
                    'total_deleted': total_deleted,
                    'table_counts': table_counts,
                    'id_sequences_reset': True,
                    'cache_cleared': self.cache is not None,
                    'timestamp': datetime.now().isoformat()
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ í´ë¦¬ì–´ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'message': f'ë°ì´í„°ë² ì´ìŠ¤ í´ë¦¬ì–´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}'
            }
    
    # === ì¼ì¼ ìˆ˜ì§‘ ì„¤ì • ê´€ë¦¬ ===
    
    def set_daily_collection_config(self, enabled: bool, strategy: str = None, collection_days: int = 3) -> Dict[str, Any]:
        """ì¼ì¼ ìˆ˜ì§‘ ì„¤ì • ì €ì¥"""
        try:
            # ì„¤ì •ì„ íŒŒì¼ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            config = {
                'enabled': enabled,
                'strategy': strategy,
                'collection_days': collection_days,
                'updated_at': datetime.now().isoformat()
            }
            
            # ì„¤ì •ì„ JSON íŒŒì¼ë¡œ ì €ì¥ (ê°„ë‹¨í•œ êµ¬í˜„)
            config_path = 'daily_collection_config.json'
            import json
            try:
                with open(config_path, 'w') as f:
                    json.dump(config, f, indent=2)
                self.logger.info(f"ì¼ì¼ ìˆ˜ì§‘ ì„¤ì • ì €ì¥: {config}")
            except Exception as e:
                self.logger.warning(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ì—ë„ ì €ì¥
            if not hasattr(self, '_daily_config'):
                self._daily_config = {}
            self._daily_config.update(config)
            
            # ìˆ˜ì§‘ ë¡œê·¸ ì¶”ê°€
            action = 'daily_collection_enabled' if enabled else 'daily_collection_disabled'
            self.add_collection_log('SYSTEM', action, {
                'strategy': strategy,
                'collection_days': collection_days,
                'enabled': enabled
            })
            
            return {
                'success': True,
                'message': f'ì¼ì¼ ìˆ˜ì§‘ ì„¤ì •ì´ {"í™œì„±í™”" if enabled else "ë¹„í™œì„±í™”"}ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'config': config
            }
            
        except Exception as e:
            self.logger.error(f"ì¼ì¼ ìˆ˜ì§‘ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_daily_collection_config(self) -> Dict[str, Any]:
        """ì¼ì¼ ìˆ˜ì§‘ ì„¤ì • ì¡°íšŒ"""
        try:
            # ë©”ëª¨ë¦¬ì—ì„œ ë¨¼ì € í™•ì¸
            if hasattr(self, '_daily_config') and self._daily_config:
                return self._daily_config
            
            # íŒŒì¼ì—ì„œ ë¡œë“œ
            config_path = 'daily_collection_config.json'
            import json
            import os
            
            if os.path.exists(config_path):
                try:
                    with open(config_path, 'r') as f:
                        config = json.load(f)
                    self._daily_config = config
                    return config
                except Exception as e:
                    self.logger.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
            default_config = {
                'enabled': False,
                'strategy': 'disabled',
                'collection_days': 0,
                'updated_at': datetime.now().isoformat()
            }
            
            self._daily_config = default_config
            return default_config
            
        except Exception as e:
            self.logger.error(f"ì¼ì¼ ìˆ˜ì§‘ ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'enabled': False,
                'strategy': 'disabled',
                'collection_days': 0,
                'error': str(e)
            }
    
    def is_daily_collection_enabled(self) -> bool:
        """ì¼ì¼ ìˆ˜ì§‘ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        config = self.get_daily_collection_config()
        return config.get('enabled', False)
    
    def get_daily_collection_strategy(self) -> str:
        """ì¼ì¼ ìˆ˜ì§‘ ì „ëµ ì¡°íšŒ"""
        config = self.get_daily_collection_config()
        return config.get('strategy', 'disabled')
    
    # === ìë™ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì§€ì› ë©”ì„œë“œ ===
    
    def get_daily_collection_stats(self) -> list:
        """ë‚ ì§œë³„ ìˆ˜ì§‘ í†µê³„ ë°˜í™˜"""
        try:
            db_path = os.path.join('/app' if os.path.exists('/app') else '.', 'instance/blacklist.db')
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # ìµœê·¼ 30ì¼ê°„ì˜ ë‚ ì§œë³„ ìˆ˜ì§‘ í†µê³„
            query = """
            SELECT 
                DATE(detection_date) as date,
                COUNT(*) as count,
                source
            FROM blacklist_ip 
            WHERE detection_date >= DATE('now', '-30 days')
            GROUP BY DATE(detection_date), source
            ORDER BY date DESC
            """
            
            cursor.execute(query)
            rows = cursor.fetchall()
            conn.close()
            
            # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
            stats_dict = {}
            for row in rows:
                date, count, source = row
                if date not in stats_dict:
                    stats_dict[date] = {'date': date, 'count': 0, 'sources': {}}
                stats_dict[date]['count'] += count
                stats_dict[date]['sources'][source] = count
            
            # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
            return list(stats_dict.values())
            
        except Exception as e:
            self.logger.error(f"Daily collection stats error: {e}")
            return []
    
    def get_source_statistics(self) -> dict:
        """ì†ŒìŠ¤ë³„ í†µê³„ ë°˜í™˜"""
        try:
            db_path = os.path.join('/app' if os.path.exists('/app') else '.', 'instance/blacklist.db')
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # ì†ŒìŠ¤ë³„ ì´ ê°œìˆ˜
            query = """
            SELECT 
                source,
                COUNT(*) as total,
                MIN(detection_date) as first_detection,
                MAX(detection_date) as last_detection,
                COUNT(DISTINCT DATE(detection_date)) as collection_days
            FROM blacklist_ip 
            GROUP BY source
            """
            
            cursor.execute(query)
            rows = cursor.fetchall()
            conn.close()
            
            stats = {}
            for row in rows:
                source, total, first_detection, last_detection, collection_days = row
                stats[source.lower()] = {
                    'total': total,
                    'first_detection': first_detection,
                    'last_detection': last_detection,
                    'collection_days': collection_days
                }
            
            return stats
            
        except Exception as e:
            self.logger.error(f"Source statistics error: {e}")
            return {}
    
    def get_collection_intervals(self) -> dict:
        """í˜„ì¬ ìˆ˜ì§‘ ê°„ê²© ì„¤ì • ë°˜í™˜"""
        try:
            # ì„¤ì • íŒŒì¼ ê²½ë¡œ
            config_path = os.path.join('/app' if os.path.exists('/app') else '.', 'instance/collection_intervals.json')
            
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    config = json.load(f)
                return config
            else:
                # ê¸°ë³¸ê°’
                default_config = {
                    'regtech_days': 90,  # 3ê°œì›”
                    'secudium_days': 3,  # 3ì¼
                    'updated_at': datetime.now().isoformat()
                }
                # ê¸°ë³¸ê°’ì„ íŒŒì¼ë¡œ ì €ì¥
                os.makedirs(os.path.dirname(config_path), exist_ok=True)
                with open(config_path, 'w') as f:
                    json.dump(default_config, f, indent=2)
                return default_config
                
        except Exception as e:
            self.logger.error(f"Get collection intervals error: {e}")
            return {
                'regtech_days': 90,
                'secudium_days': 3,
                'error': str(e)
            }
    
    def update_collection_intervals(self, regtech_days: int, secudium_days: int) -> dict:
        """ìˆ˜ì§‘ ê°„ê²© ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            config = {
                'regtech_days': regtech_days,
                'secudium_days': secudium_days,
                'updated_at': datetime.now().isoformat()
            }
            
            # ì„¤ì • íŒŒì¼ ì €ì¥
            config_path = os.path.join('/app' if os.path.exists('/app') else '.', 'instance/collection_intervals.json')
            os.makedirs(os.path.dirname(config_path), exist_ok=True)
            
            with open(config_path, 'w') as f:
                json.dump(config, f, indent=2)
            
            self.logger.info(f"Collection intervals updated: REGTECH={regtech_days}days, SECUDIUM={secudium_days}days")
            
            return {
                'success': True,
                'regtech_days': regtech_days,
                'secudium_days': secudium_days,
                'updated_at': config['updated_at']
            }
            
        except Exception as e:
            self.logger.error(f"Update collection intervals error: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_missing_dates_for_collection(self, source: str, days_back: int) -> list:
        """ìˆ˜ì§‘ì´ ëˆ„ë½ëœ ë‚ ì§œ ëª©ë¡ ë°˜í™˜"""
        try:
            from datetime import datetime, timedelta
            
            db_path = os.path.join('/app' if os.path.exists('/app') else '.', 'instance/blacklist.db')
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # ì§€ì •ëœ ê¸°ê°„ ë‚´ì—ì„œ ìˆ˜ì§‘ëœ ë‚ ì§œë“¤ ì¡°íšŒ
            start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
            
            query = """
            SELECT DISTINCT DATE(detection_date) as date
            FROM blacklist_ip 
            WHERE source = ? AND detection_date >= ?
            ORDER BY date DESC
            """
            
            cursor.execute(query, (source.upper(), start_date))
            collected_dates = set(row[0] for row in cursor.fetchall())
            conn.close()
            
            # ì „ì²´ ë‚ ì§œ ë²”ìœ„ì—ì„œ ëˆ„ë½ëœ ë‚ ì§œ ì°¾ê¸°
            missing_dates = []
            current_date = datetime.now()
            
            for i in range(days_back):
                check_date = (current_date - timedelta(days=i)).strftime('%Y-%m-%d')
                if check_date not in collected_dates:
                    missing_dates.append(check_date)
            
            return missing_dates
            
        except Exception as e:
            self.logger.error(f"Get missing dates error: {e}")
            return []
    
    def enable_collection(self) -> dict:
        """ìˆ˜ì§‘ í™œì„±í™”"""
        try:
            # CollectionManagerë¥¼ í†µí•´ ìˆ˜ì§‘ í™œì„±í™”
            collection_manager = self.container.get('collection_manager')
            if not collection_manager:
                return {
                    'success': False,
                    'error': 'Collection manager not available'
                }
            
            # ìˆ˜ì§‘ í™œì„±í™”
            result = collection_manager.enable_collection()
            
            # ë¡œê·¸ ì¶”ê°€
            self.add_collection_log('system', 'collection_enabled', {
                'message': 'ìˆ˜ì§‘ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤',
                'timestamp': datetime.now().isoformat()
            })
            
            self.logger.info("Collection enabled successfully")
            
            return {
                'success': True,
                'message': 'ìˆ˜ì§‘ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤',
                'status': 'enabled',
                'enabled_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Enable collection error: {e}")
            return {
                'success': False,
                'error': str(e),
                'message': 'ìˆ˜ì§‘ í™œì„±í™” ì‹¤íŒ¨'
            }
    
    def disable_collection(self) -> dict:
        """ìˆ˜ì§‘ ë¹„í™œì„±í™”"""
        try:
            # CollectionManagerë¥¼ í†µí•´ ìˆ˜ì§‘ ë¹„í™œì„±í™”
            collection_manager = self.container.get('collection_manager')
            if not collection_manager:
                return {
                    'success': False,
                    'error': 'Collection manager not available'
                }
            
            # ìˆ˜ì§‘ ë¹„í™œì„±í™”
            result = collection_manager.disable_collection()
            
            # ë¡œê·¸ ì¶”ê°€
            self.add_collection_log('system', 'collection_disabled', {
                'message': 'ìˆ˜ì§‘ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤',
                'timestamp': datetime.now().isoformat()
            })
            
            self.logger.info("Collection disabled successfully")
            
            return {
                'success': True,
                'message': 'ìˆ˜ì§‘ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤',
                'status': 'disabled',
                'disabled_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Disable collection error: {e}")
            return {
                'success': False,
                'error': str(e),
                'message': 'ìˆ˜ì§‘ ë¹„í™œì„±í™” ì‹¤íŒ¨'
            }
    
    def trigger_regtech_collection(self, start_date: str = None, end_date: str = None) -> dict:
        """REGTECH ìˆ˜ì§‘ íŠ¸ë¦¬ê±° (ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í¬í•¨)"""
        import uuid
        task_id = str(uuid.uuid4())
        self.logger.info(f"REGTECH collection triggered (task_id: {task_id})")
        
        # ìˆ˜ì§‘ ë¡œê·¸ ì¶”ê°€
        self.add_collection_log('REGTECH', 'collection_started', {
            'task_id': task_id,
            'start_date': start_date,
            'end_date': end_date,
            'is_daily': start_date == end_date if start_date and end_date else False
        })
        
        try:
            # ì‹¤ì œ REGTECH ìˆ˜ì§‘ ì‹¤í–‰
            self.logger.info(f"Container type: {type(self.container)}")
            regtech_collector = self.container.resolve('regtech_collector')
            if not regtech_collector:
                self.logger.error("REGTECH collector not available")
                return {
                    'success': False,
                    'error': 'REGTECH collector not available',
                    'message': 'REGTECH ìˆ˜ì§‘ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }
            
            # ì‹¤ì œ ìˆ˜ì§‘ ì‹¤í–‰ (ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬)
            try:
                ips = regtech_collector.collect_from_web(start_date=start_date, end_date=end_date)
                self.logger.info(f"REGTECH collection completed: {len(ips)} IPs collected")
                
                # ìˆ˜ì§‘ ì™„ë£Œ ë¡œê·¸ ì¶”ê°€
                self.add_collection_log('REGTECH', 'collection_completed', {
                    'task_id': task_id,
                    'ips_collected': len(ips),
                    'start_date': start_date,
                    'end_date': end_date,
                    'is_daily': start_date == end_date if start_date and end_date else False
                })
                
                # ìˆ˜ì§‘í•œ IPë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                if ips and self.blacklist_manager:
                    try:
                        # REGTECH ë°ì´í„°ë¥¼ ëª¨ë“  í•„ë“œ í¬í•¨í•´ì„œ ì €ì¥
                        ips_data = []
                        for ip_entry in ips:
                            # IP ì£¼ì†Œ ì¶”ì¶œ
                            ip_addr = None
                            if hasattr(ip_entry, 'ip_address'):
                                ip_addr = ip_entry.ip_address
                            elif hasattr(ip_entry, 'ip'):
                                ip_addr = ip_entry.ip
                            elif isinstance(ip_entry, dict):
                                ip_addr = ip_entry.get('ip_address') or ip_entry.get('ip')
                            elif isinstance(ip_entry, str):
                                ip_addr = ip_entry
                                
                            if not ip_addr:
                                continue
                                
                            # REGTECH ëª¨ë“  í•„ë“œ ì €ì¥ (ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)
                            ips_data.append({
                                'ip': ip_addr,
                                'ip_address': ip_addr,  # ì›ë³¸ í•„ë“œë„ ì €ì¥
                                'source': 'REGTECH',
                                'reason': getattr(ip_entry, 'reason', None),
                                'country': getattr(ip_entry, 'country', None),
                                'threat_level': getattr(ip_entry, 'threat_level', None),
                                'as_name': getattr(ip_entry, 'as_name', None),
                                'city': getattr(ip_entry, 'city', None),
                                'reg_date': getattr(ip_entry, 'reg_date', None),
                                'attack_type': getattr(ip_entry, 'reason', None),  # reasonì„ attack_typeìœ¼ë¡œë„ ì €ì¥
                                'detection_date': getattr(ip_entry, 'reg_date', None)  # reg_dateë¥¼ detection_dateë¡œë„ ì €ì¥
                            })
                        
                        self.logger.info(f"REGTECH: Calling bulk_import_ips with {len(ips_data)} IPs")
                        self.logger.info(f"REGTECH: Sample IP data: {ips_data[:3] if ips_data else 'None'}")
                        
                        # ì‹¤ì œë¡œ bulk_import_ips í˜¸ì¶œí•˜ê¸° ì „ì— blacklist_manager í™•ì¸
                        if not self.blacklist_manager:
                            self.logger.error("REGTECH: blacklist_manager is None!")
                            return {
                                'success': False,
                                'error': 'blacklist_manager not available',
                                'message': 'REGTECH ìˆ˜ì§‘ ì‹¤íŒ¨: blacklist_manager ì—†ìŒ'
                            }
                        
                        self.logger.info(f"REGTECH: blacklist_manager type: {type(self.blacklist_manager)}")
                        result = self.blacklist_manager.bulk_import_ips(ips_data, source='REGTECH')
                        self.logger.info(f"REGTECH: bulk_import_ips result: {result}")
                        self.logger.info(f"REGTECH: result type: {type(result)}")
                        
                        if result.get('success'):
                            self.logger.info(f"REGTECH: {result['imported_count']}ê°œ IPê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë¨")
                            
                            # ì €ì¥ í›„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ì ‘ í™•ì¸
                            try:
                                source_counts = self._get_source_counts_from_db()
                                self.logger.info(f"REGTECH: ì €ì¥ í›„ DB ìƒíƒœ: {source_counts}")
                            except Exception as verify_e:
                                self.logger.error(f"REGTECH: DB í™•ì¸ ì‹¤íŒ¨: {verify_e}")
                                
                            return {
                                'success': True,
                                'ip_count': len(ips),
                                'imported_count': result.get('imported_count', 0),
                                'message': f'REGTECH ìˆ˜ì§‘ ì™„ë£Œ: {len(ips)}ê°œ IP ìˆ˜ì§‘ë¨'
                            }
                        else:
                            self.logger.error(f"REGTECH: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨ - {result.get('error')}")
                            return {
                                'success': False,
                                'error': result.get('error'),
                                'message': 'REGTECH ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨'
                            }
                    except Exception as e:
                        self.logger.error(f"REGTECH ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                        return {
                            'success': False,
                            'error': str(e),
                            'message': 'REGTECH ë°ì´í„° ì €ì¥ ì‹¤íŒ¨'
                        }
                else:
                    return {
                        'success': True,
                        'ip_count': len(ips) if ips else 0,
                        'message': f'REGTECH ìˆ˜ì§‘ ì™„ë£Œ: {len(ips) if ips else 0}ê°œ IP ìˆ˜ì§‘ë¨ (ì €ì¥ ë¶ˆê°€)'
                    }
                    
            except Exception as e:
                self.logger.error(f"REGTECH ìˆ˜ì§‘ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                return {
                    'success': False,
                    'error': str(e),
                    'message': 'REGTECH ìˆ˜ì§‘ ì‹¤í–‰ ì‹¤íŒ¨'
                }
                
        except Exception as e:
            self.logger.error(f"REGTECH trigger error: {e}")
            return {
                'success': False,
                'error': str(e),
                'message': 'REGTECH ìˆ˜ì§‘ íŠ¸ë¦¬ê±° ì‹¤íŒ¨'
            }
    
    def trigger_secudium_collection(self) -> dict:
        """SECUDIUM ìˆ˜ì§‘ íŠ¸ë¦¬ê±°"""
        try:
            # SECUDIUM ìˆ˜ì§‘ê¸° ê°€ì ¸ì˜¤ê¸°
            secudium_collector = self.container.resolve('secudium_collector')
            if not secudium_collector:
                return {
                    'success': False,
                    'error': 'SECUDIUM collector not available'
                }
            
            # ìˆ˜ì§‘ ì‹œì‘ ë¡œê·¸
            self.add_collection_log('secudium', 'collection_start', {
                'triggered_by': 'manual',
                'start_time': datetime.now().isoformat()
            })
            
            # ìˆ˜ì§‘ ì‹¤í–‰
            try:
                # collect_from_web()ì€ List[BlacklistEntry]ë¥¼ ë°˜í™˜í•¨
                entries = secudium_collector.collect_from_web()
                
                if entries:  # ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°
                    ip_count = len(entries)
                    
                    # ìˆ˜ì§‘í•œ IPë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    if self.blacklist_manager:
                        try:
                            # bulk_import_ips expects a list of dictionaries
                            ips_data = []
                            for entry in entries:
                                ips_data.append({
                                    'ip': entry.ip_address,
                                    'source': 'SECUDIUM',
                                    'attack_type': entry.reason,
                                    'threat_type': entry.reason,
                                    'country': entry.country,
                                    'reg_date': entry.reg_date,  # ì›ë³¸ ë“±ë¡ì¼
                                    'detection_date': entry.reg_date,  # detection_date ì¶”ê°€
                                    'reason': entry.reason,
                                    'threat_level': entry.threat_level,
                                    'confidence': 1.0
                                })
                            
                            self.logger.info(f"SECUDIUM: Calling bulk_import_ips with {len(ips_data)} IPs")
                            result = self.blacklist_manager.bulk_import_ips(ips_data, source='SECUDIUM')
                            if result.get('success'):
                                self.logger.info(f"SECUDIUM: {result['imported_count']}ê°œ IPê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë¨")
                            else:
                                self.logger.error(f"SECUDIUM: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨ - {result.get('error')}")
                        except Exception as e:
                            self.logger.error(f"SECUDIUM: Error saving to database - {e}")
                            import traceback
                            self.logger.error(f"SECUDIUM: Traceback - {traceback.format_exc()}")
                    
                    # ìˆ˜ì§‘ ì™„ë£Œ ë¡œê·¸
                    self.add_collection_log('secudium', 'collection_complete', {
                        'ip_count': ip_count,
                        'triggered_by': 'manual',
                        'end_time': datetime.now().isoformat()
                    })
                    
                    return {
                        'success': True,
                        'message': f'SECUDIUM ìˆ˜ì§‘ ì™„ë£Œ: {ip_count}ê°œ IP ìˆ˜ì§‘ë¨',
                        'ip_count': ip_count,
                        'source': 'secudium'
                    }
                else:
                    self.add_collection_log('secudium', 'collection_failed', {
                        'error': 'No IPs collected',
                        'triggered_by': 'manual'
                    })
                    
                    return {
                        'success': False,
                        'error': 'No IPs collected',
                        'message': 'SECUDIUM ìˆ˜ì§‘ ì‹¤íŒ¨: IPë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                    }
                    
            except Exception as e:
                self.add_collection_log('secudium', 'collection_failed', {
                    'error': str(e),
                    'triggered_by': 'manual'
                })
                raise e
            
        except Exception as e:
            self.logger.error(f"SECUDIUM trigger error: {e}")
            return {
                'success': False,
                'error': str(e),
                'message': 'SECUDIUM ìˆ˜ì§‘ íŠ¸ë¦¬ê±° ì‹¤íŒ¨'
            }

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
_unified_service = None

def get_unified_service() -> UnifiedBlacklistService:
    """í†µí•© ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _unified_service
    if _unified_service is None:
        _unified_service = UnifiedBlacklistService()
    return _unified_service