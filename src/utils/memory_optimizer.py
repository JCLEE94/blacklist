"""
ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ëª¨ë“ˆ - Modularized Entry Point

ì´ ëª¨ë“ˆì€ Blacklist ì‹œìŠ¤í…œì˜ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ
ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬, ë©”ëª¨ë¦¬ í’€ë§, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

This module now uses modular mixins for better code organization:
- CoreMemoryOptimizer: Core memory monitoring and optimization
- DatabaseOptimizationMixin: Database-specific memory optimizations
- BulkProcessorMixin: Large-scale data processing
- ReportingMixin: Memory usage analysis and reporting
"""


from .memory.bulk_processor import BulkProcessorMixin

# Import modular components
from .memory.core_optimizer import CoreMemoryOptimizer
from .memory.database_operations import DatabaseOptimizationMixin
from .memory.reporting import ReportingMixin


class MemoryOptimizer(
    CoreMemoryOptimizer, DatabaseOptimizationMixin, BulkProcessorMixin, ReportingMixin
):
    """
    ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ê´€ë¦¬ì - ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©

    Uses multiple inheritance with specialized mixins for modular functionality:
    - CoreMemoryOptimizer: Memory monitoring, GC, and basic optimization
    - DatabaseOptimizationMixin: Database operation optimizations
    - BulkProcessorMixin: Large-scale IP processing
    - ReportingMixin: Analysis and recommendations
    """

    def __init__(
        self,
        max_memory_percent: float = 80.0,
        gc_threshold_mb: float = 100.0,
        monitoring_interval: float = 30.0,
    ):
        # Initialize core optimizer (other mixins don't need initialization)
        super().__init__(max_memory_percent, gc_threshold_mb, monitoring_interval)

    # get_memory_stats is now provided by CoreMemoryOptimizer

    # check_memory_pressure is now provided by CoreMemoryOptimizer

    # force_gc_if_needed is now provided by CoreMemoryOptimizer

    # chunked_processing is now provided by CoreMemoryOptimizer

    # get_object_from_pool and return_object_to_pool are now provided by CoreMemoryOptimizer

    # optimize_database_operations is now provided by DatabaseOptimizationMixin

    # efficient_ip_processing is now provided by BulkProcessorMixin

    # start_memory_monitoring, stop_memory_monitoring, and _monitoring_loop are now provided by CoreMemoryOptimizer

    # get_optimization_report and _generate_recommendations are now provided by ReportingMixin


# ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬ ìµœì í™”ê¸°
_global_memory_optimizer = None


def get_global_memory_optimizer() -> MemoryOptimizer:
    """ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬ ìµœì í™”ê¸° ë°˜í™˜"""
    global _global_memory_optimizer

    if _global_memory_optimizer is None:
        _global_memory_optimizer = MemoryOptimizer()

    return _global_memory_optimizer


def memory_efficient(chunk_size: int = 1000):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ ë°ì½”ë ˆì´í„°"""

    def decorator(func):
        def wrapper(data, *args, **kwargs):
            optimizer = get_global_memory_optimizer()

            if isinstance(data, list) and len(data) > chunk_size:
                results = []
                with optimizer.chunked_processing(data, chunk_size) as chunks:
                    for chunk_num, chunk, total_chunks in chunks:
                        chunk_result = func(chunk, *args, **kwargs)
                        results.extend(
                            chunk_result
                            if isinstance(chunk_result, list)
                            else [chunk_result]
                        )
                return results
            else:
                return func(data, *args, **kwargs)

        return wrapper

    return decorator


if __name__ == "__main__":
    """ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ ê²€ì¦"""
    import sys

    optimizer = MemoryOptimizer()
    all_tests_passed = True

    try:
        # í…ŒìŠ¤íŠ¸ 1: ë©”ëª¨ë¦¬ í†µê³„
        stats = optimizer.get_memory_stats()
        if stats.total_memory_mb <= 0:
            print("âŒ ë©”ëª¨ë¦¬ í†µê³„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            all_tests_passed = False

        # í…ŒìŠ¤íŠ¸ 2: ì²­í¬ ì²˜ë¦¬
        test_data = list(range(10000))
        processed_chunks = 0

        with optimizer.chunked_processing(test_data, chunk_size=1000) as chunks:
            for chunk_num, chunk, total_chunks in chunks:
                processed_chunks += 1
                if len(chunk) > 1000:
                    print("âŒ ì²­í¬ í¬ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                    all_tests_passed = False

        if processed_chunks != 10:
            print(f"âŒ ì²­í¬ ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: expected 10, got {processed_chunks}")
            all_tests_passed = False

        # í…ŒìŠ¤íŠ¸ 3: IP ì²˜ë¦¬ ìµœì í™”
        test_ips = [f"192.168.1.{i}" for i in range(1000)] * 2  # ì¤‘ë³µ í¬í•¨
        unique_ips = optimizer.efficient_ip_processing(test_ips)

        if len(unique_ips) != 1000:
            print(f"âŒ IP ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: expected 1000 unique IPs, got {len(unique_ips)}")
            all_tests_passed = False

        # í…ŒìŠ¤íŠ¸ 4: ê°ì²´ í’€
        def list_factory():
            return []

        obj1 = optimizer.get_object_from_pool("test_list", list_factory)
        optimizer.return_object_to_pool("test_list", obj1, lambda x: x.clear())
        obj2 = optimizer.get_object_from_pool("test_list")

        if obj1 is not obj2:
            print("âŒ ê°ì²´ í’€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            all_tests_passed = False

        # ìµœì¢… ë³´ê³ ì„œ
        report = optimizer.get_optimization_report()

        if all_tests_passed:
            print("âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ - ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼")
            print(f"ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {report['current_memory']['usage_percent']:.1f}%")
            print(f"ğŸ¯ ìµœì í™” í†µê³„: {report['optimization_stats']}")
            sys.exit(0)
        else:
            print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            sys.exit(1)

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
