<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="89" skipped="0" tests="188" time="9.491" timestamp="2025-08-08T19:56:40.548766" hostname="jclee-dev"><testcase classname="test_apis" name="test_regtech_apis" time="0.018" /><testcase classname="test_apis" name="test_secudium_apis" time="0.002" /><testcase classname="test_cicd_modules" name="test_imports" time="0.002" /><testcase classname="test_cicd_modules" name="test_functionality" time="0.002" /><testcase classname="test_cicd_modules" name="test_integration" time="0.002" /><testcase classname="test_cicd_modules" name="test_line_count_compliance" time="0.002" /><testcase classname="test_container_system" name="test_container_service_registration" time="0.004" /><testcase classname="test_container_system" name="test_container_singleton_behavior" time="0.002" /><testcase classname="test_container_system" name="test_container_dependency_injection" time="0.004" /><testcase classname="test_container_system" name="test_container_error_handling" time="0.003" /><testcase classname="test_core_endpoints" name="test_core_endpoints" time="0.009" /><testcase classname="test_core_endpoints" name="test_dashboard_charts" time="0.005" /><testcase classname="test_excel_integration" name="test_excel_download" time="0.112" /><testcase classname="integration.test_cache_database_integration.TestCacheDatabaseIntegration" name="test_cache_invalidation_on_collection" time="0.012"><failure message="assert 0 &gt; 0&#10; +  where 0 = len([])">tests/integration/test_cache_database_integration.py:48: in test_cache_invalidation_on_collection
    assert len(cache_calls) &gt; 0
E   assert 0 &gt; 0
E    +  where 0 = len([])</failure></testcase><testcase classname="integration.test_cache_database_integration.TestCacheDatabaseIntegration" name="test_cache_fallback_behavior" time="0.011"><failure message="AssertionError: Expected 'get_all_ips' to have been called.">/usr/lib/python3.10/unittest/mock.py:898: in assert_called
    raise AssertionError(msg)
E   AssertionError: Expected 'get_all_ips' to have been called.

During handling of the above exception, another exception occurred:
tests/integration/test_cache_database_integration.py:67: in test_cache_fallback_behavior
    service.blacklist_manager.get_all_ips.assert_called()
E   AssertionError: Expected 'get_all_ips' to have been called.</failure></testcase><testcase classname="integration.test_cache_database_integration.TestCacheDatabaseIntegration" name="test_database_transaction_handling" time="0.010"><failure message="assert 0 &gt; 0">tests/integration/test_cache_database_integration.py:102: in test_database_transaction_handling
    assert count &gt; 0
E   assert 0 &gt; 0</failure></testcase><testcase classname="integration.test_cache_database_integration.TestCacheDatabaseIntegration" name="test_bulk_operation_performance" time="0.011"><failure message="KeyError: 'collected'">tests/integration/test_cache_database_integration.py:131: in test_bulk_operation_performance
    assert result["collected"] == 1000
E   KeyError: 'collected'</failure></testcase><testcase classname="integration.test_cache_database_integration.TestCacheDatabaseIntegration" name="test_concurrent_service_access" time="0.014"><failure message="KeyError: 'enabled'">tests/integration/test_cache_database_integration.py:163: in test_concurrent_service_access
    assert all(r["status"]["enabled"] for r in results)
tests/integration/test_cache_database_integration.py:163: in &lt;genexpr&gt;
    assert all(r["status"]["enabled"] for r in results)
E   KeyError: 'enabled'</failure></testcase><testcase classname="integration.test_cicd_mocks.TestGitHubActionsMocking" name="test_workflow_dispatch_trigger" time="0.003" /><testcase classname="integration.test_cicd_mocks.TestGitHubActionsMocking" name="test_github_api_workflow_run" time="0.002" /><testcase classname="integration.test_cicd_mocks.TestDockerMocking" name="test_docker_client_mocking" time="0.066" /><testcase classname="integration.test_cicd_mocks.TestDockerMocking" name="test_docker_cli_mocking" time="0.002" /><testcase classname="integration.test_cicd_mocks.TestKubernetesMocking" name="test_k8s_api_mocking" time="0.194" /><testcase classname="integration.test_cicd_mocks.TestKubernetesMocking" name="test_kubectl_mocking" time="0.002" /><testcase classname="integration.test_cicd_mocks.TestArgoCDMocking" name="test_argocd_cli_mocking" time="0.002" /><testcase classname="integration.test_cicd_mocks.TestArgoCDMocking" name="test_argocd_api_mocking" time="0.002" /><testcase classname="integration.test_cicd_mocks.TestRegistryMocking" name="test_registry_api_mocking" time="0.002" /><testcase classname="integration.test_cicd_mocks.TestRegistryMocking" name="test_registry_login_mocking" time="0.002" /><testcase classname="integration.test_cicd_mocks.TestEndToEndMocking" name="test_full_pipeline_simulation" time="0.003" /><testcase classname="integration.test_cicd_mocks.TestEndToEndMocking" name="test_pipeline_failure_scenarios" time="0.002" /><testcase classname="integration.test_cicd_pipeline.TestCICDPipelineTriggers" name="test_main_branch_push_triggers_full_pipeline" time="0.095"><failure message="assert 'create-offline-package' in {'build': {'name': 'Build &amp; Push Container', 'needs': ['security-scan', 'test'], 'outputs': {'image-digest': '${{ steps.build.outputs.digest }}', 'image-tags': '${{ steps.meta.outputs.tags }}'}, 'runs-on': 'self-hosted', ...}, 'deploy-development': {'environment': 'development', 'if': &quot;github.ref == 'refs/heads/develop'&quot;, 'name': 'Deploy to Development', 'needs': 'build', ...}, 'deploy-production': {'environment': 'production', 'if': &quot;github.ref == 'refs/heads/main' &amp;&amp; github.event_name == 'workflow_dispatch' &amp;&amp; github.event.inputs.environment == 'production'&quot;, 'name': 'Deploy to Production', 'needs': ['build', 'deploy-staging'], ...}, 'deploy-staging': {'environment': 'staging', 'if': &quot;github.ref == 'refs/heads/main'&quot;, 'name': 'Deploy to Staging', 'needs': 'build', ...}, ...}">tests/integration/test_cicd_pipeline.py:49: in test_main_branch_push_triggers_full_pipeline
    assert job in workflow["jobs"]
E   assert 'create-offline-package' in {'build': {'name': 'Build &amp; Push Container', 'needs': ['security-scan', 'test'], 'outputs': {'image-digest': '${{ steps.build.outputs.digest }}', 'image-tags': '${{ steps.meta.outputs.tags }}'}, 'runs-on': 'self-hosted', ...}, 'deploy-development': {'environment': 'development', 'if': "github.ref == 'refs/heads/develop'", 'name': 'Deploy to Development', 'needs': 'build', ...}, 'deploy-production': {'environment': 'production', 'if': "github.ref == 'refs/heads/main' &amp;&amp; github.event_name == 'workflow_dispatch' &amp;&amp; github.event.inputs.environment == 'production'", 'name': 'Deploy to Production', 'needs': ['build', 'deploy-staging'], ...}, 'deploy-staging': {'environment': 'staging', 'if': "github.ref == 'refs/heads/main'", 'name': 'Deploy to Staging', 'needs': 'build', ...}, ...}</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestCICDPipelineTriggers" name="test_develop_branch_push_triggers_appropriate_workflow" time="0.025"><failure message="KeyError: 'on'">tests/integration/test_cicd_pipeline.py:57: in test_develop_branch_push_triggers_appropriate_workflow
    assert "develop" in workflow["on"]["push"]["branches"]
E   KeyError: 'on'</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestCICDPipelineTriggers" name="test_pr_creation_triggers_quality_checks_only" time="0.025"><failure message="KeyError: 'on'">tests/integration/test_cicd_pipeline.py:66: in test_pr_creation_triggers_quality_checks_only
    assert "pull_request" in workflow["on"]
E   KeyError: 'on'</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestCICDPipelineTriggers" name="test_path_ignoring_for_docs" time="0.024"><failure message="KeyError: 'on'">tests/integration/test_cicd_pipeline.py:76: in test_path_ignoring_for_docs
    paths_ignore = workflow["on"]["push"]["paths-ignore"]
E   KeyError: 'on'</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestCICDPipelineTriggers" name="test_concurrency_cancellation" time="0.025"><failure message="assert 'concurrency' in {'name': 'Complete CI/CD Pipeline', True: {'pull_request': {'branches': ['main']}, 'push': {'branches': ['main', 'develop']}, 'workflow_dispatch': {'inputs': {'environment': {'default': 'development', 'description': 'Target environment', 'options': ['development', 'staging', 'production'], 'required': True, ...}}}}, 'env': {'IMAGE_NAME': 'jclee94/blacklist', 'NAMESPACE': 'blacklist', 'REGISTRY': 'registry.jclee.me'}, 'jobs': {'build': {'name': 'Build &amp; Push Container', 'needs': ['security-scan', 'test'], 'outputs': {'image-digest': '${{ steps.build.outputs.digest }}', 'image-tags': '${{ steps.meta.outputs.tags }}'}, 'runs-on': 'self-hosted', ...}, 'deploy-development': {'environment': 'development', 'if': &quot;github.ref == 'refs/heads/develop'&quot;, 'name': 'Deploy to Development', 'needs': 'build', ...}, 'deploy-production': {'environment': 'production', 'if': &quot;github.ref == 'refs/heads/main' &amp;&amp; github.event_name == 'workflow_dispatch' &amp;&amp; github.event.inputs.environment == 'production'&quot;, 'name': 'Deploy to Production', 'needs': ['build', 'deploy-staging'], ...}, 'deploy-staging': {'environment': 'staging', 'if': &quot;github.ref == 'refs/heads/main'&quot;, 'name': 'Deploy to Staging', 'needs': 'build', ...}, ...}}">tests/integration/test_cicd_pipeline.py:86: in test_concurrency_cancellation
    assert "concurrency" in workflow
E   assert 'concurrency' in {'name': 'Complete CI/CD Pipeline', True: {'pull_request': {'branches': ['main']}, 'push': {'branches': ['main', 'develop']}, 'workflow_dispatch': {'inputs': {'environment': {'default': 'development', 'description': 'Target environment', 'options': ['development', 'staging', 'production'], 'required': True, ...}}}}, 'env': {'IMAGE_NAME': 'jclee94/blacklist', 'NAMESPACE': 'blacklist', 'REGISTRY': 'registry.jclee.me'}, 'jobs': {'build': {'name': 'Build &amp; Push Container', 'needs': ['security-scan', 'test'], 'outputs': {'image-digest': '${{ steps.build.outputs.digest }}', 'image-tags': '${{ steps.meta.outputs.tags }}'}, 'runs-on': 'self-hosted', ...}, 'deploy-development': {'environment': 'development', 'if': "github.ref == 'refs/heads/develop'", 'name': 'Deploy to Development', 'needs': 'build', ...}, 'deploy-production': {'environment': 'production', 'if': "github.ref == 'refs/heads/main' &amp;&amp; github.event_name == 'workflow_dispatch' &amp;&amp; github.event.inputs.environment == 'production'", 'name': 'Deploy to Production', 'needs': ['build', 'deploy-staging'], ...}, 'deploy-staging': {'environment': 'staging', 'if': "github.ref == 'refs/heads/main'", 'name': 'Deploy to Staging', 'needs': 'build', ...}, ...}}</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestCodeQualityStage" name="test_python_linting_catches_style_violations" time="0.004"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'python'">tests/integration/test_cicd_pipeline.py:115: in test_python_linting_catches_style_violations
    result = subprocess.run(
/usr/lib/python3.10/subprocess.py:503: in run
    with Popen(*popenargs, **kwargs) as process:
/usr/lib/python3.10/subprocess.py:971: in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
/usr/lib/python3.10/subprocess.py:1863: in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
E   FileNotFoundError: [Errno 2] No such file or directory: 'python'</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestCodeQualityStage" name="test_security_scanning_detects_hardcoded_secrets" time="0.004" /><testcase classname="integration.test_cicd_pipeline.TestCodeQualityStage" name="test_dependency_vulnerability_scanning" time="0.002" /><testcase classname="integration.test_cicd_pipeline.TestCodeQualityStage" name="test_code_coverage_threshold_enforcement" time="0.002"><failure message="assert ('--cov' in '[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts = \n    -v\n    --tb=short\n    --strict-markers\n    --disable-warnings\n    -p no:warnings\n    --ignore=scripts/\n    --ignore=archive/\nmarkers =\n    slow: marks tests as slow (deselect with \'-m &quot;not slow&quot;\')\n    integration: marks tests as integration tests\n    unit: marks tests as unit tests\n    manual: marks tests that require manual intervention' or 'coverage' in '[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = test*\npython_functions = test_*\naddopts = \n    -v\n    --tb=short\n    --strict-markers\n    --disable-warnings\n    -p no:warnings\n    --ignore=scripts/\n    --ignore=archive/\nmarkers =\n    slow: marks tests as slow (deselect with \'-m &quot;not slow&quot;\')\n    integration: marks tests as integration tests\n    unit: marks tests as unit tests\n    manual: marks tests that require manual intervention')&#10; +  where '[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = test*\npython_functions = test_*\naddopts = \n    -v\n    --tb=short\n    --strict-markers\n    --disable-warnings\n    -p no:warnings\n    --ignore=scripts/\n    --ignore=archive/\nmarkers =\n    slow: marks tests as slow (deselect with \'-m &quot;not slow&quot;\')\n    integration: marks tests as integration tests\n    unit: marks tests as unit tests\n    manual: marks tests that require manual intervention' = &lt;built-in method lower of str object at 0x756574e72a30&gt;()&#10; +    where &lt;built-in method lower of str object at 0x756574e72a30&gt; = '[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts = \n    -v\n    --tb=short\n    --strict-markers\n    --disable-warnings\n    -p no:warnings\n    --ignore=scripts/\n    --ignore=archive/\nmarkers =\n    slow: marks tests as slow (deselect with \'-m &quot;not slow&quot;\')\n    integration: marks tests as integration tests\n    unit: marks tests as unit tests\n    manual: marks tests that require manual intervention'.lower">tests/integration/test_cicd_pipeline.py:167: in test_code_coverage_threshold_enforcement
    assert "--cov" in content or "coverage" in content.lower()
E   assert ('--cov' in '[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts = \n    -v\n    --tb=short\n    --strict-markers\n    --disable-warnings\n    -p no:warnings\n    --ignore=scripts/\n    --ignore=archive/\nmarkers =\n    slow: marks tests as slow (deselect with \'-m "not slow"\')\n    integration: marks tests as integration tests\n    unit: marks tests as unit tests\n    manual: marks tests that require manual intervention' or 'coverage' in '[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = test*\npython_functions = test_*\naddopts = \n    -v\n    --tb=short\n    --strict-markers\n    --disable-warnings\n    -p no:warnings\n    --ignore=scripts/\n    --ignore=archive/\nmarkers =\n    slow: marks tests as slow (deselect with \'-m "not slow"\')\n    integration: marks tests as integration tests\n    unit: marks tests as unit tests\n    manual: marks tests that require manual intervention')
E    +  where '[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = test*\npython_functions = test_*\naddopts = \n    -v\n    --tb=short\n    --strict-markers\n    --disable-warnings\n    -p no:warnings\n    --ignore=scripts/\n    --ignore=archive/\nmarkers =\n    slow: marks tests as slow (deselect with \'-m "not slow"\')\n    integration: marks tests as integration tests\n    unit: marks tests as unit tests\n    manual: marks tests that require manual intervention' = &lt;built-in method lower of str object at 0x756574e72a30&gt;()
E    +    where &lt;built-in method lower of str object at 0x756574e72a30&gt; = '[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts = \n    -v\n    --tb=short\n    --strict-markers\n    --disable-warnings\n    -p no:warnings\n    --ignore=scripts/\n    --ignore=archive/\nmarkers =\n    slow: marks tests as slow (deselect with \'-m "not slow"\')\n    integration: marks tests as integration tests\n    unit: marks tests as unit tests\n    manual: marks tests that require manual intervention'.lower</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestBuildStage" name="test_docker_multi_stage_build" time="0.002"><failure message="assert 'FROM python:3.10-slim' in '# Multi-stage Python FastAPI Blacklist Management System\n# Stage 1: Builder for production dependencies\nFROM python:3.9 AS builder\n\n# Build arguments\nARG BUILD_TIME\nARG CACHE_BUST=1\nENV BUILD_TIME=${BUILD_TIME}\nENV CACHE_BUST=${CACHE_BUST}\nENV TZ=Asia/Seoul\n\n# python:3.9 already includes gcc, g++, and other build tools\n# No need to install them separately, saving significant build time\n\n# Create app user\nRUN useradd --create-home --shell /bin/bash app\n\n# Set working directory\nWORKDIR /app\n\n# Copy requirements first for better caching\nCOPY requirements.txt .\n\n# Install Python dependencies (production only)\nRUN pip install --no-cache-dir --upgrade pip &amp;&amp; \\\n    pip install --no-cache-dir -r requirements.txt\n\n# Stage 2: Production image with all dependencies\n# Using regular python:3.9 instead of slim to have curl pre-installed\nFROM python:3.9 AS production\n\n# Build arguments\nARG BUILD_TIME=&quot;Unknown&quot;\nENV BUILD_TIME=${BUILD_TIME}\nENV TZ=Asia/Seoul\nENV PYTHONPATH=/app\n\n# Verify curl is available (should be pre-installed in python:3.9)\nRUN which curl &amp;&amp; curl --version\n\n# Create app user\nRUN useradd --create-home --shell /bin/bash app\n\n# Set working directory\nWORKDIR /app\n\n# Copy Python packages from builder\nCOPY --from=builder /usr/local/lib/python3.9/site-packages /usr/local/lib/python3.9/site-packages\nCOPY --from=builder /usr/local/bin /usr/local/bin\n\n# Copy application code\nCOPY --chown=app:app . .\n\n# Create necessary directories\nRUN mkdir -p instance data logs &amp;&amp; \\\n    chown -R app:app /app\n\n# Switch to app user\nUSER app\n\n# Create database directory  \nRUN mkdir -p instance\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:${PORT:-8541}/health || exit 1\n\n# Expose port (configurable)\nEXPOSE ${PORT:-8541}\n\n# Copy startup script\nCOPY --chown=app:app startup.sh /app/startup.sh\nRUN chmod +x /app/startup.sh\n\n# Initialize database if needed and start application\nCMD [&quot;/app/startup.sh&quot;]'">tests/integration/test_cicd_pipeline.py:186: in test_docker_multi_stage_build
    assert "FROM python:3.10-slim" in dockerfile_content
E   assert 'FROM python:3.10-slim' in '# Multi-stage Python FastAPI Blacklist Management System\n# Stage 1: Builder for production dependencies\nFROM python:3.9 AS builder\n\n# Build arguments\nARG BUILD_TIME\nARG CACHE_BUST=1\nENV BUILD_TIME=${BUILD_TIME}\nENV CACHE_BUST=${CACHE_BUST}\nENV TZ=Asia/Seoul\n\n# python:3.9 already includes gcc, g++, and other build tools\n# No need to install them separately, saving significant build time\n\n# Create app user\nRUN useradd --create-home --shell /bin/bash app\n\n# Set working directory\nWORKDIR /app\n\n# Copy requirements first for better caching\nCOPY requirements.txt .\n\n# Install Python dependencies (production only)\nRUN pip install --no-cache-dir --upgrade pip &amp;&amp; \\\n    pip install --no-cache-dir -r requirements.txt\n\n# Stage 2: Production image with all dependencies\n# Using regular python:3.9 instead of slim to have curl pre-installed\nFROM python:3.9 AS production\n\n# Build arguments\nARG BUILD_TIME="Unknown"\nENV BUILD_TIME=${BUILD_TIME}\nENV TZ=Asia/Seoul\nENV PYTHONPATH=/app\n\n# Verify curl is available (should be pre-installed in python:3.9)\nRUN which curl &amp;&amp; curl --version\n\n# Create app user\nRUN useradd --create-home --shell /bin/bash app\n\n# Set working directory\nWORKDIR /app\n\n# Copy Python packages from builder\nCOPY --from=builder /usr/local/lib/python3.9/site-packages /usr/local/lib/python3.9/site-packages\nCOPY --from=builder /usr/local/bin /usr/local/bin\n\n# Copy application code\nCOPY --chown=app:app . .\n\n# Create necessary directories\nRUN mkdir -p instance data logs &amp;&amp; \\\n    chown -R app:app /app\n\n# Switch to app user\nUSER app\n\n# Create database directory  \nRUN mkdir -p instance\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:${PORT:-8541}/health || exit 1\n\n# Expose port (configurable)\nEXPOSE ${PORT:-8541}\n\n# Copy startup script\nCOPY --chown=app:app startup.sh /app/startup.sh\nRUN chmod +x /app/startup.sh\n\n# Initialize database if needed and start application\nCMD ["/app/startup.sh"]'</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestBuildStage" name="test_build_cache_utilization" time="0.002" /><testcase classname="integration.test_cicd_pipeline.TestBuildStage" name="test_image_tagging_strategy" time="0.002"><failure message="assert 'sha-' in 'name: Complete CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: \'Target environment\'\n        required: true\n        default: \'development\'\n        type: choice\n        options:\n        - development\n        - staging\n        - production\n\nenv:\n  REGISTRY: registry.jclee.me\n  IMAGE_NAME: jclee94/blacklist\n  NAMESPACE: blacklist\n\njobs:\n  security-scan:\n    name: Security &amp; Quality Checks\n    runs-on: self-hosted\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n        pip install bandit safety black flake8 pytest-cov\n\n    - name: Security scan with Bandit\n      run: |\n        bandit -r src/ -ll -f json -o bandit-report.json || true\n        bandit -r src/ -ll\n\n    - name: Dependency vulnerability check\n      run: |\n        safety check --json --output safety-report.json || true\n        safety check\n\n    - name: Code quality check\n      run: |\n        black --check src/ tests/ || true\n        flake8 src/ --max-line-length=88 --extend-ignore=E203,W503 || true\n\n    - name: File size enforcement (500-line rule)\n      run: |\n        echo &quot;Checking file sizes (500-line limit)...&quot;\n        find src/ -name &quot;*.py&quot; -exec wc -l {} + | awk \'$1 &gt; 500 {print &quot;❌ File too large:&quot;, $2, &quot;(&quot;$1&quot; lines)&quot;; exit_code=1} END {if(exit_code) exit 1}\'\n\n    - name: Upload security reports\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: security-reports\n        path: |\n          bandit-report.json\n          safety-report.json\n\n  test:\n    name: Test Suite\n    runs-on: self-hosted\n    needs: security-scan\n    \n    strategy:\n      matrix:\n        test-type: [unit, integration]\n        \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n\n    - name: Setup test environment\n      run: |\n        cp .env.example .env\n        # Set secure defaults for testing\n        echo &quot;FORCE_DISABLE_COLLECTION=true&quot; &gt;&gt; .env\n        echo &quot;COLLECTION_ENABLED=false&quot; &gt;&gt; .env\n        echo &quot;RESTART_PROTECTION=true&quot; &gt;&gt; .env\n        echo &quot;TEST_MODE=true&quot; &gt;&gt; .env\n        \n        # Initialize test database\n        PYTHONPATH=/home/jclee/app/blacklist python init_database.py\n\n    - name: Run unit tests\n      if: matrix.test-type == \'unit\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --junitxml=unit-test-results.xml\n\n    - name: Run integration tests\n      if: matrix.test-type == \'integration\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist python tests/integration/run_integration_tests.py\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/integration/ -v --junitxml=integration-test-results.xml -m &quot;not slow&quot;\n\n    - name: Upload test results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results-${{ matrix.test-type }}\n        path: |\n          *-test-results.xml\n          htmlcov/\n          coverage.xml\n\n  build:\n    name: Build &amp; Push Container\n    runs-on: self-hosted\n    needs: [security-scan, test]\n    \n    outputs:\n      image-digest: ${{ steps.build.outputs.digest }}\n      image-tags: ${{ steps.meta.outputs.tags }}\n      \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n      with:\n        config-inline: |\n          [registry.&quot;registry.jclee.me&quot;]\n            http = true\n            insecure = true\n\n    - name: Log in to Container Registry\n      uses: docker/login-action@v2\n      with:\n        registry: ${{ env.REGISTRY }}\n        username: ${{ secrets.DOCKER_REGISTRY_USER }}\n        password: ${{ secrets.DOCKER_REGISTRY_PASS }}\n\n    - name: Extract metadata\n      id: meta\n      uses: docker/metadata-action@v4\n      with:\n        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n        tags: |\n          type=ref,event=branch\n          type=ref,event=pr\n          type=semver,pattern={{version}}\n          type=sha,prefix={{branch}}-\n          type=raw,value=latest,enable={{is_default_branch}}\n\n    - name: Build and push container\n      id: build\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        file: ./deployment/Dockerfile\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        build-args: |\n          BUILD_DATE=${{ github.event.head_commit.timestamp }}\n          VCS_REF=${{ github.sha }}\n          VERSION=${{ github.ref_name }}\n\n    - name: Container image security scan\n      uses: aquasecurity/trivy-action@master\n      with:\n        image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n        format: \'sarif\'\n        output: \'trivy-results.sarif\'\n\n    - name: Upload Trivy scan results\n      uses: github/codeql-action/upload-sarif@v2\n      if: always()\n      with:\n        sarif_file: \'trivy-results.sarif\'\n\n  deploy-development:\n    name: Deploy to Development\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/develop\'\n    environment: development\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update Kubernetes manifests\n      run: |\n        sed -i &quot;s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|&quot; k8s/development/deployment.yaml\n\n    - name: Deploy to development cluster\n      run: |\n        kubectl apply -k k8s/development/\n        kubectl rollout status deployment/blacklist -n blacklist-dev --timeout=300s\n\n    - name: Health check\n      run: |\n        sleep 30\n        curl -f http://blacklist-dev.jclee.me/health || exit 1\n\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/main\'\n    environment: staging\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update staging manifests\n      run: |\n        sed -i &quot;s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|&quot; k8s/staging/deployment.yaml\n\n    - name: Deploy to staging\n      run: |\n        kubectl apply -k k8s/staging/\n        kubectl rollout status deployment/blacklist -n blacklist-staging --timeout=300s\n\n    - name: Run smoke tests\n      run: |\n        sleep 30\n        curl -f http://blacklist-staging.jclee.me/health\n        curl -f http://blacklist-staging.jclee.me/api/blacklist/active\n\n  deploy-production:\n    name: Deploy to Production\n    runs-on: self-hosted\n    needs: [build, deploy-staging]\n    if: github.ref == \'refs/heads/main\' &amp;&amp; github.event_name == \'workflow_dispatch\' &amp;&amp; github.event.inputs.environment == \'production\'\n    environment: production\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update production manifests\n      run: |\n        sed -i &quot;s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|&quot; k8s/production/deployment.yaml\n\n    - name: ArgoCD sync\n      run: |\n        # Update image annotation to trigger ArgoCD\n        kubectl annotate deployment blacklist -n blacklist \\\n          deployment.kubernetes.io/image-tag=&quot;${{ github.sha }}&quot; \\\n          --overwrite\n\n    - name: Trigger ArgoCD sync\n      run: |\n        curl -X POST &quot;https://argo.jclee.me/api/v1/applications/blacklist/sync&quot; \\\n          -H &quot;Authorization: Bearer ${{ secrets.ARGOCD_TOKEN }}&quot; \\\n          -H &quot;Content-Type: application/json&quot; \\\n          -d \'{&quot;revision&quot;: &quot;${{ github.sha }}&quot;}\'\n\n    - name: Wait for deployment\n      run: |\n        kubectl rollout status deployment/blacklist -n blacklist --timeout=600s\n\n    - name: Production health check\n      run: |\n        sleep 60\n        curl -f https://blacklist.jclee.me/health\n        curl -f https://blacklist.jclee.me/api/blacklist/active\n\n    - name: Notify deployment success\n      if: success()\n      run: |\n        echo &quot;#x1F680 Production deployment successful!&quot;\n        echo &quot;Version: ${{ github.sha }}&quot;\n        echo &quot;URL: https://blacklist.jclee.me&quot;\n\n  notification:\n    name: Notification\n    runs-on: self-hosted\n    needs: [deploy-development, deploy-staging, deploy-production]\n    if: always()\n    \n    steps:\n    - name: Deployment Status Summary\n      run: |\n        echo &quot;#x1F504 CI/CD Pipeline Complete&quot;\n        echo &quot;===============================&quot;\n        echo &quot;Branch: ${{ github.ref_name }}&quot;\n        echo &quot;Commit: ${{ github.sha }}&quot;\n        echo &quot;Security Scan: ${{ needs.security-scan.result }}&quot;\n        echo &quot;Tests: ${{ needs.test.result }}&quot;\n        echo &quot;Build: ${{ needs.build.result }}&quot;\n        \n        if [ &quot;${{ github.ref }}&quot; == &quot;refs/heads/develop&quot; ]; then\n          echo &quot;Development Deploy: ${{ needs.deploy-development.result }}&quot;\n        elif [ &quot;${{ github.ref }}&quot; == &quot;refs/heads/main&quot; ]; then\n          echo &quot;Staging Deploy: ${{ needs.deploy-staging.result }}&quot;\n          if [ &quot;${{ github.event.inputs.environment }}&quot; == &quot;production&quot; ]; then\n            echo &quot;Production Deploy: ${{ needs.deploy-production.result }}&quot;\n          fi\n        fi'">tests/integration/test_cicd_pipeline.py:205: in test_image_tagging_strategy
    assert "sha-" in workflow_content
E   assert 'sha-' in 'name: Complete CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: \'Target environment\'\n        required: true\n        default: \'development\'\n        type: choice\n        options:\n        - development\n        - staging\n        - production\n\nenv:\n  REGISTRY: registry.jclee.me\n  IMAGE_NAME: jclee94/blacklist\n  NAMESPACE: blacklist\n\njobs:\n  security-scan:\n    name: Security &amp; Quality Checks\n    runs-on: self-hosted\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n        pip install bandit safety black flake8 pytest-cov\n\n    - name: Security scan with Bandit\n      run: |\n        bandit -r src/ -ll -f json -o bandit-report.json || true\n        bandit -r src/ -ll\n\n    - name: Dependency vulnerability check\n      run: |\n        safety check --json --output safety-report.json || true\n        safety check\n\n    - name: Code quality check\n      run: |\n        black --check src/ tests/ || true\n        flake8 src/ --max-line-length=88 --extend-ignore=E203,W503 || true\n\n    - name: File size enforcement (500-line rule)\n      run: |\n        echo "Checking file sizes (500-line limit)..."\n        find src/ -name "*.py" -exec wc -l {} + | awk \'$1 &gt; 500 {print "❌ File too large:", $2, "("$1" lines)"; exit_code=1} END {if(exit_code) exit 1}\'\n\n    - name: Upload security reports\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: security-reports\n        path: |\n          bandit-report.json\n          safety-report.json\n\n  test:\n    name: Test Suite\n    runs-on: self-hosted\n    needs: security-scan\n    \n    strategy:\n      matrix:\n        test-type: [unit, integration]\n        \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n\n    - name: Setup test environment\n      run: |\n        cp .env.example .env\n        # Set secure defaults for testing\n        echo "FORCE_DISABLE_COLLECTION=true" &gt;&gt; .env\n        echo "COLLECTION_ENABLED=false" &gt;&gt; .env\n        echo "RESTART_PROTECTION=true" &gt;&gt; .env\n        echo "TEST_MODE=true" &gt;&gt; .env\n        \n        # Initialize test database\n        PYTHONPATH=/home/jclee/app/blacklist python init_database.py\n\n    - name: Run unit tests\n      if: matrix.test-type == \'unit\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --junitxml=unit-test-results.xml\n\n    - name: Run integration tests\n      if: matrix.test-type == \'integration\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist python tests/integration/run_integration_tests.py\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/integration/ -v --junitxml=integration-test-results.xml -m "not slow"\n\n    - name: Upload test results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results-${{ matrix.test-type }}\n        path: |\n          *-test-results.xml\n          htmlcov/\n          coverage.xml\n\n  build:\n    name: Build &amp; Push Container\n    runs-on: self-hosted\n    needs: [security-scan, test]\n    \n    outputs:\n      image-digest: ${{ steps.build.outputs.digest }}\n      image-tags: ${{ steps.meta.outputs.tags }}\n      \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n      with:\n        config-inline: |\n          [registry."registry.jclee.me"]\n            http = true\n            insecure = true\n\n    - name: Log in to Container Registry\n      uses: docker/login-action@v2\n      with:\n        registry: ${{ env.REGISTRY }}\n        username: ${{ secrets.DOCKER_REGISTRY_USER }}\n        password: ${{ secrets.DOCKER_REGISTRY_PASS }}\n\n    - name: Extract metadata\n      id: meta\n      uses: docker/metadata-action@v4\n      with:\n        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n        tags: |\n          type=ref,event=branch\n          type=ref,event=pr\n          type=semver,pattern={{version}}\n          type=sha,prefix={{branch}}-\n          type=raw,value=latest,enable={{is_default_branch}}\n\n    - name: Build and push container\n      id: build\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        file: ./deployment/Dockerfile\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        build-args: |\n          BUILD_DATE=${{ github.event.head_commit.timestamp }}\n          VCS_REF=${{ github.sha }}\n          VERSION=${{ github.ref_name }}\n\n    - name: Container image security scan\n      uses: aquasecurity/trivy-action@master\n      with:\n        image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n        format: \'sarif\'\n        output: \'trivy-results.sarif\'\n\n    - name: Upload Trivy scan results\n      uses: github/codeql-action/upload-sarif@v2\n      if: always()\n      with:\n        sarif_file: \'trivy-results.sarif\'\n\n  deploy-development:\n    name: Deploy to Development\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/develop\'\n    environment: development\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update Kubernetes manifests\n      run: |\n        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|" k8s/development/deployment.yaml\n\n    - name: Deploy to development cluster\n      run: |\n        kubectl apply -k k8s/development/\n        kubectl rollout status deployment/blacklist -n blacklist-dev --timeout=300s\n\n    - name: Health check\n      run: |\n        sleep 30\n        curl -f http://blacklist-dev.jclee.me/health || exit 1\n\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/main\'\n    environment: staging\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update staging manifests\n      run: |\n        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|" k8s/staging/deployment.yaml\n\n    - name: Deploy to staging\n      run: |\n        kubectl apply -k k8s/staging/\n        kubectl rollout status deployment/blacklist -n blacklist-staging --timeout=300s\n\n    - name: Run smoke tests\n      run: |\n        sleep 30\n        curl -f http://blacklist-staging.jclee.me/health\n        curl -f http://blacklist-staging.jclee.me/api/blacklist/active\n\n  deploy-production:\n    name: Deploy to Production\n    runs-on: self-hosted\n    needs: [build, deploy-staging]\n    if: github.ref == \'refs/heads/main\' &amp;&amp; github.event_name == \'workflow_dispatch\' &amp;&amp; github.event.inputs.environment == \'production\'\n    environment: production\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update production manifests\n      run: |\n        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|" k8s/production/deployment.yaml\n\n    - name: ArgoCD sync\n      run: |\n        # Update image annotation to trigger ArgoCD\n        kubectl annotate deployment blacklist -n blacklist \\\n          deployment.kubernetes.io/image-tag="${{ github.sha }}" \\\n          --overwrite\n\n    - name: Trigger ArgoCD sync\n      run: |\n        curl -X POST "https://argo.jclee.me/api/v1/applications/blacklist/sync" \\\n          -H "Authorization: Bearer ${{ secrets.ARGOCD_TOKEN }}" \\\n          -H "Content-Type: application/json" \\\n          -d \'{"revision": "${{ github.sha }}"}\'\n\n    - name: Wait for deployment\n      run: |\n        kubectl rollout status deployment/blacklist -n blacklist --timeout=600s\n\n    - name: Production health check\n      run: |\n        sleep 60\n        curl -f https://blacklist.jclee.me/health\n        curl -f https://blacklist.jclee.me/api/blacklist/active\n\n    - name: Notify deployment success\n      if: success()\n      run: |\n        echo "#x1F680 Production deployment successful!"\n        echo "Version: ${{ github.sha }}"\n        echo "URL: https://blacklist.jclee.me"\n\n  notification:\n    name: Notification\n    runs-on: self-hosted\n    needs: [deploy-development, deploy-staging, deploy-production]\n    if: always()\n    \n    steps:\n    - name: Deployment Status Summary\n      run: |\n        echo "#x1F504 CI/CD Pipeline Complete"\n        echo "==============================="\n        echo "Branch: ${{ github.ref_name }}"\n        echo "Commit: ${{ github.sha }}"\n        echo "Security Scan: ${{ needs.security-scan.result }}"\n        echo "Tests: ${{ needs.test.result }}"\n        echo "Build: ${{ needs.build.result }}"\n        \n        if [ "${{ github.ref }}" == "refs/heads/develop" ]; then\n          echo "Development Deploy: ${{ needs.deploy-development.result }}"\n        elif [ "${{ github.ref }}" == "refs/heads/main" ]; then\n          echo "Staging Deploy: ${{ needs.deploy-staging.result }}"\n          if [ "${{ github.event.inputs.environment }}" == "production" ]; then\n            echo "Production Deploy: ${{ needs.deploy-production.result }}"\n          fi\n        fi'</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestBuildStage" name="test_registry_authentication" time="0.002" /><testcase classname="integration.test_cicd_pipeline.TestDeploymentStage" name="test_argocd_application_sync" time="0.002"><failure message="AssertionError: assert False&#10; +  where False = &lt;bound method Path.exists of PosixPath('k8s/argocd-app-clean.yaml')&gt;()&#10; +    where &lt;bound method Path.exists of PosixPath('k8s/argocd-app-clean.yaml')&gt; = PosixPath('k8s/argocd-app-clean.yaml').exists">tests/integration/test_cicd_pipeline.py:232: in test_argocd_application_sync
    assert argocd_app_path.exists()
E   AssertionError: assert False
E    +  where False = &lt;bound method Path.exists of PosixPath('k8s/argocd-app-clean.yaml')&gt;()
E    +    where &lt;bound method Path.exists of PosixPath('k8s/argocd-app-clean.yaml')&gt; = PosixPath('k8s/argocd-app-clean.yaml').exists</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestDeploymentStage" name="test_image_update_detection" time="0.002"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'k8s/argocd-app-clean.yaml'">tests/integration/test_cicd_pipeline.py:245: in test_image_update_detection
    with open(argocd_app_path) as f:
E   FileNotFoundError: [Errno 2] No such file or directory: 'k8s/argocd-app-clean.yaml'</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestDeploymentStage" name="test_health_check_validation" time="0.002"><failure message="AssertionError: assert False&#10; +  where False = &lt;bound method Path.exists of PosixPath('k8s/deployment.yaml')&gt;()&#10; +    where &lt;bound method Path.exists of PosixPath('k8s/deployment.yaml')&gt; = PosixPath('k8s/deployment.yaml').exists">tests/integration/test_cicd_pipeline.py:259: in test_health_check_validation
    assert deployment_path.exists()
E   AssertionError: assert False
E    +  where False = &lt;bound method Path.exists of PosixPath('k8s/deployment.yaml')&gt;()
E    +    where &lt;bound method Path.exists of PosixPath('k8s/deployment.yaml')&gt; = PosixPath('k8s/deployment.yaml').exists</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestDeploymentStage" name="test_rollback_on_deployment_failure" time="0.002" /><testcase classname="integration.test_cicd_pipeline.TestDeploymentStage" name="test_multi_cluster_deployment" time="0.002"><failure message="AssertionError: assert False&#10; +  where False = &lt;bound method Path.exists of PosixPath('scripts/multi-deploy.sh')&gt;()&#10; +    where &lt;bound method Path.exists of PosixPath('scripts/multi-deploy.sh')&gt; = PosixPath('scripts/multi-deploy.sh').exists">tests/integration/test_cicd_pipeline.py:291: in test_multi_cluster_deployment
    assert multi_deploy_script.exists()
E   AssertionError: assert False
E    +  where False = &lt;bound method Path.exists of PosixPath('scripts/multi-deploy.sh')&gt;()
E    +    where &lt;bound method Path.exists of PosixPath('scripts/multi-deploy.sh')&gt; = PosixPath('scripts/multi-deploy.sh').exists</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestEndToEndFlow" name="test_full_pipeline_from_commit_to_deployment" time="0.002" /><testcase classname="integration.test_cicd_pipeline.TestEndToEndFlow" name="test_failure_recovery_at_each_stage" time="0.003"><failure message="assert ('retry' in 'name: Complete CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: \'Target environment\'\n        required: true\n        default: \'development\'\n        type: choice\n        options:\n        - development\n        - staging\n        - production\n\nenv:\n  REGISTRY: registry.jclee.me\n  IMAGE_NAME: jclee94/blacklist\n  NAMESPACE: blacklist\n\njobs:\n  security-scan:\n    name: Security &amp; Quality Checks\n    runs-on: self-hosted\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n        pip install bandit safety black flake8 pytest-cov\n\n    - name: Security scan with Bandit\n      run: |\n        bandit -r src/ -ll -f json -o bandit-report.json || true\n        bandit -r src/ -ll\n\n    - name: Dependency vulnerability check\n      run: |\n        safety check --json --output safety-report.json || true\n        safety check\n\n    - name: Code quality check\n      run: |\n        black --check src/ tests/ || true\n        flake8 src/ --max-line-length=88 --extend-ignore=E203,W503 || true\n\n    - name: File size enforcement (500-line rule)\n      run: |\n        echo &quot;Checking file sizes (500-line limit)...&quot;\n        find src/ -name &quot;*.py&quot; -exec wc -l {} + | awk \'$1 &gt; 500 {print &quot;❌ File too large:&quot;, $2, &quot;(&quot;$1&quot; lines)&quot;; exit_code=1} END {if(exit_code) exit 1}\'\n\n    - name: Upload security reports\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: security-reports\n        path: |\n          bandit-report.json\n          safety-report.json\n\n  test:\n    name: Test Suite\n    runs-on: self-hosted\n    needs: security-scan\n    \n    strategy:\n      matrix:\n        test-type: [unit, integration]\n        \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n\n    - name: Setup test environment\n      run: |\n        cp .env.example .env\n        # Set secure defaults for testing\n        echo &quot;FORCE_DISABLE_COLLECTION=true&quot; &gt;&gt; .env\n        echo &quot;COLLECTION_ENABLED=false&quot; &gt;&gt; .env\n        echo &quot;RESTART_PROTECTION=true&quot; &gt;&gt; .env\n        echo &quot;TEST_MODE=true&quot; &gt;&gt; .env\n        \n        # Initialize test database\n        PYTHONPATH=/home/jclee/app/blacklist python init_database.py\n\n    - name: Run unit tests\n      if: matrix.test-type == \'unit\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --junitxml=unit-test-results.xml\n\n    - name: Run integration tests\n      if: matrix.test-type == \'integration\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist python tests/integration/run_integration_tests.py\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/integration/ -v --junitxml=integration-test-results.xml -m &quot;not slow&quot;\n\n    - name: Upload test results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results-${{ matrix.test-type }}\n        path: |\n          *-test-results.xml\n          htmlcov/\n          coverage.xml\n\n  build:\n    name: Build &amp; Push Container\n    runs-on: self-hosted\n    needs: [security-scan, test]\n    \n    outputs:\n      image-digest: ${{ steps.build.outputs.digest }}\n      image-tags: ${{ steps.meta.outputs.tags }}\n      \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n      with:\n        config-inline: |\n          [registry.&quot;registry.jclee.me&quot;]\n            http = true\n            insecure = true\n\n    - name: Log in to Container Registry\n      uses: docker/login-action@v2\n      with:\n        registry: ${{ env.REGISTRY }}\n        username: ${{ secrets.DOCKER_REGISTRY_USER }}\n        password: ${{ secrets.DOCKER_REGISTRY_PASS }}\n\n    - name: Extract metadata\n      id: meta\n      uses: docker/metadata-action@v4\n      with:\n        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n        tags: |\n          type=ref,event=branch\n          type=ref,event=pr\n          type=semver,pattern={{version}}\n          type=sha,prefix={{branch}}-\n          type=raw,value=latest,enable={{is_default_branch}}\n\n    - name: Build and push container\n      id: build\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        file: ./deployment/Dockerfile\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        build-args: |\n          BUILD_DATE=${{ github.event.head_commit.timestamp }}\n          VCS_REF=${{ github.sha }}\n          VERSION=${{ github.ref_name }}\n\n    - name: Container image security scan\n      uses: aquasecurity/trivy-action@master\n      with:\n        image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n        format: \'sarif\'\n        output: \'trivy-results.sarif\'\n\n    - name: Upload Trivy scan results\n      uses: github/codeql-action/upload-sarif@v2\n      if: always()\n      with:\n        sarif_file: \'trivy-results.sarif\'\n\n  deploy-development:\n    name: Deploy to Development\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/develop\'\n    environment: development\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update Kubernetes manifests\n      run: |\n        sed -i &quot;s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|&quot; k8s/development/deployment.yaml\n\n    - name: Deploy to development cluster\n      run: |\n        kubectl apply -k k8s/development/\n        kubectl rollout status deployment/blacklist -n blacklist-dev --timeout=300s\n\n    - name: Health check\n      run: |\n        sleep 30\n        curl -f http://blacklist-dev.jclee.me/health || exit 1\n\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/main\'\n    environment: staging\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update staging manifests\n      run: |\n        sed -i &quot;s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|&quot; k8s/staging/deployment.yaml\n\n    - name: Deploy to staging\n      run: |\n        kubectl apply -k k8s/staging/\n        kubectl rollout status deployment/blacklist -n blacklist-staging --timeout=300s\n\n    - name: Run smoke tests\n      run: |\n        sleep 30\n        curl -f http://blacklist-staging.jclee.me/health\n        curl -f http://blacklist-staging.jclee.me/api/blacklist/active\n\n  deploy-production:\n    name: Deploy to Production\n    runs-on: self-hosted\n    needs: [build, deploy-staging]\n    if: github.ref == \'refs/heads/main\' &amp;&amp; github.event_name == \'workflow_dispatch\' &amp;&amp; github.event.inputs.environment == \'production\'\n    environment: production\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update production manifests\n      run: |\n        sed -i &quot;s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|&quot; k8s/production/deployment.yaml\n\n    - name: ArgoCD sync\n      run: |\n        # Update image annotation to trigger ArgoCD\n        kubectl annotate deployment blacklist -n blacklist \\\n          deployment.kubernetes.io/image-tag=&quot;${{ github.sha }}&quot; \\\n          --overwrite\n\n    - name: Trigger ArgoCD sync\n      run: |\n        curl -X POST &quot;https://argo.jclee.me/api/v1/applications/blacklist/sync&quot; \\\n          -H &quot;Authorization: Bearer ${{ secrets.ARGOCD_TOKEN }}&quot; \\\n          -H &quot;Content-Type: application/json&quot; \\\n          -d \'{&quot;revision&quot;: &quot;${{ github.sha }}&quot;}\'\n\n    - name: Wait for deployment\n      run: |\n        kubectl rollout status deployment/blacklist -n blacklist --timeout=600s\n\n    - name: Production health check\n      run: |\n        sleep 60\n        curl -f https://blacklist.jclee.me/health\n        curl -f https://blacklist.jclee.me/api/blacklist/active\n\n    - name: Notify deployment success\n      if: success()\n      run: |\n        echo &quot;#x1F680 Production deployment successful!&quot;\n        echo &quot;Version: ${{ github.sha }}&quot;\n        echo &quot;URL: https://blacklist.jclee.me&quot;\n\n  notification:\n    name: Notification\n    runs-on: self-hosted\n    needs: [deploy-development, deploy-staging, deploy-production]\n    if: always()\n    \n    steps:\n    - name: Deployment Status Summary\n      run: |\n        echo &quot;#x1F504 CI/CD Pipeline Complete&quot;\n        echo &quot;===============================&quot;\n        echo &quot;Branch: ${{ github.ref_name }}&quot;\n        echo &quot;Commit: ${{ github.sha }}&quot;\n        echo &quot;Security Scan: ${{ needs.security-scan.result }}&quot;\n        echo &quot;Tests: ${{ needs.test.result }}&quot;\n        echo &quot;Build: ${{ needs.build.result }}&quot;\n        \n        if [ &quot;${{ github.ref }}&quot; == &quot;refs/heads/develop&quot; ]; then\n          echo &quot;Development Deploy: ${{ needs.deploy-development.result }}&quot;\n        elif [ &quot;${{ github.ref }}&quot; == &quot;refs/heads/main&quot; ]; then\n          echo &quot;Staging Deploy: ${{ needs.deploy-staging.result }}&quot;\n          if [ &quot;${{ github.event.inputs.environment }}&quot; == &quot;production&quot; ]; then\n            echo &quot;Production Deploy: ${{ needs.deploy-production.result }}&quot;\n          fi\n        fi' or 'continue-on-error' in 'name: Complete CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: \'Target environment\'\n        required: true\n        default: \'development\'\n        type: choice\n        options:\n        - development\n        - staging\n        - production\n\nenv:\n  REGISTRY: registry.jclee.me\n  IMAGE_NAME: jclee94/blacklist\n  NAMESPACE: blacklist\n\njobs:\n  security-scan:\n    name: Security &amp; Quality Checks\n    runs-on: self-hosted\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n        pip install bandit safety black flake8 pytest-cov\n\n    - name: Security scan with Bandit\n      run: |\n        bandit -r src/ -ll -f json -o bandit-report.json || true\n        bandit -r src/ -ll\n\n    - name: Dependency vulnerability check\n      run: |\n        safety check --json --output safety-report.json || true\n        safety check\n\n    - name: Code quality check\n      run: |\n        black --check src/ tests/ || true\n        flake8 src/ --max-line-length=88 --extend-ignore=E203,W503 || true\n\n    - name: File size enforcement (500-line rule)\n      run: |\n        echo &quot;Checking file sizes (500-line limit)...&quot;\n        find src/ -name &quot;*.py&quot; -exec wc -l {} + | awk \'$1 &gt; 500 {print &quot;❌ File too large:&quot;, $2, &quot;(&quot;$1&quot; lines)&quot;; exit_code=1} END {if(exit_code) exit 1}\'\n\n    - name: Upload security reports\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: security-reports\n        path: |\n          bandit-report.json\n          safety-report.json\n\n  test:\n    name: Test Suite\n    runs-on: self-hosted\n    needs: security-scan\n    \n    strategy:\n      matrix:\n        test-type: [unit, integration]\n        \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n\n    - name: Setup test environment\n      run: |\n        cp .env.example .env\n        # Set secure defaults for testing\n        echo &quot;FORCE_DISABLE_COLLECTION=true&quot; &gt;&gt; .env\n        echo &quot;COLLECTION_ENABLED=false&quot; &gt;&gt; .env\n        echo &quot;RESTART_PROTECTION=true&quot; &gt;&gt; .env\n        echo &quot;TEST_MODE=true&quot; &gt;&gt; .env\n        \n        # Initialize test database\n        PYTHONPATH=/home/jclee/app/blacklist python init_database.py\n\n    - name: Run unit tests\n      if: matrix.test-type == \'unit\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --junitxml=unit-test-results.xml\n\n    - name: Run integration tests\n      if: matrix.test-type == \'integration\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist python tests/integration/run_integration_tests.py\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/integration/ -v --junitxml=integration-test-results.xml -m &quot;not slow&quot;\n\n    - name: Upload test results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results-${{ matrix.test-type }}\n        path: |\n          *-test-results.xml\n          htmlcov/\n          coverage.xml\n\n  build:\n    name: Build &amp; Push Container\n    runs-on: self-hosted\n    needs: [security-scan, test]\n    \n    outputs:\n      image-digest: ${{ steps.build.outputs.digest }}\n      image-tags: ${{ steps.meta.outputs.tags }}\n      \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n      with:\n        config-inline: |\n          [registry.&quot;registry.jclee.me&quot;]\n            http = true\n            insecure = true\n\n    - name: Log in to Container Registry\n      uses: docker/login-action@v2\n      with:\n        registry: ${{ env.REGISTRY }}\n        username: ${{ secrets.DOCKER_REGISTRY_USER }}\n        password: ${{ secrets.DOCKER_REGISTRY_PASS }}\n\n    - name: Extract metadata\n      id: meta\n      uses: docker/metadata-action@v4\n      with:\n        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n        tags: |\n          type=ref,event=branch\n          type=ref,event=pr\n          type=semver,pattern={{version}}\n          type=sha,prefix={{branch}}-\n          type=raw,value=latest,enable={{is_default_branch}}\n\n    - name: Build and push container\n      id: build\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        file: ./deployment/Dockerfile\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        build-args: |\n          BUILD_DATE=${{ github.event.head_commit.timestamp }}\n          VCS_REF=${{ github.sha }}\n          VERSION=${{ github.ref_name }}\n\n    - name: Container image security scan\n      uses: aquasecurity/trivy-action@master\n      with:\n        image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n        format: \'sarif\'\n        output: \'trivy-results.sarif\'\n\n    - name: Upload Trivy scan results\n      uses: github/codeql-action/upload-sarif@v2\n      if: always()\n      with:\n        sarif_file: \'trivy-results.sarif\'\n\n  deploy-development:\n    name: Deploy to Development\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/develop\'\n    environment: development\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update Kubernetes manifests\n      run: |\n        sed -i &quot;s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|&quot; k8s/development/deployment.yaml\n\n    - name: Deploy to development cluster\n      run: |\n        kubectl apply -k k8s/development/\n        kubectl rollout status deployment/blacklist -n blacklist-dev --timeout=300s\n\n    - name: Health check\n      run: |\n        sleep 30\n        curl -f http://blacklist-dev.jclee.me/health || exit 1\n\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/main\'\n    environment: staging\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update staging manifests\n      run: |\n        sed -i &quot;s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|&quot; k8s/staging/deployment.yaml\n\n    - name: Deploy to staging\n      run: |\n        kubectl apply -k k8s/staging/\n        kubectl rollout status deployment/blacklist -n blacklist-staging --timeout=300s\n\n    - name: Run smoke tests\n      run: |\n        sleep 30\n        curl -f http://blacklist-staging.jclee.me/health\n        curl -f http://blacklist-staging.jclee.me/api/blacklist/active\n\n  deploy-production:\n    name: Deploy to Production\n    runs-on: self-hosted\n    needs: [build, deploy-staging]\n    if: github.ref == \'refs/heads/main\' &amp;&amp; github.event_name == \'workflow_dispatch\' &amp;&amp; github.event.inputs.environment == \'production\'\n    environment: production\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update production manifests\n      run: |\n        sed -i &quot;s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|&quot; k8s/production/deployment.yaml\n\n    - name: ArgoCD sync\n      run: |\n        # Update image annotation to trigger ArgoCD\n        kubectl annotate deployment blacklist -n blacklist \\\n          deployment.kubernetes.io/image-tag=&quot;${{ github.sha }}&quot; \\\n          --overwrite\n\n    - name: Trigger ArgoCD sync\n      run: |\n        curl -X POST &quot;https://argo.jclee.me/api/v1/applications/blacklist/sync&quot; \\\n          -H &quot;Authorization: Bearer ${{ secrets.ARGOCD_TOKEN }}&quot; \\\n          -H &quot;Content-Type: application/json&quot; \\\n          -d \'{&quot;revision&quot;: &quot;${{ github.sha }}&quot;}\'\n\n    - name: Wait for deployment\n      run: |\n        kubectl rollout status deployment/blacklist -n blacklist --timeout=600s\n\n    - name: Production health check\n      run: |\n        sleep 60\n        curl -f https://blacklist.jclee.me/health\n        curl -f https://blacklist.jclee.me/api/blacklist/active\n\n    - name: Notify deployment success\n      if: success()\n      run: |\n        echo &quot;#x1F680 Production deployment successful!&quot;\n        echo &quot;Version: ${{ github.sha }}&quot;\n        echo &quot;URL: https://blacklist.jclee.me&quot;\n\n  notification:\n    name: Notification\n    runs-on: self-hosted\n    needs: [deploy-development, deploy-staging, deploy-production]\n    if: always()\n    \n    steps:\n    - name: Deployment Status Summary\n      run: |\n        echo &quot;#x1F504 CI/CD Pipeline Complete&quot;\n        echo &quot;===============================&quot;\n        echo &quot;Branch: ${{ github.ref_name }}&quot;\n        echo &quot;Commit: ${{ github.sha }}&quot;\n        echo &quot;Security Scan: ${{ needs.security-scan.result }}&quot;\n        echo &quot;Tests: ${{ needs.test.result }}&quot;\n        echo &quot;Build: ${{ needs.build.result }}&quot;\n        \n        if [ &quot;${{ github.ref }}&quot; == &quot;refs/heads/develop&quot; ]; then\n          echo &quot;Development Deploy: ${{ needs.deploy-development.result }}&quot;\n        elif [ &quot;${{ github.ref }}&quot; == &quot;refs/heads/main&quot; ]; then\n          echo &quot;Staging Deploy: ${{ needs.deploy-staging.result }}&quot;\n          if [ &quot;${{ github.event.inputs.environment }}&quot; == &quot;production&quot; ]; then\n            echo &quot;Production Deploy: ${{ needs.deploy-production.result }}&quot;\n          fi\n        fi')">tests/integration/test_cicd_pipeline.py:373: in test_failure_recovery_at_each_stage
    assert "retry" in workflow_content or "continue-on-error" in workflow_content
E   assert ('retry' in 'name: Complete CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: \'Target environment\'\n        required: true\n        default: \'development\'\n        type: choice\n        options:\n        - development\n        - staging\n        - production\n\nenv:\n  REGISTRY: registry.jclee.me\n  IMAGE_NAME: jclee94/blacklist\n  NAMESPACE: blacklist\n\njobs:\n  security-scan:\n    name: Security &amp; Quality Checks\n    runs-on: self-hosted\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n        pip install bandit safety black flake8 pytest-cov\n\n    - name: Security scan with Bandit\n      run: |\n        bandit -r src/ -ll -f json -o bandit-report.json || true\n        bandit -r src/ -ll\n\n    - name: Dependency vulnerability check\n      run: |\n        safety check --json --output safety-report.json || true\n        safety check\n\n    - name: Code quality check\n      run: |\n        black --check src/ tests/ || true\n        flake8 src/ --max-line-length=88 --extend-ignore=E203,W503 || true\n\n    - name: File size enforcement (500-line rule)\n      run: |\n        echo "Checking file sizes (500-line limit)..."\n        find src/ -name "*.py" -exec wc -l {} + | awk \'$1 &gt; 500 {print "❌ File too large:", $2, "("$1" lines)"; exit_code=1} END {if(exit_code) exit 1}\'\n\n    - name: Upload security reports\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: security-reports\n        path: |\n          bandit-report.json\n          safety-report.json\n\n  test:\n    name: Test Suite\n    runs-on: self-hosted\n    needs: security-scan\n    \n    strategy:\n      matrix:\n        test-type: [unit, integration]\n        \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n\n    - name: Setup test environment\n      run: |\n        cp .env.example .env\n        # Set secure defaults for testing\n        echo "FORCE_DISABLE_COLLECTION=true" &gt;&gt; .env\n        echo "COLLECTION_ENABLED=false" &gt;&gt; .env\n        echo "RESTART_PROTECTION=true" &gt;&gt; .env\n        echo "TEST_MODE=true" &gt;&gt; .env\n        \n        # Initialize test database\n        PYTHONPATH=/home/jclee/app/blacklist python init_database.py\n\n    - name: Run unit tests\n      if: matrix.test-type == \'unit\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --junitxml=unit-test-results.xml\n\n    - name: Run integration tests\n      if: matrix.test-type == \'integration\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist python tests/integration/run_integration_tests.py\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/integration/ -v --junitxml=integration-test-results.xml -m "not slow"\n\n    - name: Upload test results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results-${{ matrix.test-type }}\n        path: |\n          *-test-results.xml\n          htmlcov/\n          coverage.xml\n\n  build:\n    name: Build &amp; Push Container\n    runs-on: self-hosted\n    needs: [security-scan, test]\n    \n    outputs:\n      image-digest: ${{ steps.build.outputs.digest }}\n      image-tags: ${{ steps.meta.outputs.tags }}\n      \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n      with:\n        config-inline: |\n          [registry."registry.jclee.me"]\n            http = true\n            insecure = true\n\n    - name: Log in to Container Registry\n      uses: docker/login-action@v2\n      with:\n        registry: ${{ env.REGISTRY }}\n        username: ${{ secrets.DOCKER_REGISTRY_USER }}\n        password: ${{ secrets.DOCKER_REGISTRY_PASS }}\n\n    - name: Extract metadata\n      id: meta\n      uses: docker/metadata-action@v4\n      with:\n        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n        tags: |\n          type=ref,event=branch\n          type=ref,event=pr\n          type=semver,pattern={{version}}\n          type=sha,prefix={{branch}}-\n          type=raw,value=latest,enable={{is_default_branch}}\n\n    - name: Build and push container\n      id: build\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        file: ./deployment/Dockerfile\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        build-args: |\n          BUILD_DATE=${{ github.event.head_commit.timestamp }}\n          VCS_REF=${{ github.sha }}\n          VERSION=${{ github.ref_name }}\n\n    - name: Container image security scan\n      uses: aquasecurity/trivy-action@master\n      with:\n        image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n        format: \'sarif\'\n        output: \'trivy-results.sarif\'\n\n    - name: Upload Trivy scan results\n      uses: github/codeql-action/upload-sarif@v2\n      if: always()\n      with:\n        sarif_file: \'trivy-results.sarif\'\n\n  deploy-development:\n    name: Deploy to Development\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/develop\'\n    environment: development\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update Kubernetes manifests\n      run: |\n        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|" k8s/development/deployment.yaml\n\n    - name: Deploy to development cluster\n      run: |\n        kubectl apply -k k8s/development/\n        kubectl rollout status deployment/blacklist -n blacklist-dev --timeout=300s\n\n    - name: Health check\n      run: |\n        sleep 30\n        curl -f http://blacklist-dev.jclee.me/health || exit 1\n\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/main\'\n    environment: staging\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update staging manifests\n      run: |\n        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|" k8s/staging/deployment.yaml\n\n    - name: Deploy to staging\n      run: |\n        kubectl apply -k k8s/staging/\n        kubectl rollout status deployment/blacklist -n blacklist-staging --timeout=300s\n\n    - name: Run smoke tests\n      run: |\n        sleep 30\n        curl -f http://blacklist-staging.jclee.me/health\n        curl -f http://blacklist-staging.jclee.me/api/blacklist/active\n\n  deploy-production:\n    name: Deploy to Production\n    runs-on: self-hosted\n    needs: [build, deploy-staging]\n    if: github.ref == \'refs/heads/main\' &amp;&amp; github.event_name == \'workflow_dispatch\' &amp;&amp; github.event.inputs.environment == \'production\'\n    environment: production\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update production manifests\n      run: |\n        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|" k8s/production/deployment.yaml\n\n    - name: ArgoCD sync\n      run: |\n        # Update image annotation to trigger ArgoCD\n        kubectl annotate deployment blacklist -n blacklist \\\n          deployment.kubernetes.io/image-tag="${{ github.sha }}" \\\n          --overwrite\n\n    - name: Trigger ArgoCD sync\n      run: |\n        curl -X POST "https://argo.jclee.me/api/v1/applications/blacklist/sync" \\\n          -H "Authorization: Bearer ${{ secrets.ARGOCD_TOKEN }}" \\\n          -H "Content-Type: application/json" \\\n          -d \'{"revision": "${{ github.sha }}"}\'\n\n    - name: Wait for deployment\n      run: |\n        kubectl rollout status deployment/blacklist -n blacklist --timeout=600s\n\n    - name: Production health check\n      run: |\n        sleep 60\n        curl -f https://blacklist.jclee.me/health\n        curl -f https://blacklist.jclee.me/api/blacklist/active\n\n    - name: Notify deployment success\n      if: success()\n      run: |\n        echo "#x1F680 Production deployment successful!"\n        echo "Version: ${{ github.sha }}"\n        echo "URL: https://blacklist.jclee.me"\n\n  notification:\n    name: Notification\n    runs-on: self-hosted\n    needs: [deploy-development, deploy-staging, deploy-production]\n    if: always()\n    \n    steps:\n    - name: Deployment Status Summary\n      run: |\n        echo "#x1F504 CI/CD Pipeline Complete"\n        echo "==============================="\n        echo "Branch: ${{ github.ref_name }}"\n        echo "Commit: ${{ github.sha }}"\n        echo "Security Scan: ${{ needs.security-scan.result }}"\n        echo "Tests: ${{ needs.test.result }}"\n        echo "Build: ${{ needs.build.result }}"\n        \n        if [ "${{ github.ref }}" == "refs/heads/develop" ]; then\n          echo "Development Deploy: ${{ needs.deploy-development.result }}"\n        elif [ "${{ github.ref }}" == "refs/heads/main" ]; then\n          echo "Staging Deploy: ${{ needs.deploy-staging.result }}"\n          if [ "${{ github.event.inputs.environment }}" == "production" ]; then\n            echo "Production Deploy: ${{ needs.deploy-production.result }}"\n          fi\n        fi' or 'continue-on-error' in 'name: Complete CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: \'Target environment\'\n        required: true\n        default: \'development\'\n        type: choice\n        options:\n        - development\n        - staging\n        - production\n\nenv:\n  REGISTRY: registry.jclee.me\n  IMAGE_NAME: jclee94/blacklist\n  NAMESPACE: blacklist\n\njobs:\n  security-scan:\n    name: Security &amp; Quality Checks\n    runs-on: self-hosted\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n        pip install bandit safety black flake8 pytest-cov\n\n    - name: Security scan with Bandit\n      run: |\n        bandit -r src/ -ll -f json -o bandit-report.json || true\n        bandit -r src/ -ll\n\n    - name: Dependency vulnerability check\n      run: |\n        safety check --json --output safety-report.json || true\n        safety check\n\n    - name: Code quality check\n      run: |\n        black --check src/ tests/ || true\n        flake8 src/ --max-line-length=88 --extend-ignore=E203,W503 || true\n\n    - name: File size enforcement (500-line rule)\n      run: |\n        echo "Checking file sizes (500-line limit)..."\n        find src/ -name "*.py" -exec wc -l {} + | awk \'$1 &gt; 500 {print "❌ File too large:", $2, "("$1" lines)"; exit_code=1} END {if(exit_code) exit 1}\'\n\n    - name: Upload security reports\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: security-reports\n        path: |\n          bandit-report.json\n          safety-report.json\n\n  test:\n    name: Test Suite\n    runs-on: self-hosted\n    needs: security-scan\n    \n    strategy:\n      matrix:\n        test-type: [unit, integration]\n        \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: \'3.11\'\n        cache: \'pip\'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n\n    - name: Setup test environment\n      run: |\n        cp .env.example .env\n        # Set secure defaults for testing\n        echo "FORCE_DISABLE_COLLECTION=true" &gt;&gt; .env\n        echo "COLLECTION_ENABLED=false" &gt;&gt; .env\n        echo "RESTART_PROTECTION=true" &gt;&gt; .env\n        echo "TEST_MODE=true" &gt;&gt; .env\n        \n        # Initialize test database\n        PYTHONPATH=/home/jclee/app/blacklist python init_database.py\n\n    - name: Run unit tests\n      if: matrix.test-type == \'unit\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --junitxml=unit-test-results.xml\n\n    - name: Run integration tests\n      if: matrix.test-type == \'integration\'\n      run: |\n        PYTHONPATH=/home/jclee/app/blacklist python tests/integration/run_integration_tests.py\n        PYTHONPATH=/home/jclee/app/blacklist pytest tests/integration/ -v --junitxml=integration-test-results.xml -m "not slow"\n\n    - name: Upload test results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results-${{ matrix.test-type }}\n        path: |\n          *-test-results.xml\n          htmlcov/\n          coverage.xml\n\n  build:\n    name: Build &amp; Push Container\n    runs-on: self-hosted\n    needs: [security-scan, test]\n    \n    outputs:\n      image-digest: ${{ steps.build.outputs.digest }}\n      image-tags: ${{ steps.meta.outputs.tags }}\n      \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n      with:\n        config-inline: |\n          [registry."registry.jclee.me"]\n            http = true\n            insecure = true\n\n    - name: Log in to Container Registry\n      uses: docker/login-action@v2\n      with:\n        registry: ${{ env.REGISTRY }}\n        username: ${{ secrets.DOCKER_REGISTRY_USER }}\n        password: ${{ secrets.DOCKER_REGISTRY_PASS }}\n\n    - name: Extract metadata\n      id: meta\n      uses: docker/metadata-action@v4\n      with:\n        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n        tags: |\n          type=ref,event=branch\n          type=ref,event=pr\n          type=semver,pattern={{version}}\n          type=sha,prefix={{branch}}-\n          type=raw,value=latest,enable={{is_default_branch}}\n\n    - name: Build and push container\n      id: build\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        file: ./deployment/Dockerfile\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        build-args: |\n          BUILD_DATE=${{ github.event.head_commit.timestamp }}\n          VCS_REF=${{ github.sha }}\n          VERSION=${{ github.ref_name }}\n\n    - name: Container image security scan\n      uses: aquasecurity/trivy-action@master\n      with:\n        image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n        format: \'sarif\'\n        output: \'trivy-results.sarif\'\n\n    - name: Upload Trivy scan results\n      uses: github/codeql-action/upload-sarif@v2\n      if: always()\n      with:\n        sarif_file: \'trivy-results.sarif\'\n\n  deploy-development:\n    name: Deploy to Development\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/develop\'\n    environment: development\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update Kubernetes manifests\n      run: |\n        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|" k8s/development/deployment.yaml\n\n    - name: Deploy to development cluster\n      run: |\n        kubectl apply -k k8s/development/\n        kubectl rollout status deployment/blacklist -n blacklist-dev --timeout=300s\n\n    - name: Health check\n      run: |\n        sleep 30\n        curl -f http://blacklist-dev.jclee.me/health || exit 1\n\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: self-hosted\n    needs: build\n    if: github.ref == \'refs/heads/main\'\n    environment: staging\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update staging manifests\n      run: |\n        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|" k8s/staging/deployment.yaml\n\n    - name: Deploy to staging\n      run: |\n        kubectl apply -k k8s/staging/\n        kubectl rollout status deployment/blacklist -n blacklist-staging --timeout=300s\n\n    - name: Run smoke tests\n      run: |\n        sleep 30\n        curl -f http://blacklist-staging.jclee.me/health\n        curl -f http://blacklist-staging.jclee.me/api/blacklist/active\n\n  deploy-production:\n    name: Deploy to Production\n    runs-on: self-hosted\n    needs: [build, deploy-staging]\n    if: github.ref == \'refs/heads/main\' &amp;&amp; github.event_name == \'workflow_dispatch\' &amp;&amp; github.event.inputs.environment == \'production\'\n    environment: production\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Update production manifests\n      run: |\n        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}|" k8s/production/deployment.yaml\n\n    - name: ArgoCD sync\n      run: |\n        # Update image annotation to trigger ArgoCD\n        kubectl annotate deployment blacklist -n blacklist \\\n          deployment.kubernetes.io/image-tag="${{ github.sha }}" \\\n          --overwrite\n\n    - name: Trigger ArgoCD sync\n      run: |\n        curl -X POST "https://argo.jclee.me/api/v1/applications/blacklist/sync" \\\n          -H "Authorization: Bearer ${{ secrets.ARGOCD_TOKEN }}" \\\n          -H "Content-Type: application/json" \\\n          -d \'{"revision": "${{ github.sha }}"}\'\n\n    - name: Wait for deployment\n      run: |\n        kubectl rollout status deployment/blacklist -n blacklist --timeout=600s\n\n    - name: Production health check\n      run: |\n        sleep 60\n        curl -f https://blacklist.jclee.me/health\n        curl -f https://blacklist.jclee.me/api/blacklist/active\n\n    - name: Notify deployment success\n      if: success()\n      run: |\n        echo "#x1F680 Production deployment successful!"\n        echo "Version: ${{ github.sha }}"\n        echo "URL: https://blacklist.jclee.me"\n\n  notification:\n    name: Notification\n    runs-on: self-hosted\n    needs: [deploy-development, deploy-staging, deploy-production]\n    if: always()\n    \n    steps:\n    - name: Deployment Status Summary\n      run: |\n        echo "#x1F504 CI/CD Pipeline Complete"\n        echo "==============================="\n        echo "Branch: ${{ github.ref_name }}"\n        echo "Commit: ${{ github.sha }}"\n        echo "Security Scan: ${{ needs.security-scan.result }}"\n        echo "Tests: ${{ needs.test.result }}"\n        echo "Build: ${{ needs.build.result }}"\n        \n        if [ "${{ github.ref }}" == "refs/heads/develop" ]; then\n          echo "Development Deploy: ${{ needs.deploy-development.result }}"\n        elif [ "${{ github.ref }}" == "refs/heads/main" ]; then\n          echo "Staging Deploy: ${{ needs.deploy-staging.result }}"\n          if [ "${{ github.event.inputs.environment }}" == "production" ]; then\n            echo "Production Deploy: ${{ needs.deploy-production.result }}"\n          fi\n        fi')</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestEndToEndFlow" name="test_notification_and_alerting" time="0.002"><failure message="AssertionError: assert False&#10; +  where False = &lt;bound method Path.exists of PosixPath('.github/workflows/create-issue-on-failure.yml')&gt;()&#10; +    where &lt;bound method Path.exists of PosixPath('.github/workflows/create-issue-on-failure.yml')&gt; = PosixPath('.github/workflows/create-issue-on-failure.yml').exists">tests/integration/test_cicd_pipeline.py:379: in test_notification_and_alerting
    assert issue_workflow.exists()
E   AssertionError: assert False
E    +  where False = &lt;bound method Path.exists of PosixPath('.github/workflows/create-issue-on-failure.yml')&gt;()
E    +    where &lt;bound method Path.exists of PosixPath('.github/workflows/create-issue-on-failure.yml')&gt; = PosixPath('.github/workflows/create-issue-on-failure.yml').exists</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestPipelineRefactoring" name="test_configuration_extraction" time="0.028" /><testcase classname="integration.test_cicd_pipeline.TestPipelineRefactoring" name="test_pipeline_hooks_availability" time="0.002" /><testcase classname="integration.test_cicd_pipeline.TestPipelineRefactoring" name="test_script_modularity" time="0.002"><failure message="AssertionError: assert False&#10; +  where False = &lt;bound method Path.exists of PosixPath('scripts/multi-deploy.sh')&gt;()&#10; +    where &lt;bound method Path.exists of PosixPath('scripts/multi-deploy.sh')&gt; = (PosixPath('scripts') / 'multi-deploy.sh').exists">tests/integration/test_cicd_pipeline.py:429: in test_script_modularity
    assert (scripts_dir / script).exists()
E   AssertionError: assert False
E    +  where False = &lt;bound method Path.exists of PosixPath('scripts/multi-deploy.sh')&gt;()
E    +    where &lt;bound method Path.exists of PosixPath('scripts/multi-deploy.sh')&gt; = (PosixPath('scripts') / 'multi-deploy.sh').exists</failure></testcase><testcase classname="integration.test_cicd_pipeline.TestPipelineRefactoring" name="test_dry_run_mode_support" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestPipelineConfig" name="test_config_from_environment" time="0.003"><failure message="AssertionError: assert 'registry.jclee.me' == 'test.registry.com'&#10;  - test.registry.com&#10;  + registry.jclee.me">tests/integration/test_cicd_refactoring.py:166: in test_config_from_environment
    assert config.registry == "test.registry.com"
E   AssertionError: assert 'registry.jclee.me' == 'test.registry.com'
E     - test.registry.com
E     + registry.jclee.me</failure></testcase><testcase classname="integration.test_cicd_refactoring.TestPipelineConfig" name="test_config_defaults" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestPipelineStage" name="test_stage_lifecycle" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestPipelineStage" name="test_stage_failure_handling" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestPipelineStage" name="test_dry_run_mode" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestCodeQualityStage" name="test_python_syntax_check" time="0.002"><failure message="AssertionError: Expected 'run' to have been called once. Called 0 times.">/usr/lib/python3.10/unittest/mock.py:908: in assert_called_once
    raise AssertionError(msg)
E   AssertionError: Expected 'run' to have been called once. Called 0 times.

During handling of the above exception, another exception occurred:
tests/integration/test_cicd_refactoring.py:257: in test_python_syntax_check
    mock_run.assert_called_once()
E   AssertionError: Expected 'run' to have been called once. Called 0 times.</failure></testcase><testcase classname="integration.test_cicd_refactoring.TestCodeQualityStage" name="test_code_style_check" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestCodeQualityStage" name="test_security_scan" time="0.002"><failure message="assert True is False">tests/integration/test_cicd_refactoring.py:289: in test_security_scan
    assert result is False
E   assert True is False</failure></testcase><testcase classname="integration.test_cicd_refactoring.TestCodeQualityStage" name="test_dependency_check" time="0.003"><failure message="assert True is False">tests/integration/test_cicd_refactoring.py:320: in test_dependency_check
    assert result is False
E   assert True is False</failure></testcase><testcase classname="integration.test_cicd_refactoring.TestBuildStage" name="test_docker_build" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestBuildStage" name="test_commit_sha_extraction" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestBuildStage" name="test_build_failure_handling" time="0.002"><failure message="assert True is False">tests/integration/test_cicd_refactoring.py:367: in test_build_failure_handling
    assert result is False
E   assert True is False</failure></testcase><testcase classname="integration.test_cicd_refactoring.TestDeploymentStage" name="test_argocd_sync" time="0.003"><failure message="AssertionError: expected call not found.&#10;Expected: run(['argocd', 'app', 'sync', 'blacklist', '--server', 'argo.jclee.me', '--grpc-web'], capture_output=True)&#10;Actual: not called.">/usr/lib/python3.10/unittest/mock.py:920: in assert_called_with
    raise AssertionError(error_message)
E   AssertionError: expected call not found.
E   Expected: run(['argocd', 'app', 'sync', 'blacklist', '--server', 'argo.jclee.me', '--grpc-web'], capture_output=True)
E   Actual: not called.

During handling of the above exception, another exception occurred:
tests/integration/test_cicd_refactoring.py:384: in test_argocd_sync
    mock_run.assert_called_with(
E   AssertionError: expected call not found.
E   Expected: run(['argocd', 'app', 'sync', 'blacklist', '--server', 'argo.jclee.me', '--grpc-web'], capture_output=True)
E   Actual: not called.</failure></testcase><testcase classname="integration.test_cicd_refactoring.TestDeploymentStage" name="test_deployment_verification" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestDeploymentStage" name="test_rollback_on_failure" time="0.003" /><testcase classname="integration.test_cicd_refactoring.TestPipelineOrchestrator" name="test_full_pipeline_execution" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestPipelineOrchestrator" name="test_pipeline_with_skip_stages" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestPipelineOrchestrator" name="test_pipeline_failure_stops_execution" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestCLIInterface" name="test_cli_dry_run" time="0.003"><failure message="ModuleNotFoundError: No module named 'scripts.lib.cicd_testability'">/usr/lib/python3.10/unittest/mock.py:1248: in _dot_lookup
    return getattr(thing, comp)
E   AttributeError: module 'scripts.lib' has no attribute 'cicd_testability'

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/unittest/mock.py:1376: in patched
    with self.decoration_helper(patched,
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/usr/lib/python3.10/unittest/mock.py:1358: in decoration_helper
    arg = exit_stack.enter_context(patching)
/usr/lib/python3.10/contextlib.py:492: in enter_context
    result = _cm_type.__enter__(cm)
/usr/lib/python3.10/unittest/mock.py:1431: in __enter__
    self.target = self.getter()
/usr/lib/python3.10/unittest/mock.py:1618: in &lt;lambda&gt;
    getter = lambda: _importer(target)
/usr/lib/python3.10/unittest/mock.py:1261: in _importer
    thing = _dot_lookup(thing, comp, import_path)
/usr/lib/python3.10/unittest/mock.py:1250: in _dot_lookup
    __import__(import_path)
E   ModuleNotFoundError: No module named 'scripts.lib.cicd_testability'</failure></testcase><testcase classname="integration.test_cicd_refactoring.TestCLIInterface" name="test_cli_single_stage" time="0.003"><failure message="ModuleNotFoundError: No module named 'scripts.lib.cicd_testability'">tests/integration/test_cicd_refactoring.py:494: in test_cli_single_stage
    from scripts.lib.cicd_testability import main
E   ModuleNotFoundError: No module named 'scripts.lib.cicd_testability'</failure></testcase><testcase classname="integration.test_cicd_refactoring.TestHelperFunctions" name="test_pipeline_config_serialization" time="0.002" /><testcase classname="integration.test_cicd_refactoring.TestHelperFunctions" name="test_stage_result_format" time="0.002" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_collection_status_returns_always_enabled" time="0.018" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_collection_status_handles_service_errors" time="0.016" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_collection_enable_is_idempotent" time="0.016" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_collection_enable_with_clear_data" time="0.079" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_collection_disable_returns_warning" time="0.018" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_collection_enable_disable_error_handling" time="0.015" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_regtech_trigger_with_date_parameters" time="0.016" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_regtech_trigger_with_form_data" time="0.015" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_regtech_trigger_without_dates" time="0.018" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_regtech_trigger_handles_collection_failure" time="0.016" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_regtech_trigger_handles_exceptions" time="0.016" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_secudium_trigger_returns_disabled_status" time="0.019" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_secudium_trigger_with_any_payload" time="0.016" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_concurrent_collection_requests" time="0.023" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_collection_status_with_real_service_calls" time="0.016"><failure message="assert 500 == 200&#10; +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code">tests/integration/test_collection_endpoints_integration.py:282: in test_collection_status_with_real_service_calls
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code</failure></testcase><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_regtech_trigger_logging" time="0.016"><failure message="assert 'logs' in {'daily_collection': {'recent_days': [], 'today': 0}, 'enabled': False, 'error': &quot;'count'&quot;, 'sources': {}, ...}">tests/integration/test_collection_endpoints_integration.py:301: in test_regtech_trigger_logging
    assert "logs" in status_data
E   assert 'logs' in {'daily_collection': {'recent_days': [], 'today': 0}, 'enabled': False, 'error': "'count'", 'sources': {}, ...}</failure></testcase><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_all_endpoints_return_json" time="0.018" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsIntegration" name="test_collection_state_remains_consistent" time="0.016"><failure message="assert False is True">tests/integration/test_collection_endpoints_integration.py:341: in test_collection_state_remains_consistent
    assert initial_state["enabled"] is True
E   assert False is True</failure></testcase><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsPerformance" name="test_collection_status_response_time" time="0.015"><failure message="assert 500 == 200&#10; +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code">tests/integration/test_collection_endpoints_integration.py:388: in test_collection_status_response_time
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code</failure></testcase><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsPerformance" name="test_multiple_rapid_requests" time="0.016" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsEdgeCases" name="test_malformed_json_handling" time="0.015" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsEdgeCases" name="test_empty_request_handling" time="0.015" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsEdgeCases" name="test_large_date_range_handling" time="0.015" /><testcase classname="integration.test_collection_endpoints_integration.TestCollectionEndpointsEdgeCases" name="test_special_characters_in_parameters" time="0.020" /><testcase classname="integration.test_collection_integration.TestCollectionIntegration" name="test_collection_status" time="0.004" /><testcase classname="integration.test_collection_integration.TestCollectionIntegration" name="test_regtech_collection" time="0.004" /><testcase classname="integration.test_collection_integration.TestCollectionIntegration" name="test_secudium_collection" time="0.004" /><testcase classname="integration.test_collection_integration.TestCollectionIntegration" name="test_collection_trigger" time="0.003" /><testcase classname="integration.test_collection_integration.TestCollectionIntegration" name="test_collection_disabled_state" time="0.003" /><testcase classname="integration.test_collection_integration.TestCollectionIntegration" name="test_collection_error_handling" time="0.003" /><testcase classname="integration.test_collection_integration.TestCollectionIntegration" name="test_collection_data_validation" time="0.003" /><testcase classname="integration.test_collection_system_integration" name="test_collection_manager_initialization" time="0.012"><failure message="AssertionError: Environment variable should override&#10;assert False == True&#10; +  where False = &lt;src.core.collection_manager.manager.CollectionManager object at 0x7565949ce8c0&gt;.collection_enabled">tests/integration/test_collection_system_integration.py:43: in test_collection_manager_initialization
    assert (
E   AssertionError: Environment variable should override
E   assert False == True
E    +  where False = &lt;src.core.collection_manager.manager.CollectionManager object at 0x7565949ce8c0&gt;.collection_enabled</failure></testcase><testcase classname="integration.test_collection_system_integration" name="test_collection_enable_disable_cycle" time="0.029"><failure message="KeyError: 'action'">tests/integration/test_collection_system_integration.py:75: in test_collection_enable_disable_cycle
    assert result["action"] == "enabled"
E   KeyError: 'action'</failure></testcase><testcase classname="integration.test_collection_system_integration" name="test_regtech_collector_mock_integration" time="0.003"><failure message="TypeError: RegtechSimpleCollector.__init__() got an unexpected keyword argument 'username'">tests/integration/test_collection_system_integration.py:154: in test_regtech_collector_mock_integration
    collector = RegtechSimpleCollector(
E   TypeError: RegtechSimpleCollector.__init__() got an unexpected keyword argument 'username'</failure></testcase><testcase classname="integration.test_collection_system_integration" name="test_data_lifecycle_integration" time="0.020" /><testcase classname="integration.test_collection_system_integration" name="test_collection_error_handling" time="0.004"><failure message="TypeError: RegtechSimpleCollector.__init__() got an unexpected keyword argument 'username'">tests/integration/test_collection_system_integration.py:286: in test_collection_error_handling
    collector = RegtechSimpleCollector(
E   TypeError: RegtechSimpleCollector.__init__() got an unexpected keyword argument 'username'</failure></testcase><testcase classname="integration.test_collection_system_integration" name="test_unified_service_integration" time="0.003"><failure message="AssertionError: assert 'collection_enabled' in {'active_ips': 0, 'last_update': '2025-08-08T19:56:43.299713', 'public_count': 0, 'regtech_count': 0, ...}">tests/integration/test_collection_system_integration.py:343: in test_unified_service_integration
    assert "collection_enabled" in health
E   AssertionError: assert 'collection_enabled' in {'active_ips': 0, 'last_update': '2025-08-08T19:56:43.299713', 'public_count': 0, 'regtech_count': 0, ...}</failure></testcase><testcase classname="integration.test_deployment_integration" name="test_dockerfile_build" time="0.002" /><testcase classname="integration.test_deployment_integration" name="test_kubernetes_manifests" time="0.017"><failure message="AssertionError: Invalid YAML in deployment.yaml: expected a single document in the stream&#10;    in &quot;k8s-gitops/base/deployment.yaml&quot;, line 1, column 1&#10;  but found another document&#10;    in &quot;k8s-gitops/base/deployment.yaml&quot;, line 182, column 1&#10;assert False">tests/integration/test_deployment_integration.py:71: in test_kubernetes_manifests
    yaml_content = yaml.safe_load(f)
../../.local/lib/python3.10/site-packages/yaml/__init__.py:125: in safe_load
    return load(stream, SafeLoader)
../../.local/lib/python3.10/site-packages/yaml/__init__.py:81: in load
    return loader.get_single_data()
../../.local/lib/python3.10/site-packages/yaml/constructor.py:49: in get_single_data
    node = self.get_single_node()
../../.local/lib/python3.10/site-packages/yaml/composer.py:41: in get_single_node
    raise ComposerError("expected a single document in the stream",
E   yaml.composer.ComposerError: expected a single document in the stream
E     in "k8s-gitops/base/deployment.yaml", line 1, column 1
E   but found another document
E     in "k8s-gitops/base/deployment.yaml", line 182, column 1

During handling of the above exception, another exception occurred:
tests/integration/test_deployment_integration.py:74: in test_kubernetes_manifests
    assert False, f"Invalid YAML in {file_name}: {e}"
E   AssertionError: Invalid YAML in deployment.yaml: expected a single document in the stream
E       in "k8s-gitops/base/deployment.yaml", line 1, column 1
E     but found another document
E       in "k8s-gitops/base/deployment.yaml", line 182, column 1
E   assert False</failure></testcase><testcase classname="integration.test_deployment_integration" name="test_argocd_application" time="0.003"><failure message="AssertionError: No ArgoCD application files found&#10;assert 0 &gt; 0&#10; +  where 0 = len([])">tests/integration/test_deployment_integration.py:140: in test_argocd_application
    assert len(app_files) &gt; 0, "No ArgoCD application files found"
E   AssertionError: No ArgoCD application files found
E   assert 0 &gt; 0
E    +  where 0 = len([])</failure></testcase><testcase classname="integration.test_deployment_integration" name="test_docker_compose" time="0.005" /><testcase classname="integration.test_deployment_integration" name="test_deployment_scripts" time="0.002" /><testcase classname="integration.test_deployment_integration" name="test_registry_configuration" time="0.003" /><testcase classname="integration.test_deployment_integration" name="test_health_probes" time="0.018"><failure message="yaml.composer.ComposerError: expected a single document in the stream&#10;  in &quot;k8s-gitops/base/deployment.yaml&quot;, line 1, column 1&#10;but found another document&#10;  in &quot;k8s-gitops/base/deployment.yaml&quot;, line 182, column 1">tests/integration/test_deployment_integration.py:277: in test_health_probes
    deployment = yaml.safe_load(f)
../../.local/lib/python3.10/site-packages/yaml/__init__.py:125: in safe_load
    return load(stream, SafeLoader)
../../.local/lib/python3.10/site-packages/yaml/__init__.py:81: in load
    return loader.get_single_data()
../../.local/lib/python3.10/site-packages/yaml/constructor.py:49: in get_single_data
    node = self.get_single_node()
../../.local/lib/python3.10/site-packages/yaml/composer.py:41: in get_single_node
    raise ComposerError("expected a single document in the stream",
E   yaml.composer.ComposerError: expected a single document in the stream
E     in "k8s-gitops/base/deployment.yaml", line 1, column 1
E   but found another document
E     in "k8s-gitops/base/deployment.yaml", line 182, column 1</failure></testcase><testcase classname="integration.test_deployment_integration" name="test_resource_limits" time="0.017"><failure message="yaml.composer.ComposerError: expected a single document in the stream&#10;  in &quot;k8s-gitops/base/deployment.yaml&quot;, line 1, column 1&#10;but found another document&#10;  in &quot;k8s-gitops/base/deployment.yaml&quot;, line 182, column 1">tests/integration/test_deployment_integration.py:314: in test_resource_limits
    deployment = yaml.safe_load(f)
../../.local/lib/python3.10/site-packages/yaml/__init__.py:125: in safe_load
    return load(stream, SafeLoader)
../../.local/lib/python3.10/site-packages/yaml/__init__.py:81: in load
    return loader.get_single_data()
../../.local/lib/python3.10/site-packages/yaml/constructor.py:49: in get_single_data
    node = self.get_single_node()
../../.local/lib/python3.10/site-packages/yaml/composer.py:41: in get_single_node
    raise ComposerError("expected a single document in the stream",
E   yaml.composer.ComposerError: expected a single document in the stream
E     in "k8s-gitops/base/deployment.yaml", line 1, column 1
E   but found another document
E     in "k8s-gitops/base/deployment.yaml", line 182, column 1</failure></testcase><testcase classname="integration.test_deployment_integration" name="test_hpa_configuration" time="0.002" /><testcase classname="integration.test_e2e_integration" name="test_complete_data_flow" time="0.094"><failure message="AttributeError: 'BlacklistContainer' object has no attribute 'resolve'">tests/integration/test_e2e_integration.py:68: in test_complete_data_flow
    blacklist_manager = container.resolve("blacklist_manager")
E   AttributeError: 'BlacklistContainer' object has no attribute 'resolve'</failure></testcase><testcase classname="integration.test_e2e_integration" name="test_deployment_pipeline_simulation" time="0.002"><failure message="AssertionError: CI/CD workflow not found&#10;assert False&#10; +  where False = &lt;bound method Path.exists of PosixPath('.github/workflows/simple-cicd.yml')&gt;()&#10; +    where &lt;bound method Path.exists of PosixPath('.github/workflows/simple-cicd.yml')&gt; = PosixPath('.github/workflows/simple-cicd.yml').exists">tests/integration/test_e2e_integration.py:171: in test_deployment_pipeline_simulation
    assert workflow_file.exists(), "CI/CD workflow not found"
E   AssertionError: CI/CD workflow not found
E   assert False
E    +  where False = &lt;bound method Path.exists of PosixPath('.github/workflows/simple-cicd.yml')&gt;()
E    +    where &lt;bound method Path.exists of PosixPath('.github/workflows/simple-cicd.yml')&gt; = PosixPath('.github/workflows/simple-cicd.yml').exists</failure></testcase><testcase classname="integration.test_e2e_integration" name="test_error_recovery_flow" time="0.120"><failure message="assert 500 in [400, 422]&#10; +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code">tests/integration/test_e2e_integration.py:252: in test_error_recovery_flow
    assert response.status_code in [400, 422]
E   assert 500 in [400, 422]
E    +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code</failure></testcase><testcase classname="integration.test_e2e_integration" name="test_performance_under_load" time="0.239"><failure message="ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574856940&gt; was created in a different Context">/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x75657484a240&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574861880&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x75657484bd80&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x75657488e400&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x75657485c380&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574856fc0&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x75657484b640&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x75657485e880&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x75657484b180&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574981800&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x756574848800&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x75657484ba80&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x756574848840&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x75657488ff00&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x756574848900&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x75657484ae80&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x756574854a80&gt; was created in a different Context

During handling of the above exception, another exception occurred:
tests/integration/test_e2e_integration.py:287: in test_performance_under_load
    with app.test_client() as client:
../../.local/lib/python3.10/site-packages/flask/testing.py:259: in __exit__
    self._context_stack.close()
/usr/lib/python3.10/contextlib.py:584: in close
    self.__exit__(None, None, None)
/usr/lib/python3.10/contextlib.py:576: in __exit__
    raise exc_details[1]
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574856940&gt; was created in a different Context</failure></testcase><testcase classname="integration.test_e2e_integration" name="test_multi_source_integration" time="0.076"><failure message="assert 500 == 200&#10; +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code">tests/integration/test_e2e_integration.py:391: in test_multi_source_integration
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestDataEdgeCases" name="test_empty_database_scenario" time="0.017"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:29: in test_empty_database_scenario
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestDataEdgeCases" name="test_large_response_handling" time="0.017"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:54: in test_large_response_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestDataEdgeCases" name="test_unicode_handling_in_errors" time="0.014"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:66: in test_unicode_handling_in_errors
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestDateEdgeCases" name="test_future_date_handling" time="0.015"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:87: in test_future_date_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestDateEdgeCases" name="test_very_old_date_handling" time="0.016"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:107: in test_very_old_date_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestDateEdgeCases" name="test_invalid_date_format_handling" time="0.016"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:123: in test_invalid_date_format_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestResourceExhaustionCases" name="test_memory_exhaustion_handling" time="0.015"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:147: in test_memory_exhaustion_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestResourceExhaustionCases" name="test_timeout_handling" time="0.015"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:165: in test_timeout_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestSpecialInputCases" name="test_null_and_undefined_handling" time="0.073"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:189: in test_null_and_undefined_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestSpecialInputCases" name="test_special_characters_in_requests" time="0.014"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/edge_case_tests.py:205: in test_special_characters_in_requests
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestAuthenticationErrors" name="test_authentication_failure_handling" time="0.015"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/error_scenarios.py:73: in test_authentication_failure_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestAuthenticationErrors" name="test_expired_session_handling" time="0.016"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/error_scenarios.py:92: in test_expired_session_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestConcurrencyErrors" name="test_race_condition_handling" time="0.022"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/error_scenarios.py:150: in test_race_condition_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestDatabaseErrors" name="test_database_lock_handling" time="0.017"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/error_scenarios.py:108: in test_database_lock_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestDatabaseErrors" name="test_database_corruption_handling" time="0.015"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/error_scenarios.py:124: in test_database_corruption_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestNetworkErrors" name="test_network_timeout_handling" time="0.014"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/error_scenarios.py:25: in test_network_timeout_handling
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestNetworkErrors" name="test_partial_network_failure" time="0.014"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/error_scenarios.py:53: in test_partial_network_failure
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_handling_edge_cases.TestErrorHandlingIntegration" name="test_basic_error_response_format" time="0.017"><failure message="AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'">tests/integration/test_error_handling_edge_cases.py:36: in test_basic_error_response_format
    with patch("src.core.unified_routes.service", mock_service):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'src.core.unified_routes' from '/home/jclee/app/blacklist/src/core/unified_routes.py'&gt; does not have the attribute 'service'</failure></testcase><testcase classname="integration.test_error_recovery.TestServiceErrorRecovery" name="test_service_recovers_from_transient_errors" time="0.010" /><testcase classname="integration.test_error_recovery.TestServiceErrorRecovery" name="test_service_degrades_gracefully" time="0.013"><failure message="AssertionError: assert 'healthy' == 'degraded'&#10;  - degraded&#10;  + healthy">tests/integration/test_error_recovery.py:78: in test_service_degrades_gracefully
    assert health["status"] == "degraded"
E   AssertionError: assert 'healthy' == 'degraded'
E     - degraded
E     + healthy</failure></testcase><testcase classname="integration.test_service_core.TestServiceCore" name="test_service_initialization" time="0.010" /><testcase classname="integration.test_service_core.TestServiceCore" name="test_service_handles_missing_dependencies" time="0.004" /><testcase classname="integration.test_service_core.TestServiceCore" name="test_system_health_aggregates_all_components" time="0.010"><failure message="AssertionError: assert &lt;Mock name='mock.get_system_stats().get()' id='129078640021552'&gt; == 3">tests/integration/test_service_core.py:72: in test_system_health_aggregates_all_components
    assert health["total_ips"] == 3
E   AssertionError: assert &lt;Mock name='mock.get_system_stats().get()' id='129078640021552'&gt; == 3</failure></testcase><testcase classname="integration.test_service_core.TestServiceCore" name="test_system_health_reports_unhealthy_state" time="0.009"><failure message="AssertionError: assert 'healthy' == 'degraded'&#10;  - degraded&#10;  + healthy">tests/integration/test_service_core.py:86: in test_system_health_reports_unhealthy_state
    assert health["status"] == "degraded"
E   AssertionError: assert 'healthy' == 'degraded'
E     - degraded
E     + healthy</failure></testcase><testcase classname="integration.test_service_integration.TestCacheDatabaseIntegration" name="test_cache_invalidation_on_collection" time="0.012"><failure message="assert 0 &gt; 0&#10; +  where 0 = len([])">tests/integration/test_cache_database_integration.py:48: in test_cache_invalidation_on_collection
    assert len(cache_calls) &gt; 0
E   assert 0 &gt; 0
E    +  where 0 = len([])</failure></testcase><testcase classname="integration.test_service_integration.TestCacheDatabaseIntegration" name="test_cache_fallback_behavior" time="0.009"><failure message="AssertionError: Expected 'get_all_ips' to have been called.">/usr/lib/python3.10/unittest/mock.py:898: in assert_called
    raise AssertionError(msg)
E   AssertionError: Expected 'get_all_ips' to have been called.

During handling of the above exception, another exception occurred:
tests/integration/test_cache_database_integration.py:67: in test_cache_fallback_behavior
    service.blacklist_manager.get_all_ips.assert_called()
E   AssertionError: Expected 'get_all_ips' to have been called.</failure></testcase><testcase classname="integration.test_service_integration.TestCacheDatabaseIntegration" name="test_database_transaction_handling" time="0.011"><failure message="assert 0 &gt; 0">tests/integration/test_cache_database_integration.py:102: in test_database_transaction_handling
    assert count &gt; 0
E   assert 0 &gt; 0</failure></testcase><testcase classname="integration.test_service_integration.TestCacheDatabaseIntegration" name="test_bulk_operation_performance" time="0.011"><failure message="KeyError: 'collected'">tests/integration/test_cache_database_integration.py:131: in test_bulk_operation_performance
    assert result["collected"] == 1000
E   KeyError: 'collected'</failure></testcase><testcase classname="integration.test_service_integration.TestCacheDatabaseIntegration" name="test_concurrent_service_access" time="0.014"><failure message="KeyError: 'enabled'">tests/integration/test_cache_database_integration.py:163: in test_concurrent_service_access
    assert all(r["status"]["enabled"] for r in results)
tests/integration/test_cache_database_integration.py:163: in &lt;genexpr&gt;
    assert all(r["status"]["enabled"] for r in results)
E   KeyError: 'enabled'</failure></testcase><testcase classname="integration.test_service_integration.TestCollectionIntegration" name="test_collection_status" time="0.003" /><testcase classname="integration.test_service_integration.TestCollectionIntegration" name="test_regtech_collection" time="0.003" /><testcase classname="integration.test_service_integration.TestCollectionIntegration" name="test_secudium_collection" time="0.004" /><testcase classname="integration.test_service_integration.TestCollectionIntegration" name="test_collection_trigger" time="0.005" /><testcase classname="integration.test_service_integration.TestCollectionIntegration" name="test_collection_disabled_state" time="0.004" /><testcase classname="integration.test_service_integration.TestCollectionIntegration" name="test_collection_error_handling" time="0.003" /><testcase classname="integration.test_service_integration.TestCollectionIntegration" name="test_collection_data_validation" time="0.003" /><testcase classname="integration.test_service_integration.TestServiceErrorRecovery" name="test_service_recovers_from_transient_errors" time="0.010" /><testcase classname="integration.test_service_integration.TestServiceErrorRecovery" name="test_service_degrades_gracefully" time="0.011"><failure message="AssertionError: assert 'healthy' == 'degraded'&#10;  - degraded&#10;  + healthy">tests/integration/test_error_recovery.py:78: in test_service_degrades_gracefully
    assert health["status"] == "degraded"
E   AssertionError: assert 'healthy' == 'degraded'
E     - degraded
E     + healthy</failure></testcase><testcase classname="integration.test_service_integration.TestServiceCore" name="test_service_initialization" time="0.009" /><testcase classname="integration.test_service_integration.TestServiceCore" name="test_service_handles_missing_dependencies" time="0.002" /><testcase classname="integration.test_service_integration.TestServiceCore" name="test_system_health_aggregates_all_components" time="0.010"><failure message="AssertionError: assert &lt;Mock name='mock.get_system_stats().get()' id='129078638908064'&gt; == 3">tests/integration/test_service_core.py:72: in test_system_health_aggregates_all_components
    assert health["total_ips"] == 3
E   AssertionError: assert &lt;Mock name='mock.get_system_stats().get()' id='129078638908064'&gt; == 3</failure></testcase><testcase classname="integration.test_service_integration.TestServiceCore" name="test_system_health_reports_unhealthy_state" time="0.011"><failure message="AssertionError: assert 'healthy' == 'degraded'&#10;  - degraded&#10;  + healthy">tests/integration/test_service_core.py:86: in test_system_health_reports_unhealthy_state
    assert health["status"] == "degraded"
E   AssertionError: assert 'healthy' == 'degraded'
E     - degraded
E     + healthy</failure></testcase><testcase classname="integration.test_service_integration.TestServiceLayerIntegration" name="test_service_initialization" time="0.011" /><testcase classname="integration.test_service_integration.TestServiceLayerIntegration" name="test_service_handles_missing_dependencies" time="0.002" /><testcase classname="integration.test_service_integration.TestServiceLayerIntegration" name="test_system_health_aggregates_all_components" time="0.010"><failure message="AssertionError: assert &lt;Mock name='mock.get_system_stats().get()' id='129078640582736'&gt; == 3">tests/integration/test_service_core.py:72: in test_system_health_aggregates_all_components
    assert health["total_ips"] == 3
E   AssertionError: assert &lt;Mock name='mock.get_system_stats().get()' id='129078640582736'&gt; == 3</failure></testcase><testcase classname="integration.test_service_integration.TestServiceLayerIntegration" name="test_system_health_reports_unhealthy_state" time="0.009"><failure message="AssertionError: assert 'healthy' == 'degraded'&#10;  - degraded&#10;  + healthy">tests/integration/test_service_core.py:86: in test_system_health_reports_unhealthy_state
    assert health["status"] == "degraded"
E   AssertionError: assert 'healthy' == 'degraded'
E     - degraded
E     + healthy</failure></testcase><testcase classname="integration.test_unified_routes_integration" name="test_health_endpoint_integration" time="0.015"><failure message="KeyError: 'components'">tests/integration/test_unified_routes_integration.py:38: in test_health_endpoint_integration
    assert "database" in data["components"], "Missing database component"
E   KeyError: 'components'</failure></testcase><testcase classname="integration.test_unified_routes_integration" name="test_blacklist_api_integration" time="0.016"><failure message="AssertionError: assert 'application/json' == 'text/plain; charset=utf-8'&#10;  - text/plain; charset=utf-8&#10;  + application/json">tests/integration/test_unified_routes_integration.py:66: in test_blacklist_api_integration
    assert response.content_type == "text/plain; charset=utf-8"
E   AssertionError: assert 'application/json' == 'text/plain; charset=utf-8'
E     - text/plain; charset=utf-8
E     + application/json</failure></testcase><testcase classname="integration.test_unified_routes_integration" name="test_collection_management_integration" time="0.020"><failure message="assert 500 == 200&#10; +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code">tests/integration/test_unified_routes_integration.py:113: in test_collection_management_integration
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code</failure></testcase><testcase classname="integration.test_unified_routes_integration" name="test_search_functionality_integration" time="0.044"><failure message="AssertionError: assert 'ip' in {'data': {'ip': '192.168.1.1', 'result': {'found': False, 'ip': '192.168.1.1', 'search_timestamp': '2025-08-08T19:56:46.270017', 'sources': []}, 'success': True, 'timestamp': '2025-08-08T19:56:46.290081'}, 'success': True}">tests/integration/test_unified_routes_integration.py:161: in test_search_functionality_integration
    assert "ip" in data
E   AssertionError: assert 'ip' in {'data': {'ip': '192.168.1.1', 'result': {'found': False, 'ip': '192.168.1.1', 'search_timestamp': '2025-08-08T19:56:46.270017', 'sources': []}, 'success': True, 'timestamp': '2025-08-08T19:56:46.290081'}, 'success': True}</failure></testcase><testcase classname="integration.test_unified_routes_integration" name="test_error_handling_integration" time="0.017"><failure message="assert 500 in [400, 415]&#10; +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code">tests/integration/test_unified_routes_integration.py:211: in test_error_handling_integration
    assert response.status_code in [400, 415]
E   assert 500 in [400, 415]
E    +  where 500 = &lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&gt;.status_code</failure></testcase><testcase classname="integration.test_unified_routes_integration" name="test_v2_api_endpoints_integration" time="0.018"><failure message="assert 404 == 200&#10; +  where 404 = &lt;WrapperTestResponse streamed [404 NOT FOUND]&gt;.status_code">tests/integration/test_unified_routes_integration.py:228: in test_v2_api_endpoints_integration
    assert response.status_code == 200
E   assert 404 == 200
E    +  where 404 = &lt;WrapperTestResponse streamed [404 NOT FOUND]&gt;.status_code</failure></testcase><testcase classname="integration.test_unified_routes_integration" name="test_performance_integration" time="0.028"><failure message="ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574c55400&gt; was created in a different Context">/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x756574a1d0c0&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574d78ec0&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x756574a1d100&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574991440&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x756574993500&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574992b80&gt; was created in a different Context

During handling of the above exception, another exception occurred:
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:277: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:258: in pop
    _cv_app.reset(self._cv_tokens.pop())
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.app_ctx' at 0x75659266f6a0&gt; at 0x756574ad3440&gt; was created in a different Context

During handling of the above exception, another exception occurred:
tests/integration/test_unified_routes_integration.py:266: in test_performance_integration
    with app.test_client() as client:
../../.local/lib/python3.10/site-packages/flask/testing.py:259: in __exit__
    self._context_stack.close()
/usr/lib/python3.10/contextlib.py:584: in close
    self.__exit__(None, None, None)
/usr/lib/python3.10/contextlib.py:576: in __exit__
    raise exc_details[1]
/usr/lib/python3.10/contextlib.py:561: in __exit__
    if cb(*exc_details):
../../.local/lib/python3.10/site-packages/flask/ctx.py:434: in __exit__
    self.pop(exc_value)
../../.local/lib/python3.10/site-packages/flask/ctx.py:409: in pop
    _cv_request.reset(token)
E   ValueError: &lt;Token var=&lt;ContextVar name='flask.request_ctx' at 0x75659266f650&gt; at 0x756574c55400&gt; was created in a different Context</failure></testcase><testcase classname="performance.test_performance_suite.TestAPIPerformance" name="test_health_endpoint_performance" time="0.057"><failure message="AssertionError: Health endpoint success rate too low: 0.0%&#10;assert 0.0 &gt;= 99.0">tests/performance/test_performance_suite.py:118: in test_health_endpoint_performance
    assert result['success_rate'] &gt;= 99.0, f"Health endpoint success rate too low: {result['success_rate']}%"
E   AssertionError: Health endpoint success rate too low: 0.0%
E   assert 0.0 &gt;= 99.0</failure></testcase><testcase classname="performance.test_performance_suite.TestAPIPerformance" name="test_blacklist_api_performance" time="0.104"><failure message="AssertionError: Blacklist API success rate too low: 0.0%&#10;assert 0.0 &gt;= 95.0">tests/performance/test_performance_suite.py:133: in test_blacklist_api_performance
    assert result['success_rate'] &gt;= 95.0, f"Blacklist API success rate too low: {result['success_rate']}%"
E   AssertionError: Blacklist API success rate too low: 0.0%
E   assert 0.0 &gt;= 95.0</failure></testcase><testcase classname="performance.test_performance_suite.TestAPIPerformance" name="test_collection_status_performance" time="0.058"><failure message="AssertionError: Collection status success rate too low: 0.0%&#10;assert 0.0 &gt;= 90.0">tests/performance/test_performance_suite.py:148: in test_collection_status_performance
    assert result['success_rate'] &gt;= 90.0, f"Collection status success rate too low: {result['success_rate']}%"
E   AssertionError: Collection status success rate too low: 0.0%
E   assert 0.0 &gt;= 90.0</failure></testcase><testcase classname="performance.test_performance_suite.TestDatabasePerformance" name="test_ip_lookup_performance" time="0.005" /><testcase classname="performance.test_performance_suite.TestDatabasePerformance" name="test_bulk_ip_operations" time="0.013" /><testcase classname="performance.test_performance_suite.TestCachePerformance" name="test_cache_operations_performance" time="0.005" /><testcase classname="performance.test_performance_suite" name="test_comprehensive_performance_benchmark" time="0.163"><failure message="AssertionError: Overall success rate too low: 0.0%&#10;assert 0.0 &gt;= 90.0">tests/performance/test_performance_suite.py:290: in test_comprehensive_performance_benchmark
    assert overall_success_rate &gt;= 90.0, f"Overall success rate too low: {overall_success_rate:.1f}%"
E   AssertionError: Overall success rate too low: 0.0%
E   assert 0.0 &gt;= 90.0</failure></testcase></testsuite></testsuites>