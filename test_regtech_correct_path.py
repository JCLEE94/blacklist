#!/usr/bin/env python3
"""
REGTECH ì˜¬ë°”ë¥¸ ê²½ë¡œë¡œ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import re
import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from loguru import logger
from dotenv import load_dotenv

load_dotenv()


def collect_regtech_data():
    """ì˜¬ë°”ë¥¸ ê²½ë¡œë¡œ REGTECH ë°ì´í„° ìˆ˜ì§‘"""
    
    username = os.getenv('REGTECH_USERNAME', '')
    password = os.getenv('REGTECH_PASSWORD', '')
    base_url = "https://regtech.fsec.or.kr"
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
    })
    
    # Step 1: ë¡œê·¸ì¸
    logger.info(f"ğŸ” ë¡œê·¸ì¸ ì‹œì‘: {username}")
    login_resp = session.post(
        f"{base_url}/login/loginProcess",
        data={'loginId': username, 'loginPw': password},
        allow_redirects=True
    )
    
    if 'regtech-front' not in session.cookies:
        logger.error("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨ - ì¿ í‚¤ ì—†ìŒ")
        return []
    
    logger.info(f"âœ… ë¡œê·¸ì¸ ì„±ê³µ! ì¿ í‚¤: {session.cookies.get('regtech-front')[:20]}...")
    
    # Step 2: ë°ì´í„° ìˆ˜ì§‘ (ì˜¬ë°”ë¥¸ ê²½ë¡œ)
    collected_ips = []
    page = 0
    max_pages = 10
    
    # ë‚ ì§œ ì„¤ì • (ìµœê·¼ 30ì¼)
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')
    
    logger.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")
    
    while page < max_pages:
        logger.info(f"ğŸ“„ í˜ì´ì§€ {page + 1} ìˆ˜ì§‘ ì¤‘...")
        
        # ì˜¬ë°”ë¥¸ ì—”ë“œí¬ì¸íŠ¸ì™€ íŒŒë¼ë¯¸í„°
        data = {
            "page": str(page),
            "tabSort": "blacklist",
            "startDate": start_date,
            "endDate": end_date,
            "findCondition": "all",
            "findKeyword": "",
            "size": "100",
            "rows": "100",
            "excelDownload": "",
            "cveId": "",
            "ipId": "",
            "estId": "",
        }
        
        # POST ìš”ì²­
        url = f"{base_url}/fcti/securityAdvisory/advisoryList"
        response = session.post(
            url,
            data=data,
            headers={"Content-Type": "application/x-www-form-urlencoded"},
            timeout=30
        )
        
        logger.info(f"   ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        
        if response.status_code != 200:
            logger.warning(f"   âš ï¸ í˜ì´ì§€ {page + 1} ì‹¤íŒ¨")
            break
        
        # HTML íŒŒì‹±
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë¡œê·¸ì¸ ì²´í¬
        if "login" in response.text.lower()[:500]:
            logger.error("âŒ ì„¸ì…˜ ë§Œë£Œ - ì¬ë¡œê·¸ì¸ í•„ìš”")
            break
        
        # í…Œì´ë¸” ì°¾ê¸°
        tables = soup.find_all('table')
        logger.info(f"   í…Œì´ë¸” ìˆ˜: {len(tables)}")
        
        # IP ë°ì´í„° ì¶”ì¶œ
        page_ips = []
        
        # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ IP ì°¾ê¸°
        # 1. í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
        for table in tables:
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all(['td', 'th'])
                for cell in cells:
                    text = cell.get_text(strip=True)
                    # IP íŒ¨í„´ ë§¤ì¹­
                    if text and '.' in text:
                        parts = text.split('.')
                        if len(parts) == 4:
                            try:
                                # IP í˜•ì‹ ê²€ì¦
                                octets = [int(p) for p in parts if p.isdigit()]
                                if len(octets) == 4 and all(0 <= o <= 255 for o in octets):
                                    ip_data = {
                                        "ip": text,
                                        "source": "REGTECH",
                                        "description": "Malicious IP from REGTECH",
                                        "detection_date": datetime.now().strftime('%Y-%m-%d'),
                                        "confidence": "high"
                                    }
                                    page_ips.append(ip_data)
                                    logger.info(f"      âœ… IP ë°œê²¬: {text}")
                            except:
                                pass
        
        # 2. JavaScript ë°ì´í„°ì—ì„œ ì°¾ê¸°
        scripts = soup.find_all('script')
        for script in scripts:
            if script.string and 'blacklist' in script.string.lower():
                # JavaScriptì—ì„œ IP íŒ¨í„´ ì°¾ê¸°
                ip_pattern = re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b')
                matches = ip_pattern.findall(script.string)
                for match in matches:
                    # ì‹¤ì œ IPì¸ì§€ ê²€ì¦
                    octets = match.split('.')
                    try:
                        if all(0 <= int(o) <= 255 for o in octets):
                            ip_data = {
                                "ip": match,
                                "source": "REGTECH",
                                "description": "Malicious IP from REGTECH (JS)",
                                "detection_date": datetime.now().strftime('%Y-%m-%d'),
                                "confidence": "high"
                            }
                            if ip_data not in page_ips:
                                page_ips.append(ip_data)
                                logger.info(f"      âœ… IP ë°œê²¬ (JS): {match}")
                    except:
                        pass
        
        # 3. Advisory ë°ì´í„° í™•ì¸
        advisory_items = soup.find_all(class_=re.compile('advisory|blacklist|threat', re.I))
        logger.info(f"   Advisory í•­ëª©: {len(advisory_items)}")
        
        if page_ips:
            logger.info(f"   ğŸ“Š í˜ì´ì§€ {page + 1}ì—ì„œ {len(page_ips)}ê°œ IP ìˆ˜ì§‘")
            collected_ips.extend(page_ips)
        else:
            logger.info(f"   âš ï¸ í˜ì´ì§€ {page + 1}ì—ì„œ IPë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # ë””ë²„ê¹…: HTML ì¼ë¶€ ì €ì¥
            if page == 0:
                with open('regtech_first_page.html', 'w', encoding='utf-8') as f:
                    f.write(response.text)
                logger.info("   ì²« í˜ì´ì§€ HTMLì„ regtech_first_page.htmlì— ì €ì¥")
            
            # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
            if page > 0:
                logger.info("   ë” ì´ìƒ ë°ì´í„° ì—†ìŒ - ìˆ˜ì§‘ ì¢…ë£Œ")
                break
        
        page += 1
    
    session.close()
    
    # ê²°ê³¼ ìš”ì•½
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
    logger.info(f"   ì´ {len(collected_ips)}ê°œ IP ìˆ˜ì§‘")
    
    if collected_ips:
        logger.info(f"\nğŸ” ì²˜ìŒ 5ê°œ IP:")
        for i, ip_data in enumerate(collected_ips[:5], 1):
            logger.info(f"   {i}. {ip_data['ip']}")
    
    return collected_ips


if __name__ == "__main__":
    # ì‹¤í–‰
    collected_data = collect_regtech_data()
    
    if collected_data:
        print(f"\nâœ… ì„±ê³µ! {len(collected_data)}ê°œ ì‹¤ì œ IPë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    else:
        print("\nâŒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. HTML íŒŒì¼ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
        sys.exit(1)